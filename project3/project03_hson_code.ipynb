{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECE 763 Project 3 Babysitting the training of DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                                   Rachel Hyo Son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor,Resize,Normalize\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Rache\\\\Documents\\\\GitHub\\\\ECE 763\\\\hson_project03\\\\00.psudo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='./main_dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using `CIFAR10` dataset to build my model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape) # batch size , # of channel, # pixelsize, pixel size \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bird   car  ship   cat\n"
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "outputSize = 10\n",
    "hiddenSize = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameter : `requires_grad` want gradients with respect to weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pytorch.autograd** provides classes and functions implementing automatic differentiation of arbitrary scalar valued functions. It requires minimal changes to the existing code - you only need to declare Tensor s for which gradients should be computed with the `requires_grad=True` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(inputSize, hiddenSize, requires_grad=True)\n",
    "#W1.requires_grad_()\n",
    "W2 = torch.randn(hiddenSize,outputSize, requires_grad=True)\n",
    "#W2.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Active Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid\n",
    "sigmoid = Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Sigmoid(X):\n",
    "    z  = torch.matmul(X, W1)\n",
    "    z2 = sigmoid(z)\n",
    "    z3 = torch.matmul(z2,W2)\n",
    "    #o  = sigmoid(z3)\n",
    "    return z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified Linear unit (ReLU) are commonly used since they are relatively robust to the vanishing/exploding gradient issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Relu(X):\n",
    "    z  = torch.matmul(X, W1)\n",
    "    z2 = z.clamp(min=0)\n",
    "    z3 = torch.matmul(z2,W2)\n",
    "    #o  = sigmoid(z3)\n",
    "    return z3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measures the cross-entropy between the predicted and the actual value. \n",
    "- x is the probability of the true label and y is the probability of predicted label \n",
    "- cross-entropy as a loss function is used to learn the probability distribution of the data. cross entropy gives a greater penalty when incorrect predictions are predicted with high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop\n",
    "- `loss.backward()`: updates the gradients of the model (`weight`)\n",
    "- `with torch.no_grad()`: use gradients to update the `weight`\n",
    "- `grad.zero_()`: set the gradients to zero, so that get ready for the next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "time0 = time()\n",
    "lr = 0.5 # learning rate\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    running_loss = 0\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    X = torch.reshape(inputs,(-1,32*32*3))\n",
    "    x = torch.tensor(X)\n",
    "    output = model_Sigmoid(x)   \n",
    "    \n",
    "    loss = criterion(output,labels)\n",
    "    loss.backward() ## updates the gradients of the model weights \n",
    "    \n",
    "    running_loss += loss.item()\n",
    "    with torch.no_grad():\n",
    "        W1 -=  W1.grad *lr\n",
    "        W2 -=  W2.grad *lr\n",
    "        W1.grad.zero_()\n",
    "        W2.grad.zero_()   \n",
    "    #print(f' Loss : {running_loss/len(trainloader)}')\n",
    "#print(f' Training Time : {(time()-time0)/60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3072])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 6, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop over the dataset multiple times using `epoch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,loss:2.57\n",
      "Epoch:1,loss:2.53\n",
      "Epoch:1,loss:2.53\n",
      "Epoch:1,loss:2.55\n",
      "Epoch:1,loss:2.50\n",
      "Epoch:1,loss:2.49\n",
      "Epoch:2,loss:2.49\n",
      "Epoch:2,loss:2.48\n",
      "Epoch:2,loss:2.46\n",
      "Epoch:2,loss:2.45\n",
      "Epoch:2,loss:2.41\n",
      "Epoch:2,loss:2.44\n",
      "Epoch:3,loss:2.43\n",
      "Epoch:3,loss:2.41\n",
      "Epoch:3,loss:2.45\n",
      "Epoch:3,loss:2.41\n",
      "Epoch:3,loss:2.42\n",
      "Epoch:3,loss:2.43\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    lr = 0.5 # learning rate\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "    \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        output = model_Sigmoid(x)   \n",
    "    \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward() ## updates the gradients of the model weights \n",
    "    \n",
    "        with torch.no_grad():\n",
    "            W1 -=  W1.grad *lr\n",
    "            W2 -=  W2.grad *lr\n",
    "            W1.grad.zero_()\n",
    "            W2.grad.zero_()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            #print('[%d, %5d] loss: %.3f' %\n",
    "                 # (epoch + 1, i + 1, running_loss / 2000))\n",
    "            print(f'Epoch:{epoch+1},loss:{running_loss/2000:.2f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model-1: activation function with Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "outputSize = 10\n",
    "hiddenSize_1 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.049\n",
      "[1,  4000] loss: 1.853\n",
      "[1,  6000] loss: 1.812\n",
      "[1,  8000] loss: 1.773\n",
      "[1, 10000] loss: 1.743\n",
      "[1, 12000] loss: 1.733\n",
      "[2,  2000] loss: 1.704\n",
      "[2,  4000] loss: 1.674\n",
      "[2,  6000] loss: 1.675\n",
      "[2,  8000] loss: 1.670\n",
      "[2, 10000] loss: 1.674\n",
      "[2, 12000] loss: 1.675\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate = 1e-2\n",
    "    momentum = 0\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 42 %\n"
     ]
    }
   ],
   "source": [
    "#train score\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 22 %\n",
      "Accuracy of   cat : 17 %\n",
      "Accuracy of  deer : 33 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 58 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 51 %\n",
      "Accuracy of truck : 57 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-2 : activation function with ReLu (one-layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "outputSize = 10\n",
    "hiddenSize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (3): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.840\n",
      "[1,  4000] loss: 1.696\n",
      "[1,  6000] loss: 1.657\n",
      "[1,  8000] loss: 1.627\n",
      "[1, 10000] loss: 1.625\n",
      "[1, 12000] loss: 1.580\n",
      "[2,  2000] loss: 1.510\n",
      "[2,  4000] loss: 1.516\n",
      "[2,  6000] loss: 1.504\n",
      "[2,  8000] loss: 1.523\n",
      "[2, 10000] loss: 1.495\n",
      "[2, 12000] loss: 1.499\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate = 1e-2\n",
    "    momentum = 0\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 46 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 26 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 42 %\n",
      "Accuracy of   cat : 15 %\n",
      "Accuracy of  deer : 31 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 66 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 69 %\n",
      "Accuracy of truck : 53 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model -2 : activation function with ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (3): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loop over the dataset multiple times using `epoch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `learning rate` is 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.848\n",
      "[1,  4000] loss: 1.696\n",
      "[1,  6000] loss: 1.661\n",
      "[1,  8000] loss: 1.634\n",
      "[1, 10000] loss: 1.595\n",
      "[1, 12000] loss: 1.594\n",
      "[2,  2000] loss: 1.520\n",
      "[2,  4000] loss: 1.512\n",
      "[2,  6000] loss: 1.529\n",
      "[2,  8000] loss: 1.498\n",
      "[2, 10000] loss: 1.523\n",
      "[2, 12000] loss: 1.479\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate = 1e-2\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 49 %\n",
      "Accuracy of   car : 50 %\n",
      "Accuracy of  bird : 26 %\n",
      "Accuracy of   cat : 44 %\n",
      "Accuracy of  deer : 47 %\n",
      "Accuracy of   dog : 29 %\n",
      "Accuracy of  frog : 54 %\n",
      "Accuracy of horse : 61 %\n",
      "Accuracy of  ship : 66 %\n",
      "Accuracy of truck : 50 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `learning rate` change to 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.308\n",
      "[1,  4000] loss: 1.282\n",
      "[1,  6000] loss: 1.279\n",
      "[1,  8000] loss: 1.274\n",
      "[1, 10000] loss: 1.246\n",
      "[1, 12000] loss: 1.275\n",
      "[2,  2000] loss: 1.238\n",
      "[2,  4000] loss: 1.238\n",
      "[2,  6000] loss: 1.251\n",
      "[2,  8000] loss: 1.239\n",
      "[2, 10000] loss: 1.229\n",
      "[2, 12000] loss: 1.220\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate = 1e-3\n",
    "    momentum = 0\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is reasonably changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = './cifar_net.pth'\n",
    "#torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 33 %\n",
      "Accuracy of   cat : 31 %\n",
      "Accuracy of  deer : 42 %\n",
      "Accuracy of   dog : 42 %\n",
      "Accuracy of  frog : 69 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 67 %\n",
      "Accuracy of truck : 57 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `learning rate` change to 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.197\n",
      "[1,  4000] loss: 1.216\n",
      "[1,  6000] loss: 1.181\n",
      "[1,  8000] loss: 1.215\n",
      "[1, 10000] loss: 1.200\n",
      "[1, 12000] loss: 1.221\n",
      "[2,  2000] loss: 1.203\n",
      "[2,  4000] loss: 1.189\n",
      "[2,  6000] loss: 1.210\n",
      "[2,  8000] loss: 1.199\n",
      "[2, 10000] loss: 1.205\n",
      "[2, 12000] loss: 1.211\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-6\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 33 %\n",
      "Accuracy of   cat : 31 %\n",
      "Accuracy of  deer : 43 %\n",
      "Accuracy of   dog : 42 %\n",
      "Accuracy of  frog : 68 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 68 %\n",
      "Accuracy of truck : 57 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `learning rate` change to 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.208\n",
      "[1,  4000] loss: 1.207\n",
      "[1,  6000] loss: 1.192\n",
      "[1,  8000] loss: 1.203\n",
      "[1, 10000] loss: 1.194\n",
      "[1, 12000] loss: 1.194\n",
      "[2,  2000] loss: 1.191\n",
      "[2,  4000] loss: 1.201\n",
      "[2,  6000] loss: 1.202\n",
      "[2,  8000] loss: 1.188\n",
      "[2, 10000] loss: 1.200\n",
      "[2, 12000] loss: 1.181\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-4\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 61 %\n",
      "Accuracy of  bird : 38 %\n",
      "Accuracy of   cat : 33 %\n",
      "Accuracy of  deer : 45 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 65 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 67 %\n",
      "Accuracy of truck : 60 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`learning rate` change to 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.188\n",
      "[1,  4000] loss: 1.216\n",
      "[1,  6000] loss: 1.183\n",
      "[1,  8000] loss: 1.194\n",
      "[1, 10000] loss: 1.190\n",
      "[1, 12000] loss: 1.179\n",
      "[2,  2000] loss: 1.182\n",
      "[2,  4000] loss: 1.188\n",
      "[2,  6000] loss: 1.203\n",
      "[2,  8000] loss: 1.195\n",
      "[2, 10000] loss: 1.188\n",
      "[2, 12000] loss: 1.189\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-5\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 57 %\n",
      "Accuracy of   car : 61 %\n",
      "Accuracy of  bird : 37 %\n",
      "Accuracy of   cat : 32 %\n",
      "Accuracy of  deer : 45 %\n",
      "Accuracy of   dog : 38 %\n",
      "Accuracy of  frog : 65 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 68 %\n",
      "Accuracy of truck : 59 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `learning rate` is selected `1e-3`\n",
    "\n",
    "- Regularization : weight_decay = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.202\n",
      "[1,  4000] loss: 1.211\n",
      "[1,  6000] loss: 1.198\n",
      "[1,  8000] loss: 1.214\n",
      "[1, 10000] loss: 1.217\n",
      "[1, 12000] loss: 1.204\n",
      "[2,  2000] loss: 1.180\n",
      "[2,  4000] loss: 1.192\n",
      "[2,  6000] loss: 1.196\n",
      "[2,  8000] loss: 1.187\n",
      "[2, 10000] loss: 1.210\n",
      "[2, 12000] loss: 1.188\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-3\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=1e-5)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 59 %\n"
     ]
    }
   ],
   "source": [
    "#train score\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "#test score\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 61 %\n",
      "Accuracy of   car : 58 %\n",
      "Accuracy of  bird : 35 %\n",
      "Accuracy of   cat : 30 %\n",
      "Accuracy of  deer : 49 %\n",
      "Accuracy of   dog : 45 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 59 %\n",
      "Accuracy of  ship : 65 %\n",
      "Accuracy of truck : 62 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `loss rate` is selected `1e-3`\n",
    "\n",
    "- Regularization : weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.173\n",
      "[1,  4000] loss: 1.164\n",
      "[1,  6000] loss: 1.168\n",
      "[1,  8000] loss: 1.154\n",
      "[1, 10000] loss: 1.186\n",
      "[1, 12000] loss: 1.195\n",
      "[2,  2000] loss: 1.145\n",
      "[2,  4000] loss: 1.160\n",
      "[2,  6000] loss: 1.161\n",
      "[2,  8000] loss: 1.175\n",
      "[2, 10000] loss: 1.149\n",
      "[2, 12000] loss: 1.157\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-3\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=1e-6)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the train images: 61 %\n"
     ]
    }
   ],
   "source": [
    "# training data result\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the train images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "# testing data accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 60 %\n",
      "Accuracy of  bird : 38 %\n",
      "Accuracy of   cat : 31 %\n",
      "Accuracy of  deer : 45 %\n",
      "Accuracy of   dog : 44 %\n",
      "Accuracy of  frog : 66 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 70 %\n",
      "Accuracy of truck : 58 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.145\n",
      "[1,  4000] loss: 1.144\n",
      "[1,  6000] loss: 1.133\n",
      "[1,  8000] loss: 1.129\n",
      "[1, 10000] loss: 1.160\n",
      "[1, 12000] loss: 1.148\n",
      "[2,  2000] loss: 1.119\n",
      "[2,  4000] loss: 1.113\n",
      "[2,  6000] loss: 1.142\n",
      "[2,  8000] loss: 1.134\n",
      "[2, 10000] loss: 1.123\n",
      "[2, 12000] loss: 1.140\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-3\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=1e-5, momentum=0.001)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 61 %\n",
      "Accuracy of   car : 59 %\n",
      "Accuracy of  bird : 35 %\n",
      "Accuracy of   cat : 31 %\n",
      "Accuracy of  deer : 49 %\n",
      "Accuracy of   dog : 37 %\n",
      "Accuracy of  frog : 66 %\n",
      "Accuracy of horse : 60 %\n",
      "Accuracy of  ship : 65 %\n",
      "Accuracy of truck : 58 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 1 | epoch : 1 batch: 2000 lr : 0.000069 wd: 0.000173, loss: 2.28 accuracy: 18.91\n",
      "count : 1 | epoch : 1 batch: 4000 lr : 0.000069 wd: 0.000173, loss: 2.23 accuracy: 24.18\n",
      "count : 1 | epoch : 1 batch: 6000 lr : 0.000069 wd: 0.000173, loss: 2.19 accuracy: 25.93\n",
      "count : 1 | epoch : 1 batch: 8000 lr : 0.000069 wd: 0.000173, loss: 2.16 accuracy: 27.08\n",
      "count : 1 | epoch : 1 batch: 10000 lr : 0.000069 wd: 0.000173, loss: 2.13 accuracy: 28.10\n",
      "count : 1 | epoch : 1 batch: 12000 lr : 0.000069 wd: 0.000173, loss: 2.10 accuracy: 28.91\n",
      "count : 1 | epoch : 2 batch: 2000 lr : 0.000069 wd: 0.000173, loss: 2.07 accuracy: 30.14\n",
      "count : 1 | epoch : 2 batch: 4000 lr : 0.000069 wd: 0.000173, loss: 2.05 accuracy: 30.78\n",
      "count : 1 | epoch : 2 batch: 6000 lr : 0.000069 wd: 0.000173, loss: 2.03 accuracy: 31.30\n",
      "count : 1 | epoch : 2 batch: 8000 lr : 0.000069 wd: 0.000173, loss: 2.01 accuracy: 31.60\n",
      "count : 1 | epoch : 2 batch: 10000 lr : 0.000069 wd: 0.000173, loss: 1.99 accuracy: 32.06\n",
      "count : 1 | epoch : 2 batch: 12000 lr : 0.000069 wd: 0.000173, loss: 1.97 accuracy: 32.52\n",
      "count : 2 | epoch : 1 batch: 2000 lr : 0.000282 wd: 0.000090, loss: 1.93 accuracy: 34.32\n",
      "count : 2 | epoch : 1 batch: 4000 lr : 0.000282 wd: 0.000090, loss: 1.91 accuracy: 35.43\n",
      "count : 2 | epoch : 1 batch: 6000 lr : 0.000282 wd: 0.000090, loss: 1.87 accuracy: 36.40\n",
      "count : 2 | epoch : 1 batch: 8000 lr : 0.000282 wd: 0.000090, loss: 1.83 accuracy: 37.14\n",
      "count : 2 | epoch : 1 batch: 10000 lr : 0.000282 wd: 0.000090, loss: 1.82 accuracy: 38.06\n",
      "count : 2 | epoch : 1 batch: 12000 lr : 0.000282 wd: 0.000090, loss: 1.80 accuracy: 38.32\n",
      "count : 2 | epoch : 2 batch: 2000 lr : 0.000282 wd: 0.000090, loss: 1.77 accuracy: 38.78\n",
      "count : 2 | epoch : 2 batch: 4000 lr : 0.000282 wd: 0.000090, loss: 1.75 accuracy: 39.10\n",
      "count : 2 | epoch : 2 batch: 6000 lr : 0.000282 wd: 0.000090, loss: 1.74 accuracy: 39.29\n",
      "count : 2 | epoch : 2 batch: 8000 lr : 0.000282 wd: 0.000090, loss: 1.74 accuracy: 39.42\n",
      "count : 2 | epoch : 2 batch: 10000 lr : 0.000282 wd: 0.000090, loss: 1.73 accuracy: 40.16\n",
      "count : 2 | epoch : 2 batch: 12000 lr : 0.000282 wd: 0.000090, loss: 1.73 accuracy: 40.63\n",
      "count : 3 | epoch : 1 batch: 2000 lr : 0.000199 wd: 0.000919, loss: 1.72 accuracy: 40.94\n",
      "count : 3 | epoch : 1 batch: 4000 lr : 0.000199 wd: 0.000919, loss: 1.70 accuracy: 40.82\n",
      "count : 3 | epoch : 1 batch: 6000 lr : 0.000199 wd: 0.000919, loss: 1.68 accuracy: 41.11\n",
      "count : 3 | epoch : 1 batch: 8000 lr : 0.000199 wd: 0.000919, loss: 1.66 accuracy: 41.35\n",
      "count : 3 | epoch : 1 batch: 10000 lr : 0.000199 wd: 0.000919, loss: 1.68 accuracy: 41.47\n",
      "count : 3 | epoch : 1 batch: 12000 lr : 0.000199 wd: 0.000919, loss: 1.68 accuracy: 41.90\n",
      "count : 3 | epoch : 2 batch: 2000 lr : 0.000199 wd: 0.000919, loss: 1.66 accuracy: 41.96\n",
      "count : 3 | epoch : 2 batch: 4000 lr : 0.000199 wd: 0.000919, loss: 1.67 accuracy: 42.28\n",
      "count : 3 | epoch : 2 batch: 6000 lr : 0.000199 wd: 0.000919, loss: 1.63 accuracy: 42.48\n",
      "count : 3 | epoch : 2 batch: 8000 lr : 0.000199 wd: 0.000919, loss: 1.66 accuracy: 42.57\n",
      "count : 3 | epoch : 2 batch: 10000 lr : 0.000199 wd: 0.000919, loss: 1.66 accuracy: 42.55\n",
      "count : 3 | epoch : 2 batch: 12000 lr : 0.000199 wd: 0.000919, loss: 1.63 accuracy: 42.76\n",
      "count : 4 | epoch : 1 batch: 2000 lr : 0.000524 wd: 0.000095, loss: 1.62 accuracy: 43.54\n",
      "count : 4 | epoch : 1 batch: 4000 lr : 0.000524 wd: 0.000095, loss: 1.63 accuracy: 43.31\n",
      "count : 4 | epoch : 1 batch: 6000 lr : 0.000524 wd: 0.000095, loss: 1.60 accuracy: 43.64\n",
      "count : 4 | epoch : 1 batch: 8000 lr : 0.000524 wd: 0.000095, loss: 1.61 accuracy: 44.24\n",
      "count : 4 | epoch : 1 batch: 10000 lr : 0.000524 wd: 0.000095, loss: 1.61 accuracy: 44.76\n",
      "count : 4 | epoch : 1 batch: 12000 lr : 0.000524 wd: 0.000095, loss: 1.59 accuracy: 44.36\n",
      "count : 4 | epoch : 2 batch: 2000 lr : 0.000524 wd: 0.000095, loss: 1.55 accuracy: 44.73\n",
      "count : 4 | epoch : 2 batch: 4000 lr : 0.000524 wd: 0.000095, loss: 1.57 accuracy: 44.89\n",
      "count : 4 | epoch : 2 batch: 6000 lr : 0.000524 wd: 0.000095, loss: 1.58 accuracy: 45.53\n",
      "count : 4 | epoch : 2 batch: 8000 lr : 0.000524 wd: 0.000095, loss: 1.57 accuracy: 45.47\n",
      "count : 4 | epoch : 2 batch: 10000 lr : 0.000524 wd: 0.000095, loss: 1.55 accuracy: 45.67\n",
      "count : 4 | epoch : 2 batch: 12000 lr : 0.000524 wd: 0.000095, loss: 1.56 accuracy: 46.00\n",
      "count : 5 | epoch : 1 batch: 2000 lr : 0.000013 wd: 0.000011, loss: 1.52 accuracy: 45.71\n",
      "count : 5 | epoch : 1 batch: 4000 lr : 0.000013 wd: 0.000011, loss: 1.52 accuracy: 45.75\n",
      "count : 5 | epoch : 1 batch: 6000 lr : 0.000013 wd: 0.000011, loss: 1.55 accuracy: 45.82\n",
      "count : 5 | epoch : 1 batch: 8000 lr : 0.000013 wd: 0.000011, loss: 1.53 accuracy: 45.87\n",
      "count : 5 | epoch : 1 batch: 10000 lr : 0.000013 wd: 0.000011, loss: 1.53 accuracy: 45.97\n",
      "count : 5 | epoch : 1 batch: 12000 lr : 0.000013 wd: 0.000011, loss: 1.53 accuracy: 45.99\n",
      "count : 5 | epoch : 2 batch: 2000 lr : 0.000013 wd: 0.000011, loss: 1.54 accuracy: 45.86\n",
      "count : 5 | epoch : 2 batch: 4000 lr : 0.000013 wd: 0.000011, loss: 1.53 accuracy: 45.98\n",
      "count : 5 | epoch : 2 batch: 6000 lr : 0.000013 wd: 0.000011, loss: 1.53 accuracy: 46.10\n",
      "count : 5 | epoch : 2 batch: 8000 lr : 0.000013 wd: 0.000011, loss: 1.52 accuracy: 46.06\n",
      "count : 5 | epoch : 2 batch: 10000 lr : 0.000013 wd: 0.000011, loss: 1.52 accuracy: 46.07\n",
      "count : 5 | epoch : 2 batch: 12000 lr : 0.000013 wd: 0.000011, loss: 1.51 accuracy: 46.14\n",
      "count : 6 | epoch : 1 batch: 2000 lr : 0.000050 wd: 0.000007, loss: 1.52 accuracy: 46.06\n",
      "count : 6 | epoch : 1 batch: 4000 lr : 0.000050 wd: 0.000007, loss: 1.53 accuracy: 46.41\n",
      "count : 6 | epoch : 1 batch: 6000 lr : 0.000050 wd: 0.000007, loss: 1.52 accuracy: 46.36\n",
      "count : 6 | epoch : 1 batch: 8000 lr : 0.000050 wd: 0.000007, loss: 1.54 accuracy: 46.43\n",
      "count : 6 | epoch : 1 batch: 10000 lr : 0.000050 wd: 0.000007, loss: 1.51 accuracy: 46.48\n",
      "count : 6 | epoch : 1 batch: 12000 lr : 0.000050 wd: 0.000007, loss: 1.53 accuracy: 46.40\n",
      "count : 6 | epoch : 2 batch: 2000 lr : 0.000050 wd: 0.000007, loss: 1.53 accuracy: 46.35\n",
      "count : 6 | epoch : 2 batch: 4000 lr : 0.000050 wd: 0.000007, loss: 1.52 accuracy: 46.45\n",
      "count : 6 | epoch : 2 batch: 6000 lr : 0.000050 wd: 0.000007, loss: 1.53 accuracy: 46.50\n",
      "count : 6 | epoch : 2 batch: 8000 lr : 0.000050 wd: 0.000007, loss: 1.52 accuracy: 46.47\n",
      "count : 6 | epoch : 2 batch: 10000 lr : 0.000050 wd: 0.000007, loss: 1.51 accuracy: 46.44\n",
      "count : 6 | epoch : 2 batch: 12000 lr : 0.000050 wd: 0.000007, loss: 1.52 accuracy: 46.41\n",
      "count : 7 | epoch : 1 batch: 2000 lr : 0.000031 wd: 0.000142, loss: 1.54 accuracy: 46.48\n",
      "count : 7 | epoch : 1 batch: 4000 lr : 0.000031 wd: 0.000142, loss: 1.53 accuracy: 46.46\n",
      "count : 7 | epoch : 1 batch: 6000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.47\n",
      "count : 7 | epoch : 1 batch: 8000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.53\n",
      "count : 7 | epoch : 1 batch: 10000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.57\n",
      "count : 7 | epoch : 1 batch: 12000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.57\n",
      "count : 7 | epoch : 2 batch: 2000 lr : 0.000031 wd: 0.000142, loss: 1.52 accuracy: 46.59\n",
      "count : 7 | epoch : 2 batch: 4000 lr : 0.000031 wd: 0.000142, loss: 1.54 accuracy: 46.64\n",
      "count : 7 | epoch : 2 batch: 6000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.73\n",
      "count : 7 | epoch : 2 batch: 8000 lr : 0.000031 wd: 0.000142, loss: 1.51 accuracy: 46.70\n",
      "count : 7 | epoch : 2 batch: 10000 lr : 0.000031 wd: 0.000142, loss: 1.50 accuracy: 46.65\n",
      "count : 7 | epoch : 2 batch: 12000 lr : 0.000031 wd: 0.000142, loss: 1.50 accuracy: 46.65\n",
      "count : 8 | epoch : 1 batch: 2000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.55\n",
      "count : 8 | epoch : 1 batch: 4000 lr : 0.000109 wd: 0.000136, loss: 1.50 accuracy: 46.54\n",
      "count : 8 | epoch : 1 batch: 6000 lr : 0.000109 wd: 0.000136, loss: 1.53 accuracy: 46.75\n",
      "count : 8 | epoch : 1 batch: 8000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.99\n",
      "count : 8 | epoch : 1 batch: 10000 lr : 0.000109 wd: 0.000136, loss: 1.50 accuracy: 46.70\n",
      "count : 8 | epoch : 1 batch: 12000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.90\n",
      "count : 8 | epoch : 2 batch: 2000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.63\n",
      "count : 8 | epoch : 2 batch: 4000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.70\n",
      "count : 8 | epoch : 2 batch: 6000 lr : 0.000109 wd: 0.000136, loss: 1.50 accuracy: 47.04\n",
      "count : 8 | epoch : 2 batch: 8000 lr : 0.000109 wd: 0.000136, loss: 1.51 accuracy: 46.88\n",
      "count : 8 | epoch : 2 batch: 10000 lr : 0.000109 wd: 0.000136, loss: 1.50 accuracy: 46.84\n",
      "count : 8 | epoch : 2 batch: 12000 lr : 0.000109 wd: 0.000136, loss: 1.50 accuracy: 46.83\n",
      "count : 9 | epoch : 1 batch: 2000 lr : 0.000014 wd: 0.000003, loss: 1.50 accuracy: 47.21\n",
      "count : 9 | epoch : 1 batch: 4000 lr : 0.000014 wd: 0.000003, loss: 1.51 accuracy: 47.11\n",
      "count : 9 | epoch : 1 batch: 6000 lr : 0.000014 wd: 0.000003, loss: 1.50 accuracy: 47.07\n",
      "count : 9 | epoch : 1 batch: 8000 lr : 0.000014 wd: 0.000003, loss: 1.49 accuracy: 47.11\n",
      "count : 9 | epoch : 1 batch: 10000 lr : 0.000014 wd: 0.000003, loss: 1.50 accuracy: 47.11\n",
      "count : 9 | epoch : 1 batch: 12000 lr : 0.000014 wd: 0.000003, loss: 1.48 accuracy: 47.14\n",
      "count : 9 | epoch : 2 batch: 2000 lr : 0.000014 wd: 0.000003, loss: 1.50 accuracy: 47.15\n",
      "count : 9 | epoch : 2 batch: 4000 lr : 0.000014 wd: 0.000003, loss: 1.51 accuracy: 47.14\n",
      "count : 9 | epoch : 2 batch: 6000 lr : 0.000014 wd: 0.000003, loss: 1.50 accuracy: 47.14\n",
      "count : 9 | epoch : 2 batch: 8000 lr : 0.000014 wd: 0.000003, loss: 1.48 accuracy: 47.08\n",
      "count : 9 | epoch : 2 batch: 10000 lr : 0.000014 wd: 0.000003, loss: 1.49 accuracy: 47.14\n",
      "count : 9 | epoch : 2 batch: 12000 lr : 0.000014 wd: 0.000003, loss: 1.49 accuracy: 47.15\n",
      "count : 10 | epoch : 1 batch: 2000 lr : 0.000095 wd: 0.000596, loss: 1.52 accuracy: 46.99\n",
      "count : 10 | epoch : 1 batch: 4000 lr : 0.000095 wd: 0.000596, loss: 1.49 accuracy: 46.76\n",
      "count : 10 | epoch : 1 batch: 6000 lr : 0.000095 wd: 0.000596, loss: 1.50 accuracy: 46.90\n",
      "count : 10 | epoch : 1 batch: 8000 lr : 0.000095 wd: 0.000596, loss: 1.50 accuracy: 47.16\n",
      "count : 10 | epoch : 1 batch: 10000 lr : 0.000095 wd: 0.000596, loss: 1.49 accuracy: 47.07\n",
      "count : 10 | epoch : 1 batch: 12000 lr : 0.000095 wd: 0.000596, loss: 1.49 accuracy: 47.19\n",
      "count : 10 | epoch : 2 batch: 2000 lr : 0.000095 wd: 0.000596, loss: 1.50 accuracy: 47.11\n",
      "count : 10 | epoch : 2 batch: 4000 lr : 0.000095 wd: 0.000596, loss: 1.48 accuracy: 47.34\n",
      "count : 10 | epoch : 2 batch: 6000 lr : 0.000095 wd: 0.000596, loss: 1.49 accuracy: 47.05\n",
      "count : 10 | epoch : 2 batch: 8000 lr : 0.000095 wd: 0.000596, loss: 1.48 accuracy: 47.49\n",
      "count : 10 | epoch : 2 batch: 10000 lr : 0.000095 wd: 0.000596, loss: 1.48 accuracy: 47.30\n",
      "count : 10 | epoch : 2 batch: 12000 lr : 0.000095 wd: 0.000596, loss: 1.50 accuracy: 47.33\n",
      "count : 11 | epoch : 1 batch: 2000 lr : 0.000617 wd: 0.000004, loss: 1.49 accuracy: 46.66\n",
      "count : 11 | epoch : 1 batch: 4000 lr : 0.000617 wd: 0.000004, loss: 1.48 accuracy: 46.83\n",
      "count : 11 | epoch : 1 batch: 6000 lr : 0.000617 wd: 0.000004, loss: 1.50 accuracy: 47.43\n",
      "count : 11 | epoch : 1 batch: 8000 lr : 0.000617 wd: 0.000004, loss: 1.48 accuracy: 47.15\n",
      "count : 11 | epoch : 1 batch: 10000 lr : 0.000617 wd: 0.000004, loss: 1.48 accuracy: 47.05\n",
      "count : 11 | epoch : 1 batch: 12000 lr : 0.000617 wd: 0.000004, loss: 1.48 accuracy: 47.58\n",
      "count : 11 | epoch : 2 batch: 2000 lr : 0.000617 wd: 0.000004, loss: 1.47 accuracy: 47.78\n",
      "count : 11 | epoch : 2 batch: 4000 lr : 0.000617 wd: 0.000004, loss: 1.47 accuracy: 47.57\n",
      "count : 11 | epoch : 2 batch: 6000 lr : 0.000617 wd: 0.000004, loss: 1.45 accuracy: 47.50\n",
      "count : 11 | epoch : 2 batch: 8000 lr : 0.000617 wd: 0.000004, loss: 1.47 accuracy: 47.48\n",
      "count : 11 | epoch : 2 batch: 10000 lr : 0.000617 wd: 0.000004, loss: 1.45 accuracy: 47.63\n",
      "count : 11 | epoch : 2 batch: 12000 lr : 0.000617 wd: 0.000004, loss: 1.43 accuracy: 48.01\n",
      "count : 12 | epoch : 1 batch: 2000 lr : 0.000149 wd: 0.000016, loss: 1.42 accuracy: 48.57\n",
      "count : 12 | epoch : 1 batch: 4000 lr : 0.000149 wd: 0.000016, loss: 1.42 accuracy: 48.62\n",
      "count : 12 | epoch : 1 batch: 6000 lr : 0.000149 wd: 0.000016, loss: 1.41 accuracy: 48.53\n",
      "count : 12 | epoch : 1 batch: 8000 lr : 0.000149 wd: 0.000016, loss: 1.44 accuracy: 48.59\n",
      "count : 12 | epoch : 1 batch: 10000 lr : 0.000149 wd: 0.000016, loss: 1.44 accuracy: 48.71\n",
      "count : 12 | epoch : 1 batch: 12000 lr : 0.000149 wd: 0.000016, loss: 1.40 accuracy: 48.60\n",
      "count : 12 | epoch : 2 batch: 2000 lr : 0.000149 wd: 0.000016, loss: 1.41 accuracy: 48.40\n",
      "count : 12 | epoch : 2 batch: 4000 lr : 0.000149 wd: 0.000016, loss: 1.42 accuracy: 48.65\n",
      "count : 12 | epoch : 2 batch: 6000 lr : 0.000149 wd: 0.000016, loss: 1.40 accuracy: 48.54\n",
      "count : 12 | epoch : 2 batch: 8000 lr : 0.000149 wd: 0.000016, loss: 1.42 accuracy: 48.59\n",
      "count : 12 | epoch : 2 batch: 10000 lr : 0.000149 wd: 0.000016, loss: 1.41 accuracy: 48.66\n",
      "count : 12 | epoch : 2 batch: 12000 lr : 0.000149 wd: 0.000016, loss: 1.41 accuracy: 48.62\n",
      "count : 13 | epoch : 1 batch: 2000 lr : 0.000063 wd: 0.000016, loss: 1.41 accuracy: 48.77\n",
      "count : 13 | epoch : 1 batch: 4000 lr : 0.000063 wd: 0.000016, loss: 1.40 accuracy: 48.81\n",
      "count : 13 | epoch : 1 batch: 6000 lr : 0.000063 wd: 0.000016, loss: 1.40 accuracy: 48.65\n",
      "count : 13 | epoch : 1 batch: 8000 lr : 0.000063 wd: 0.000016, loss: 1.42 accuracy: 48.79\n",
      "count : 13 | epoch : 1 batch: 10000 lr : 0.000063 wd: 0.000016, loss: 1.41 accuracy: 48.79\n",
      "count : 13 | epoch : 1 batch: 12000 lr : 0.000063 wd: 0.000016, loss: 1.39 accuracy: 48.69\n",
      "count : 13 | epoch : 2 batch: 2000 lr : 0.000063 wd: 0.000016, loss: 1.40 accuracy: 48.79\n",
      "count : 13 | epoch : 2 batch: 4000 lr : 0.000063 wd: 0.000016, loss: 1.40 accuracy: 48.95\n",
      "count : 13 | epoch : 2 batch: 6000 lr : 0.000063 wd: 0.000016, loss: 1.41 accuracy: 48.72\n",
      "count : 13 | epoch : 2 batch: 8000 lr : 0.000063 wd: 0.000016, loss: 1.40 accuracy: 48.79\n",
      "count : 13 | epoch : 2 batch: 10000 lr : 0.000063 wd: 0.000016, loss: 1.39 accuracy: 48.64\n",
      "count : 13 | epoch : 2 batch: 12000 lr : 0.000063 wd: 0.000016, loss: 1.41 accuracy: 48.85\n",
      "count : 14 | epoch : 1 batch: 2000 lr : 0.000532 wd: 0.000863, loss: 1.41 accuracy: 48.68\n",
      "count : 14 | epoch : 1 batch: 4000 lr : 0.000532 wd: 0.000863, loss: 1.41 accuracy: 48.69\n",
      "count : 14 | epoch : 1 batch: 6000 lr : 0.000532 wd: 0.000863, loss: 1.41 accuracy: 48.60\n",
      "count : 14 | epoch : 1 batch: 8000 lr : 0.000532 wd: 0.000863, loss: 1.39 accuracy: 48.89\n",
      "count : 14 | epoch : 1 batch: 10000 lr : 0.000532 wd: 0.000863, loss: 1.41 accuracy: 48.85\n",
      "count : 14 | epoch : 1 batch: 12000 lr : 0.000532 wd: 0.000863, loss: 1.41 accuracy: 49.28\n",
      "count : 14 | epoch : 2 batch: 2000 lr : 0.000532 wd: 0.000863, loss: 1.38 accuracy: 49.22\n",
      "count : 14 | epoch : 2 batch: 4000 lr : 0.000532 wd: 0.000863, loss: 1.38 accuracy: 48.78\n",
      "count : 14 | epoch : 2 batch: 6000 lr : 0.000532 wd: 0.000863, loss: 1.39 accuracy: 49.26\n",
      "count : 14 | epoch : 2 batch: 8000 lr : 0.000532 wd: 0.000863, loss: 1.38 accuracy: 49.25\n",
      "count : 14 | epoch : 2 batch: 10000 lr : 0.000532 wd: 0.000863, loss: 1.39 accuracy: 49.71\n",
      "count : 14 | epoch : 2 batch: 12000 lr : 0.000532 wd: 0.000863, loss: 1.39 accuracy: 49.65\n",
      "count : 15 | epoch : 1 batch: 2000 lr : 0.000840 wd: 0.000105, loss: 1.35 accuracy: 49.71\n",
      "count : 15 | epoch : 1 batch: 4000 lr : 0.000840 wd: 0.000105, loss: 1.38 accuracy: 49.11\n",
      "count : 15 | epoch : 1 batch: 6000 lr : 0.000840 wd: 0.000105, loss: 1.37 accuracy: 49.77\n",
      "count : 15 | epoch : 1 batch: 8000 lr : 0.000840 wd: 0.000105, loss: 1.39 accuracy: 49.71\n",
      "count : 15 | epoch : 1 batch: 10000 lr : 0.000840 wd: 0.000105, loss: 1.38 accuracy: 49.84\n",
      "count : 15 | epoch : 1 batch: 12000 lr : 0.000840 wd: 0.000105, loss: 1.36 accuracy: 49.83\n",
      "count : 15 | epoch : 2 batch: 2000 lr : 0.000840 wd: 0.000105, loss: 1.36 accuracy: 49.78\n",
      "count : 15 | epoch : 2 batch: 4000 lr : 0.000840 wd: 0.000105, loss: 1.34 accuracy: 50.22\n",
      "count : 15 | epoch : 2 batch: 6000 lr : 0.000840 wd: 0.000105, loss: 1.33 accuracy: 49.80\n",
      "count : 15 | epoch : 2 batch: 8000 lr : 0.000840 wd: 0.000105, loss: 1.34 accuracy: 49.84\n",
      "count : 15 | epoch : 2 batch: 10000 lr : 0.000840 wd: 0.000105, loss: 1.36 accuracy: 49.52\n",
      "count : 15 | epoch : 2 batch: 12000 lr : 0.000840 wd: 0.000105, loss: 1.33 accuracy: 50.25\n",
      "count : 16 | epoch : 1 batch: 2000 lr : 0.000013 wd: 0.000206, loss: 1.32 accuracy: 50.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 16 | epoch : 1 batch: 4000 lr : 0.000013 wd: 0.000206, loss: 1.28 accuracy: 50.73\n",
      "count : 16 | epoch : 1 batch: 6000 lr : 0.000013 wd: 0.000206, loss: 1.30 accuracy: 50.73\n",
      "count : 16 | epoch : 1 batch: 8000 lr : 0.000013 wd: 0.000206, loss: 1.32 accuracy: 50.74\n",
      "count : 16 | epoch : 1 batch: 10000 lr : 0.000013 wd: 0.000206, loss: 1.30 accuracy: 50.77\n",
      "count : 16 | epoch : 1 batch: 12000 lr : 0.000013 wd: 0.000206, loss: 1.31 accuracy: 50.89\n",
      "count : 16 | epoch : 2 batch: 2000 lr : 0.000013 wd: 0.000206, loss: 1.30 accuracy: 50.84\n",
      "count : 16 | epoch : 2 batch: 4000 lr : 0.000013 wd: 0.000206, loss: 1.30 accuracy: 50.92\n",
      "count : 16 | epoch : 2 batch: 6000 lr : 0.000013 wd: 0.000206, loss: 1.29 accuracy: 50.92\n",
      "count : 16 | epoch : 2 batch: 8000 lr : 0.000013 wd: 0.000206, loss: 1.30 accuracy: 50.85\n",
      "count : 16 | epoch : 2 batch: 10000 lr : 0.000013 wd: 0.000206, loss: 1.29 accuracy: 50.91\n",
      "count : 16 | epoch : 2 batch: 12000 lr : 0.000013 wd: 0.000206, loss: 1.31 accuracy: 51.03\n",
      "count : 17 | epoch : 1 batch: 2000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.02\n",
      "count : 17 | epoch : 1 batch: 4000 lr : 0.000038 wd: 0.000324, loss: 1.32 accuracy: 51.21\n",
      "count : 17 | epoch : 1 batch: 6000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.14\n",
      "count : 17 | epoch : 1 batch: 8000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.15\n",
      "count : 17 | epoch : 1 batch: 10000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.24\n",
      "count : 17 | epoch : 1 batch: 12000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.18\n",
      "count : 17 | epoch : 2 batch: 2000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.26\n",
      "count : 17 | epoch : 2 batch: 4000 lr : 0.000038 wd: 0.000324, loss: 1.30 accuracy: 51.20\n",
      "count : 17 | epoch : 2 batch: 6000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 50.98\n",
      "count : 17 | epoch : 2 batch: 8000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 50.98\n",
      "count : 17 | epoch : 2 batch: 10000 lr : 0.000038 wd: 0.000324, loss: 1.30 accuracy: 51.14\n",
      "count : 17 | epoch : 2 batch: 12000 lr : 0.000038 wd: 0.000324, loss: 1.29 accuracy: 51.24\n",
      "count : 18 | epoch : 1 batch: 2000 lr : 0.000072 wd: 0.000001, loss: 1.31 accuracy: 50.99\n",
      "count : 18 | epoch : 1 batch: 4000 lr : 0.000072 wd: 0.000001, loss: 1.28 accuracy: 51.18\n",
      "count : 18 | epoch : 1 batch: 6000 lr : 0.000072 wd: 0.000001, loss: 1.29 accuracy: 51.01\n",
      "count : 18 | epoch : 1 batch: 8000 lr : 0.000072 wd: 0.000001, loss: 1.29 accuracy: 51.20\n",
      "count : 18 | epoch : 1 batch: 10000 lr : 0.000072 wd: 0.000001, loss: 1.28 accuracy: 51.06\n",
      "count : 18 | epoch : 1 batch: 12000 lr : 0.000072 wd: 0.000001, loss: 1.30 accuracy: 51.31\n",
      "count : 18 | epoch : 2 batch: 2000 lr : 0.000072 wd: 0.000001, loss: 1.29 accuracy: 51.06\n",
      "count : 18 | epoch : 2 batch: 4000 lr : 0.000072 wd: 0.000001, loss: 1.28 accuracy: 51.05\n",
      "count : 18 | epoch : 2 batch: 6000 lr : 0.000072 wd: 0.000001, loss: 1.28 accuracy: 51.22\n",
      "count : 18 | epoch : 2 batch: 8000 lr : 0.000072 wd: 0.000001, loss: 1.31 accuracy: 51.23\n",
      "count : 18 | epoch : 2 batch: 10000 lr : 0.000072 wd: 0.000001, loss: 1.29 accuracy: 51.16\n",
      "count : 18 | epoch : 2 batch: 12000 lr : 0.000072 wd: 0.000001, loss: 1.27 accuracy: 51.14\n",
      "count : 19 | epoch : 1 batch: 2000 lr : 0.000131 wd: 0.000132, loss: 1.28 accuracy: 51.05\n",
      "count : 19 | epoch : 1 batch: 4000 lr : 0.000131 wd: 0.000132, loss: 1.29 accuracy: 51.14\n",
      "count : 19 | epoch : 1 batch: 6000 lr : 0.000131 wd: 0.000132, loss: 1.27 accuracy: 51.10\n",
      "count : 19 | epoch : 1 batch: 8000 lr : 0.000131 wd: 0.000132, loss: 1.28 accuracy: 51.22\n",
      "count : 19 | epoch : 1 batch: 10000 lr : 0.000131 wd: 0.000132, loss: 1.31 accuracy: 51.19\n",
      "count : 19 | epoch : 1 batch: 12000 lr : 0.000131 wd: 0.000132, loss: 1.30 accuracy: 50.95\n",
      "count : 19 | epoch : 2 batch: 2000 lr : 0.000131 wd: 0.000132, loss: 1.27 accuracy: 50.91\n",
      "count : 19 | epoch : 2 batch: 4000 lr : 0.000131 wd: 0.000132, loss: 1.28 accuracy: 51.02\n",
      "count : 19 | epoch : 2 batch: 6000 lr : 0.000131 wd: 0.000132, loss: 1.28 accuracy: 50.98\n",
      "count : 19 | epoch : 2 batch: 8000 lr : 0.000131 wd: 0.000132, loss: 1.28 accuracy: 50.95\n",
      "count : 19 | epoch : 2 batch: 10000 lr : 0.000131 wd: 0.000132, loss: 1.29 accuracy: 51.01\n",
      "count : 19 | epoch : 2 batch: 12000 lr : 0.000131 wd: 0.000132, loss: 1.29 accuracy: 51.06\n",
      "count : 20 | epoch : 1 batch: 2000 lr : 0.000933 wd: 0.000008, loss: 1.30 accuracy: 50.32\n",
      "count : 20 | epoch : 1 batch: 4000 lr : 0.000933 wd: 0.000008, loss: 1.30 accuracy: 50.92\n",
      "count : 20 | epoch : 1 batch: 6000 lr : 0.000933 wd: 0.000008, loss: 1.29 accuracy: 50.43\n",
      "count : 20 | epoch : 1 batch: 8000 lr : 0.000933 wd: 0.000008, loss: 1.30 accuracy: 50.54\n",
      "count : 20 | epoch : 1 batch: 10000 lr : 0.000933 wd: 0.000008, loss: 1.32 accuracy: 50.51\n",
      "count : 20 | epoch : 1 batch: 12000 lr : 0.000933 wd: 0.000008, loss: 1.32 accuracy: 50.79\n",
      "count : 20 | epoch : 2 batch: 2000 lr : 0.000933 wd: 0.000008, loss: 1.30 accuracy: 50.70\n",
      "count : 20 | epoch : 2 batch: 4000 lr : 0.000933 wd: 0.000008, loss: 1.27 accuracy: 50.46\n",
      "count : 20 | epoch : 2 batch: 6000 lr : 0.000933 wd: 0.000008, loss: 1.26 accuracy: 50.61\n",
      "count : 20 | epoch : 2 batch: 8000 lr : 0.000933 wd: 0.000008, loss: 1.28 accuracy: 50.91\n",
      "count : 20 | epoch : 2 batch: 10000 lr : 0.000933 wd: 0.000008, loss: 1.32 accuracy: 50.60\n",
      "count : 20 | epoch : 2 batch: 12000 lr : 0.000933 wd: 0.000008, loss: 1.27 accuracy: 50.84\n",
      "count : 21 | epoch : 1 batch: 2000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.67\n",
      "count : 21 | epoch : 1 batch: 4000 lr : 0.000310 wd: 0.000070, loss: 1.22 accuracy: 51.70\n",
      "count : 21 | epoch : 1 batch: 6000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.49\n",
      "count : 21 | epoch : 1 batch: 8000 lr : 0.000310 wd: 0.000070, loss: 1.24 accuracy: 51.54\n",
      "count : 21 | epoch : 1 batch: 10000 lr : 0.000310 wd: 0.000070, loss: 1.25 accuracy: 51.42\n",
      "count : 21 | epoch : 1 batch: 12000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.39\n",
      "count : 21 | epoch : 2 batch: 2000 lr : 0.000310 wd: 0.000070, loss: 1.21 accuracy: 51.46\n",
      "count : 21 | epoch : 2 batch: 4000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.78\n",
      "count : 21 | epoch : 2 batch: 6000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.32\n",
      "count : 21 | epoch : 2 batch: 8000 lr : 0.000310 wd: 0.000070, loss: 1.23 accuracy: 51.61\n",
      "count : 21 | epoch : 2 batch: 10000 lr : 0.000310 wd: 0.000070, loss: 1.22 accuracy: 51.46\n",
      "count : 21 | epoch : 2 batch: 12000 lr : 0.000310 wd: 0.000070, loss: 1.24 accuracy: 51.76\n",
      "count : 22 | epoch : 1 batch: 2000 lr : 0.000482 wd: 0.000001, loss: 1.21 accuracy: 51.48\n",
      "count : 22 | epoch : 1 batch: 4000 lr : 0.000482 wd: 0.000001, loss: 1.23 accuracy: 51.48\n",
      "count : 22 | epoch : 1 batch: 6000 lr : 0.000482 wd: 0.000001, loss: 1.21 accuracy: 51.55\n",
      "count : 22 | epoch : 1 batch: 8000 lr : 0.000482 wd: 0.000001, loss: 1.22 accuracy: 51.47\n",
      "count : 22 | epoch : 1 batch: 10000 lr : 0.000482 wd: 0.000001, loss: 1.24 accuracy: 51.96\n",
      "count : 22 | epoch : 1 batch: 12000 lr : 0.000482 wd: 0.000001, loss: 1.24 accuracy: 51.87\n",
      "count : 22 | epoch : 2 batch: 2000 lr : 0.000482 wd: 0.000001, loss: 1.20 accuracy: 51.63\n",
      "count : 22 | epoch : 2 batch: 4000 lr : 0.000482 wd: 0.000001, loss: 1.20 accuracy: 51.69\n",
      "count : 22 | epoch : 2 batch: 6000 lr : 0.000482 wd: 0.000001, loss: 1.21 accuracy: 51.59\n",
      "count : 22 | epoch : 2 batch: 8000 lr : 0.000482 wd: 0.000001, loss: 1.21 accuracy: 51.85\n",
      "count : 22 | epoch : 2 batch: 10000 lr : 0.000482 wd: 0.000001, loss: 1.21 accuracy: 52.01\n",
      "count : 22 | epoch : 2 batch: 12000 lr : 0.000482 wd: 0.000001, loss: 1.24 accuracy: 52.17\n",
      "count : 23 | epoch : 1 batch: 2000 lr : 0.000661 wd: 0.000004, loss: 1.20 accuracy: 51.65\n",
      "count : 23 | epoch : 1 batch: 4000 lr : 0.000661 wd: 0.000004, loss: 1.20 accuracy: 51.49\n",
      "count : 23 | epoch : 1 batch: 6000 lr : 0.000661 wd: 0.000004, loss: 1.20 accuracy: 51.93\n",
      "count : 23 | epoch : 1 batch: 8000 lr : 0.000661 wd: 0.000004, loss: 1.21 accuracy: 51.64\n",
      "count : 23 | epoch : 1 batch: 10000 lr : 0.000661 wd: 0.000004, loss: 1.21 accuracy: 51.99\n",
      "count : 23 | epoch : 1 batch: 12000 lr : 0.000661 wd: 0.000004, loss: 1.22 accuracy: 51.60\n",
      "count : 23 | epoch : 2 batch: 2000 lr : 0.000661 wd: 0.000004, loss: 1.19 accuracy: 51.72\n",
      "count : 23 | epoch : 2 batch: 4000 lr : 0.000661 wd: 0.000004, loss: 1.17 accuracy: 51.97\n",
      "count : 23 | epoch : 2 batch: 6000 lr : 0.000661 wd: 0.000004, loss: 1.19 accuracy: 51.24\n",
      "count : 23 | epoch : 2 batch: 8000 lr : 0.000661 wd: 0.000004, loss: 1.22 accuracy: 51.21\n",
      "count : 23 | epoch : 2 batch: 10000 lr : 0.000661 wd: 0.000004, loss: 1.21 accuracy: 51.92\n",
      "count : 23 | epoch : 2 batch: 12000 lr : 0.000661 wd: 0.000004, loss: 1.19 accuracy: 52.24\n",
      "count : 24 | epoch : 1 batch: 2000 lr : 0.000701 wd: 0.000134, loss: 1.18 accuracy: 51.64\n",
      "count : 24 | epoch : 1 batch: 4000 lr : 0.000701 wd: 0.000134, loss: 1.17 accuracy: 51.86\n",
      "count : 24 | epoch : 1 batch: 6000 lr : 0.000701 wd: 0.000134, loss: 1.19 accuracy: 51.66\n",
      "count : 24 | epoch : 1 batch: 8000 lr : 0.000701 wd: 0.000134, loss: 1.18 accuracy: 51.67\n",
      "count : 24 | epoch : 1 batch: 10000 lr : 0.000701 wd: 0.000134, loss: 1.18 accuracy: 51.87\n",
      "count : 24 | epoch : 1 batch: 12000 lr : 0.000701 wd: 0.000134, loss: 1.20 accuracy: 51.66\n",
      "count : 24 | epoch : 2 batch: 2000 lr : 0.000701 wd: 0.000134, loss: 1.15 accuracy: 51.25\n",
      "count : 24 | epoch : 2 batch: 4000 lr : 0.000701 wd: 0.000134, loss: 1.17 accuracy: 51.46\n",
      "count : 24 | epoch : 2 batch: 6000 lr : 0.000701 wd: 0.000134, loss: 1.16 accuracy: 51.60\n",
      "count : 24 | epoch : 2 batch: 8000 lr : 0.000701 wd: 0.000134, loss: 1.19 accuracy: 51.74\n",
      "count : 24 | epoch : 2 batch: 10000 lr : 0.000701 wd: 0.000134, loss: 1.16 accuracy: 51.62\n",
      "count : 24 | epoch : 2 batch: 12000 lr : 0.000701 wd: 0.000134, loss: 1.17 accuracy: 51.82\n",
      "count : 25 | epoch : 1 batch: 2000 lr : 0.000582 wd: 0.000392, loss: 1.14 accuracy: 52.33\n",
      "count : 25 | epoch : 1 batch: 4000 lr : 0.000582 wd: 0.000392, loss: 1.14 accuracy: 51.84\n",
      "count : 25 | epoch : 1 batch: 6000 lr : 0.000582 wd: 0.000392, loss: 1.15 accuracy: 52.14\n",
      "count : 25 | epoch : 1 batch: 8000 lr : 0.000582 wd: 0.000392, loss: 1.16 accuracy: 51.52\n",
      "count : 25 | epoch : 1 batch: 10000 lr : 0.000582 wd: 0.000392, loss: 1.16 accuracy: 52.14\n",
      "count : 25 | epoch : 1 batch: 12000 lr : 0.000582 wd: 0.000392, loss: 1.15 accuracy: 51.95\n",
      "count : 25 | epoch : 2 batch: 2000 lr : 0.000582 wd: 0.000392, loss: 1.14 accuracy: 52.23\n",
      "count : 25 | epoch : 2 batch: 4000 lr : 0.000582 wd: 0.000392, loss: 1.13 accuracy: 51.74\n",
      "count : 25 | epoch : 2 batch: 6000 lr : 0.000582 wd: 0.000392, loss: 1.13 accuracy: 52.15\n",
      "count : 25 | epoch : 2 batch: 8000 lr : 0.000582 wd: 0.000392, loss: 1.16 accuracy: 52.24\n",
      "count : 25 | epoch : 2 batch: 10000 lr : 0.000582 wd: 0.000392, loss: 1.13 accuracy: 52.17\n",
      "count : 25 | epoch : 2 batch: 12000 lr : 0.000582 wd: 0.000392, loss: 1.13 accuracy: 51.98\n",
      "count : 26 | epoch : 1 batch: 2000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.25\n",
      "count : 26 | epoch : 1 batch: 4000 lr : 0.000381 wd: 0.000049, loss: 1.12 accuracy: 52.36\n",
      "count : 26 | epoch : 1 batch: 6000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.14\n",
      "count : 26 | epoch : 1 batch: 8000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.60\n",
      "count : 26 | epoch : 1 batch: 10000 lr : 0.000381 wd: 0.000049, loss: 1.12 accuracy: 52.25\n",
      "count : 26 | epoch : 1 batch: 12000 lr : 0.000381 wd: 0.000049, loss: 1.12 accuracy: 52.26\n",
      "count : 26 | epoch : 2 batch: 2000 lr : 0.000381 wd: 0.000049, loss: 1.09 accuracy: 52.25\n",
      "count : 26 | epoch : 2 batch: 4000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.19\n",
      "count : 26 | epoch : 2 batch: 6000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.14\n",
      "count : 26 | epoch : 2 batch: 8000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.63\n",
      "count : 26 | epoch : 2 batch: 10000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.43\n",
      "count : 26 | epoch : 2 batch: 12000 lr : 0.000381 wd: 0.000049, loss: 1.11 accuracy: 52.07\n",
      "count : 27 | epoch : 1 batch: 2000 lr : 0.000017 wd: 0.000047, loss: 1.10 accuracy: 52.57\n",
      "count : 27 | epoch : 1 batch: 4000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.63\n",
      "count : 27 | epoch : 1 batch: 6000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.63\n",
      "count : 27 | epoch : 1 batch: 8000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.82\n",
      "count : 27 | epoch : 1 batch: 10000 lr : 0.000017 wd: 0.000047, loss: 1.07 accuracy: 52.72\n",
      "count : 27 | epoch : 1 batch: 12000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.61\n",
      "count : 27 | epoch : 2 batch: 2000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.68\n",
      "count : 27 | epoch : 2 batch: 4000 lr : 0.000017 wd: 0.000047, loss: 1.07 accuracy: 52.65\n",
      "count : 27 | epoch : 2 batch: 6000 lr : 0.000017 wd: 0.000047, loss: 1.08 accuracy: 52.70\n",
      "count : 27 | epoch : 2 batch: 8000 lr : 0.000017 wd: 0.000047, loss: 1.07 accuracy: 52.67\n",
      "count : 27 | epoch : 2 batch: 10000 lr : 0.000017 wd: 0.000047, loss: 1.06 accuracy: 52.55\n",
      "count : 27 | epoch : 2 batch: 12000 lr : 0.000017 wd: 0.000047, loss: 1.09 accuracy: 52.74\n",
      "count : 28 | epoch : 1 batch: 2000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.29\n",
      "count : 28 | epoch : 1 batch: 4000 lr : 0.000122 wd: 0.000397, loss: 1.09 accuracy: 52.27\n",
      "count : 28 | epoch : 1 batch: 6000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.67\n",
      "count : 28 | epoch : 1 batch: 8000 lr : 0.000122 wd: 0.000397, loss: 1.10 accuracy: 52.21\n",
      "count : 28 | epoch : 1 batch: 10000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.39\n",
      "count : 28 | epoch : 1 batch: 12000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.64\n",
      "count : 28 | epoch : 2 batch: 2000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.60\n",
      "count : 28 | epoch : 2 batch: 4000 lr : 0.000122 wd: 0.000397, loss: 1.09 accuracy: 52.35\n",
      "count : 28 | epoch : 2 batch: 6000 lr : 0.000122 wd: 0.000397, loss: 1.09 accuracy: 52.72\n",
      "count : 28 | epoch : 2 batch: 8000 lr : 0.000122 wd: 0.000397, loss: 1.07 accuracy: 52.97\n",
      "count : 28 | epoch : 2 batch: 10000 lr : 0.000122 wd: 0.000397, loss: 1.08 accuracy: 52.56\n",
      "count : 28 | epoch : 2 batch: 12000 lr : 0.000122 wd: 0.000397, loss: 1.06 accuracy: 52.77\n",
      "count : 29 | epoch : 1 batch: 2000 lr : 0.000072 wd: 0.000502, loss: 1.08 accuracy: 52.57\n",
      "count : 29 | epoch : 1 batch: 4000 lr : 0.000072 wd: 0.000502, loss: 1.08 accuracy: 52.47\n",
      "count : 29 | epoch : 1 batch: 6000 lr : 0.000072 wd: 0.000502, loss: 1.07 accuracy: 52.71\n",
      "count : 29 | epoch : 1 batch: 8000 lr : 0.000072 wd: 0.000502, loss: 1.06 accuracy: 52.73\n",
      "count : 29 | epoch : 1 batch: 10000 lr : 0.000072 wd: 0.000502, loss: 1.09 accuracy: 52.78\n",
      "count : 29 | epoch : 1 batch: 12000 lr : 0.000072 wd: 0.000502, loss: 1.06 accuracy: 52.56\n",
      "count : 29 | epoch : 2 batch: 2000 lr : 0.000072 wd: 0.000502, loss: 1.06 accuracy: 52.49\n",
      "count : 29 | epoch : 2 batch: 4000 lr : 0.000072 wd: 0.000502, loss: 1.05 accuracy: 52.72\n",
      "count : 29 | epoch : 2 batch: 6000 lr : 0.000072 wd: 0.000502, loss: 1.08 accuracy: 52.60\n",
      "count : 29 | epoch : 2 batch: 8000 lr : 0.000072 wd: 0.000502, loss: 1.09 accuracy: 52.76\n",
      "count : 29 | epoch : 2 batch: 10000 lr : 0.000072 wd: 0.000502, loss: 1.08 accuracy: 52.73\n",
      "count : 29 | epoch : 2 batch: 12000 lr : 0.000072 wd: 0.000502, loss: 1.08 accuracy: 52.52\n",
      "count : 30 | epoch : 1 batch: 2000 lr : 0.000069 wd: 0.000512, loss: 1.08 accuracy: 52.70\n",
      "count : 30 | epoch : 1 batch: 4000 lr : 0.000069 wd: 0.000512, loss: 1.09 accuracy: 52.78\n",
      "count : 30 | epoch : 1 batch: 6000 lr : 0.000069 wd: 0.000512, loss: 1.05 accuracy: 52.80\n",
      "count : 30 | epoch : 1 batch: 8000 lr : 0.000069 wd: 0.000512, loss: 1.05 accuracy: 52.73\n",
      "count : 30 | epoch : 1 batch: 10000 lr : 0.000069 wd: 0.000512, loss: 1.09 accuracy: 52.67\n",
      "count : 30 | epoch : 1 batch: 12000 lr : 0.000069 wd: 0.000512, loss: 1.06 accuracy: 52.66\n",
      "count : 30 | epoch : 2 batch: 2000 lr : 0.000069 wd: 0.000512, loss: 1.08 accuracy: 52.60\n",
      "count : 30 | epoch : 2 batch: 4000 lr : 0.000069 wd: 0.000512, loss: 1.06 accuracy: 52.75\n",
      "count : 30 | epoch : 2 batch: 6000 lr : 0.000069 wd: 0.000512, loss: 1.06 accuracy: 52.37\n",
      "count : 30 | epoch : 2 batch: 8000 lr : 0.000069 wd: 0.000512, loss: 1.07 accuracy: 52.48\n",
      "count : 30 | epoch : 2 batch: 10000 lr : 0.000069 wd: 0.000512, loss: 1.09 accuracy: 52.70\n",
      "count : 30 | epoch : 2 batch: 12000 lr : 0.000069 wd: 0.000512, loss: 1.06 accuracy: 52.79\n",
      "count : 31 | epoch : 1 batch: 2000 lr : 0.000633 wd: 0.000006, loss: 1.09 accuracy: 51.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 31 | epoch : 1 batch: 4000 lr : 0.000633 wd: 0.000006, loss: 1.09 accuracy: 52.13\n",
      "count : 31 | epoch : 1 batch: 6000 lr : 0.000633 wd: 0.000006, loss: 1.13 accuracy: 51.92\n",
      "count : 31 | epoch : 1 batch: 8000 lr : 0.000633 wd: 0.000006, loss: 1.10 accuracy: 51.81\n",
      "count : 31 | epoch : 1 batch: 10000 lr : 0.000633 wd: 0.000006, loss: 1.10 accuracy: 51.97\n",
      "count : 31 | epoch : 1 batch: 12000 lr : 0.000633 wd: 0.000006, loss: 1.12 accuracy: 52.50\n",
      "count : 31 | epoch : 2 batch: 2000 lr : 0.000633 wd: 0.000006, loss: 1.06 accuracy: 51.89\n",
      "count : 31 | epoch : 2 batch: 4000 lr : 0.000633 wd: 0.000006, loss: 1.09 accuracy: 51.83\n",
      "count : 31 | epoch : 2 batch: 6000 lr : 0.000633 wd: 0.000006, loss: 1.11 accuracy: 52.11\n",
      "count : 31 | epoch : 2 batch: 8000 lr : 0.000633 wd: 0.000006, loss: 1.10 accuracy: 51.73\n",
      "count : 31 | epoch : 2 batch: 10000 lr : 0.000633 wd: 0.000006, loss: 1.10 accuracy: 51.91\n",
      "count : 31 | epoch : 2 batch: 12000 lr : 0.000633 wd: 0.000006, loss: 1.10 accuracy: 52.30\n",
      "count : 32 | epoch : 1 batch: 2000 lr : 0.000821 wd: 0.000040, loss: 1.06 accuracy: 52.50\n",
      "count : 32 | epoch : 1 batch: 4000 lr : 0.000821 wd: 0.000040, loss: 1.10 accuracy: 51.82\n",
      "count : 32 | epoch : 1 batch: 6000 lr : 0.000821 wd: 0.000040, loss: 1.09 accuracy: 51.51\n",
      "count : 32 | epoch : 1 batch: 8000 lr : 0.000821 wd: 0.000040, loss: 1.11 accuracy: 51.86\n",
      "count : 32 | epoch : 1 batch: 10000 lr : 0.000821 wd: 0.000040, loss: 1.10 accuracy: 51.79\n",
      "count : 32 | epoch : 1 batch: 12000 lr : 0.000821 wd: 0.000040, loss: 1.11 accuracy: 51.71\n",
      "count : 32 | epoch : 2 batch: 2000 lr : 0.000821 wd: 0.000040, loss: 1.07 accuracy: 52.24\n",
      "count : 32 | epoch : 2 batch: 4000 lr : 0.000821 wd: 0.000040, loss: 1.07 accuracy: 51.70\n",
      "count : 32 | epoch : 2 batch: 6000 lr : 0.000821 wd: 0.000040, loss: 1.07 accuracy: 51.92\n",
      "count : 32 | epoch : 2 batch: 8000 lr : 0.000821 wd: 0.000040, loss: 1.08 accuracy: 51.72\n",
      "count : 32 | epoch : 2 batch: 10000 lr : 0.000821 wd: 0.000040, loss: 1.10 accuracy: 51.06\n",
      "count : 32 | epoch : 2 batch: 12000 lr : 0.000821 wd: 0.000040, loss: 1.10 accuracy: 51.03\n",
      "count : 33 | epoch : 1 batch: 2000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.17\n",
      "count : 33 | epoch : 1 batch: 4000 lr : 0.000307 wd: 0.000458, loss: 1.05 accuracy: 52.36\n",
      "count : 33 | epoch : 1 batch: 6000 lr : 0.000307 wd: 0.000458, loss: 1.04 accuracy: 52.95\n",
      "count : 33 | epoch : 1 batch: 8000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.36\n",
      "count : 33 | epoch : 1 batch: 10000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.76\n",
      "count : 33 | epoch : 1 batch: 12000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.33\n",
      "count : 33 | epoch : 2 batch: 2000 lr : 0.000307 wd: 0.000458, loss: 1.02 accuracy: 52.47\n",
      "count : 33 | epoch : 2 batch: 4000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.55\n",
      "count : 33 | epoch : 2 batch: 6000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.40\n",
      "count : 33 | epoch : 2 batch: 8000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.38\n",
      "count : 33 | epoch : 2 batch: 10000 lr : 0.000307 wd: 0.000458, loss: 1.02 accuracy: 52.50\n",
      "count : 33 | epoch : 2 batch: 12000 lr : 0.000307 wd: 0.000458, loss: 1.03 accuracy: 52.24\n",
      "count : 34 | epoch : 1 batch: 2000 lr : 0.000163 wd: 0.000001, loss: 1.01 accuracy: 52.54\n",
      "count : 34 | epoch : 1 batch: 4000 lr : 0.000163 wd: 0.000001, loss: 1.00 accuracy: 52.73\n",
      "count : 34 | epoch : 1 batch: 6000 lr : 0.000163 wd: 0.000001, loss: 1.01 accuracy: 52.52\n",
      "count : 34 | epoch : 1 batch: 8000 lr : 0.000163 wd: 0.000001, loss: 1.02 accuracy: 52.55\n",
      "count : 34 | epoch : 1 batch: 10000 lr : 0.000163 wd: 0.000001, loss: 1.02 accuracy: 52.44\n",
      "count : 34 | epoch : 1 batch: 12000 lr : 0.000163 wd: 0.000001, loss: 1.02 accuracy: 52.34\n",
      "count : 34 | epoch : 2 batch: 2000 lr : 0.000163 wd: 0.000001, loss: 1.00 accuracy: 52.60\n",
      "count : 34 | epoch : 2 batch: 4000 lr : 0.000163 wd: 0.000001, loss: 1.01 accuracy: 52.61\n",
      "count : 34 | epoch : 2 batch: 6000 lr : 0.000163 wd: 0.000001, loss: 1.00 accuracy: 52.56\n",
      "count : 34 | epoch : 2 batch: 8000 lr : 0.000163 wd: 0.000001, loss: 1.01 accuracy: 52.55\n",
      "count : 34 | epoch : 2 batch: 10000 lr : 0.000163 wd: 0.000001, loss: 1.00 accuracy: 52.41\n",
      "count : 34 | epoch : 2 batch: 12000 lr : 0.000163 wd: 0.000001, loss: 1.02 accuracy: 52.85\n",
      "count : 35 | epoch : 1 batch: 2000 lr : 0.000106 wd: 0.000051, loss: 1.00 accuracy: 52.49\n",
      "count : 35 | epoch : 1 batch: 4000 lr : 0.000106 wd: 0.000051, loss: 1.01 accuracy: 52.68\n",
      "count : 35 | epoch : 1 batch: 6000 lr : 0.000106 wd: 0.000051, loss: 0.99 accuracy: 52.61\n",
      "count : 35 | epoch : 1 batch: 8000 lr : 0.000106 wd: 0.000051, loss: 0.99 accuracy: 52.57\n",
      "count : 35 | epoch : 1 batch: 10000 lr : 0.000106 wd: 0.000051, loss: 1.00 accuracy: 52.59\n",
      "count : 35 | epoch : 1 batch: 12000 lr : 0.000106 wd: 0.000051, loss: 1.01 accuracy: 52.65\n",
      "count : 35 | epoch : 2 batch: 2000 lr : 0.000106 wd: 0.000051, loss: 1.00 accuracy: 52.63\n",
      "count : 35 | epoch : 2 batch: 4000 lr : 0.000106 wd: 0.000051, loss: 1.01 accuracy: 52.71\n",
      "count : 35 | epoch : 2 batch: 6000 lr : 0.000106 wd: 0.000051, loss: 1.01 accuracy: 52.84\n",
      "count : 35 | epoch : 2 batch: 8000 lr : 0.000106 wd: 0.000051, loss: 0.99 accuracy: 52.68\n",
      "count : 35 | epoch : 2 batch: 10000 lr : 0.000106 wd: 0.000051, loss: 1.00 accuracy: 52.62\n",
      "count : 35 | epoch : 2 batch: 12000 lr : 0.000106 wd: 0.000051, loss: 0.99 accuracy: 52.84\n",
      "count : 36 | epoch : 1 batch: 2000 lr : 0.000487 wd: 0.000012, loss: 1.00 accuracy: 52.34\n",
      "count : 36 | epoch : 1 batch: 4000 lr : 0.000487 wd: 0.000012, loss: 1.04 accuracy: 52.13\n",
      "count : 36 | epoch : 1 batch: 6000 lr : 0.000487 wd: 0.000012, loss: 1.02 accuracy: 52.23\n",
      "count : 36 | epoch : 1 batch: 8000 lr : 0.000487 wd: 0.000012, loss: 1.04 accuracy: 52.23\n",
      "count : 36 | epoch : 1 batch: 10000 lr : 0.000487 wd: 0.000012, loss: 1.04 accuracy: 52.31\n",
      "count : 36 | epoch : 1 batch: 12000 lr : 0.000487 wd: 0.000012, loss: 1.01 accuracy: 52.76\n",
      "count : 36 | epoch : 2 batch: 2000 lr : 0.000487 wd: 0.000012, loss: 1.01 accuracy: 52.43\n",
      "count : 36 | epoch : 2 batch: 4000 lr : 0.000487 wd: 0.000012, loss: 1.01 accuracy: 52.21\n",
      "count : 36 | epoch : 2 batch: 6000 lr : 0.000487 wd: 0.000012, loss: 1.02 accuracy: 52.15\n",
      "count : 36 | epoch : 2 batch: 8000 lr : 0.000487 wd: 0.000012, loss: 1.02 accuracy: 52.07\n",
      "count : 36 | epoch : 2 batch: 10000 lr : 0.000487 wd: 0.000012, loss: 1.02 accuracy: 52.21\n",
      "count : 36 | epoch : 2 batch: 12000 lr : 0.000487 wd: 0.000012, loss: 1.04 accuracy: 52.50\n",
      "count : 37 | epoch : 1 batch: 2000 lr : 0.000019 wd: 0.000001, loss: 1.00 accuracy: 52.20\n",
      "count : 37 | epoch : 1 batch: 4000 lr : 0.000019 wd: 0.000001, loss: 0.99 accuracy: 52.24\n",
      "count : 37 | epoch : 1 batch: 6000 lr : 0.000019 wd: 0.000001, loss: 0.98 accuracy: 52.25\n",
      "count : 37 | epoch : 1 batch: 8000 lr : 0.000019 wd: 0.000001, loss: 0.98 accuracy: 52.33\n",
      "count : 37 | epoch : 1 batch: 10000 lr : 0.000019 wd: 0.000001, loss: 0.96 accuracy: 52.45\n",
      "count : 37 | epoch : 1 batch: 12000 lr : 0.000019 wd: 0.000001, loss: 0.98 accuracy: 52.35\n",
      "count : 37 | epoch : 2 batch: 2000 lr : 0.000019 wd: 0.000001, loss: 0.98 accuracy: 52.45\n",
      "count : 37 | epoch : 2 batch: 4000 lr : 0.000019 wd: 0.000001, loss: 0.99 accuracy: 52.55\n",
      "count : 37 | epoch : 2 batch: 6000 lr : 0.000019 wd: 0.000001, loss: 0.96 accuracy: 52.50\n",
      "count : 37 | epoch : 2 batch: 8000 lr : 0.000019 wd: 0.000001, loss: 0.97 accuracy: 52.54\n",
      "count : 37 | epoch : 2 batch: 10000 lr : 0.000019 wd: 0.000001, loss: 0.98 accuracy: 52.45\n",
      "count : 37 | epoch : 2 batch: 12000 lr : 0.000019 wd: 0.000001, loss: 0.97 accuracy: 52.41\n",
      "count : 38 | epoch : 1 batch: 2000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 51.65\n",
      "count : 38 | epoch : 1 batch: 4000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 51.45\n",
      "count : 38 | epoch : 1 batch: 6000 lr : 0.000659 wd: 0.000286, loss: 1.04 accuracy: 51.86\n",
      "count : 38 | epoch : 1 batch: 8000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 51.80\n",
      "count : 38 | epoch : 1 batch: 10000 lr : 0.000659 wd: 0.000286, loss: 1.03 accuracy: 51.73\n",
      "count : 38 | epoch : 1 batch: 12000 lr : 0.000659 wd: 0.000286, loss: 1.03 accuracy: 52.32\n",
      "count : 38 | epoch : 2 batch: 2000 lr : 0.000659 wd: 0.000286, loss: 1.00 accuracy: 52.23\n",
      "count : 38 | epoch : 2 batch: 4000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 51.99\n",
      "count : 38 | epoch : 2 batch: 6000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 51.94\n",
      "count : 38 | epoch : 2 batch: 8000 lr : 0.000659 wd: 0.000286, loss: 1.02 accuracy: 52.19\n",
      "count : 38 | epoch : 2 batch: 10000 lr : 0.000659 wd: 0.000286, loss: 1.04 accuracy: 52.01\n",
      "count : 38 | epoch : 2 batch: 12000 lr : 0.000659 wd: 0.000286, loss: 1.01 accuracy: 52.12\n",
      "count : 39 | epoch : 1 batch: 2000 lr : 0.000112 wd: 0.000275, loss: 0.97 accuracy: 52.36\n",
      "count : 39 | epoch : 1 batch: 4000 lr : 0.000112 wd: 0.000275, loss: 0.95 accuracy: 52.13\n",
      "count : 39 | epoch : 1 batch: 6000 lr : 0.000112 wd: 0.000275, loss: 0.98 accuracy: 52.54\n",
      "count : 39 | epoch : 1 batch: 8000 lr : 0.000112 wd: 0.000275, loss: 0.97 accuracy: 52.44\n",
      "count : 39 | epoch : 1 batch: 10000 lr : 0.000112 wd: 0.000275, loss: 0.97 accuracy: 52.48\n",
      "count : 39 | epoch : 1 batch: 12000 lr : 0.000112 wd: 0.000275, loss: 0.97 accuracy: 52.52\n",
      "count : 39 | epoch : 2 batch: 2000 lr : 0.000112 wd: 0.000275, loss: 0.96 accuracy: 52.63\n",
      "count : 39 | epoch : 2 batch: 4000 lr : 0.000112 wd: 0.000275, loss: 0.96 accuracy: 52.56\n",
      "count : 39 | epoch : 2 batch: 6000 lr : 0.000112 wd: 0.000275, loss: 0.98 accuracy: 52.38\n",
      "count : 39 | epoch : 2 batch: 8000 lr : 0.000112 wd: 0.000275, loss: 0.94 accuracy: 52.35\n",
      "count : 39 | epoch : 2 batch: 10000 lr : 0.000112 wd: 0.000275, loss: 0.96 accuracy: 52.29\n",
      "count : 39 | epoch : 2 batch: 12000 lr : 0.000112 wd: 0.000275, loss: 0.96 accuracy: 52.62\n",
      "count : 40 | epoch : 1 batch: 2000 lr : 0.000025 wd: 0.000118, loss: 0.96 accuracy: 52.54\n",
      "count : 40 | epoch : 1 batch: 4000 lr : 0.000025 wd: 0.000118, loss: 0.96 accuracy: 52.41\n",
      "count : 40 | epoch : 1 batch: 6000 lr : 0.000025 wd: 0.000118, loss: 0.94 accuracy: 52.44\n",
      "count : 40 | epoch : 1 batch: 8000 lr : 0.000025 wd: 0.000118, loss: 0.95 accuracy: 52.48\n",
      "count : 40 | epoch : 1 batch: 10000 lr : 0.000025 wd: 0.000118, loss: 0.95 accuracy: 52.43\n",
      "count : 40 | epoch : 1 batch: 12000 lr : 0.000025 wd: 0.000118, loss: 0.96 accuracy: 52.31\n",
      "count : 40 | epoch : 2 batch: 2000 lr : 0.000025 wd: 0.000118, loss: 0.94 accuracy: 52.44\n",
      "count : 40 | epoch : 2 batch: 4000 lr : 0.000025 wd: 0.000118, loss: 0.95 accuracy: 52.54\n",
      "count : 40 | epoch : 2 batch: 6000 lr : 0.000025 wd: 0.000118, loss: 0.94 accuracy: 52.53\n",
      "count : 40 | epoch : 2 batch: 8000 lr : 0.000025 wd: 0.000118, loss: 0.96 accuracy: 52.33\n",
      "count : 40 | epoch : 2 batch: 10000 lr : 0.000025 wd: 0.000118, loss: 0.96 accuracy: 52.35\n",
      "count : 40 | epoch : 2 batch: 12000 lr : 0.000025 wd: 0.000118, loss: 0.95 accuracy: 52.43\n",
      "count : 41 | epoch : 1 batch: 2000 lr : 0.000402 wd: 0.000003, loss: 0.96 accuracy: 52.11\n",
      "count : 41 | epoch : 1 batch: 4000 lr : 0.000402 wd: 0.000003, loss: 0.98 accuracy: 52.05\n",
      "count : 41 | epoch : 1 batch: 6000 lr : 0.000402 wd: 0.000003, loss: 0.98 accuracy: 52.00\n",
      "count : 41 | epoch : 1 batch: 8000 lr : 0.000402 wd: 0.000003, loss: 1.00 accuracy: 52.13\n",
      "count : 41 | epoch : 1 batch: 10000 lr : 0.000402 wd: 0.000003, loss: 0.98 accuracy: 52.21\n",
      "count : 41 | epoch : 1 batch: 12000 lr : 0.000402 wd: 0.000003, loss: 0.99 accuracy: 52.70\n",
      "count : 41 | epoch : 2 batch: 2000 lr : 0.000402 wd: 0.000003, loss: 0.96 accuracy: 51.89\n",
      "count : 41 | epoch : 2 batch: 4000 lr : 0.000402 wd: 0.000003, loss: 0.97 accuracy: 51.98\n",
      "count : 41 | epoch : 2 batch: 6000 lr : 0.000402 wd: 0.000003, loss: 0.97 accuracy: 51.98\n",
      "count : 41 | epoch : 2 batch: 8000 lr : 0.000402 wd: 0.000003, loss: 0.97 accuracy: 52.18\n",
      "count : 41 | epoch : 2 batch: 10000 lr : 0.000402 wd: 0.000003, loss: 0.98 accuracy: 52.78\n",
      "count : 41 | epoch : 2 batch: 12000 lr : 0.000402 wd: 0.000003, loss: 0.99 accuracy: 52.24\n",
      "count : 42 | epoch : 1 batch: 2000 lr : 0.000620 wd: 0.000002, loss: 0.97 accuracy: 51.83\n",
      "count : 42 | epoch : 1 batch: 4000 lr : 0.000620 wd: 0.000002, loss: 0.99 accuracy: 51.80\n",
      "count : 42 | epoch : 1 batch: 6000 lr : 0.000620 wd: 0.000002, loss: 0.99 accuracy: 51.24\n",
      "count : 42 | epoch : 1 batch: 8000 lr : 0.000620 wd: 0.000002, loss: 0.99 accuracy: 52.07\n",
      "count : 42 | epoch : 1 batch: 10000 lr : 0.000620 wd: 0.000002, loss: 0.97 accuracy: 51.96\n",
      "count : 42 | epoch : 1 batch: 12000 lr : 0.000620 wd: 0.000002, loss: 1.00 accuracy: 51.97\n",
      "count : 42 | epoch : 2 batch: 2000 lr : 0.000620 wd: 0.000002, loss: 0.96 accuracy: 52.09\n",
      "count : 42 | epoch : 2 batch: 4000 lr : 0.000620 wd: 0.000002, loss: 0.96 accuracy: 52.08\n",
      "count : 42 | epoch : 2 batch: 6000 lr : 0.000620 wd: 0.000002, loss: 0.99 accuracy: 51.61\n",
      "count : 42 | epoch : 2 batch: 8000 lr : 0.000620 wd: 0.000002, loss: 0.98 accuracy: 51.70\n",
      "count : 42 | epoch : 2 batch: 10000 lr : 0.000620 wd: 0.000002, loss: 0.99 accuracy: 51.56\n",
      "count : 42 | epoch : 2 batch: 12000 lr : 0.000620 wd: 0.000002, loss: 0.98 accuracy: 52.06\n",
      "count : 43 | epoch : 1 batch: 2000 lr : 0.000556 wd: 0.000085, loss: 0.95 accuracy: 52.00\n",
      "count : 43 | epoch : 1 batch: 4000 lr : 0.000556 wd: 0.000085, loss: 0.96 accuracy: 52.05\n",
      "count : 43 | epoch : 1 batch: 6000 lr : 0.000556 wd: 0.000085, loss: 0.96 accuracy: 52.19\n",
      "count : 43 | epoch : 1 batch: 8000 lr : 0.000556 wd: 0.000085, loss: 0.98 accuracy: 51.28\n",
      "count : 43 | epoch : 1 batch: 10000 lr : 0.000556 wd: 0.000085, loss: 0.96 accuracy: 52.24\n",
      "count : 43 | epoch : 1 batch: 12000 lr : 0.000556 wd: 0.000085, loss: 0.99 accuracy: 51.48\n",
      "count : 43 | epoch : 2 batch: 2000 lr : 0.000556 wd: 0.000085, loss: 0.94 accuracy: 51.50\n",
      "count : 43 | epoch : 2 batch: 4000 lr : 0.000556 wd: 0.000085, loss: 0.95 accuracy: 51.34\n",
      "count : 43 | epoch : 2 batch: 6000 lr : 0.000556 wd: 0.000085, loss: 0.96 accuracy: 51.54\n",
      "count : 43 | epoch : 2 batch: 8000 lr : 0.000556 wd: 0.000085, loss: 0.98 accuracy: 51.74\n",
      "count : 43 | epoch : 2 batch: 10000 lr : 0.000556 wd: 0.000085, loss: 0.96 accuracy: 52.12\n",
      "count : 43 | epoch : 2 batch: 12000 lr : 0.000556 wd: 0.000085, loss: 0.95 accuracy: 51.86\n",
      "count : 44 | epoch : 1 batch: 2000 lr : 0.000033 wd: 0.000164, loss: 0.93 accuracy: 52.19\n",
      "count : 44 | epoch : 1 batch: 4000 lr : 0.000033 wd: 0.000164, loss: 0.91 accuracy: 52.14\n",
      "count : 44 | epoch : 1 batch: 6000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.08\n",
      "count : 44 | epoch : 1 batch: 8000 lr : 0.000033 wd: 0.000164, loss: 0.91 accuracy: 52.11\n",
      "count : 44 | epoch : 1 batch: 10000 lr : 0.000033 wd: 0.000164, loss: 0.91 accuracy: 52.24\n",
      "count : 44 | epoch : 1 batch: 12000 lr : 0.000033 wd: 0.000164, loss: 0.91 accuracy: 52.43\n",
      "count : 44 | epoch : 2 batch: 2000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.16\n",
      "count : 44 | epoch : 2 batch: 4000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.36\n",
      "count : 44 | epoch : 2 batch: 6000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.28\n",
      "count : 44 | epoch : 2 batch: 8000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.22\n",
      "count : 44 | epoch : 2 batch: 10000 lr : 0.000033 wd: 0.000164, loss: 0.92 accuracy: 52.30\n",
      "count : 44 | epoch : 2 batch: 12000 lr : 0.000033 wd: 0.000164, loss: 0.90 accuracy: 52.23\n",
      "count : 45 | epoch : 1 batch: 2000 lr : 0.000014 wd: 0.000002, loss: 0.92 accuracy: 52.26\n",
      "count : 45 | epoch : 1 batch: 4000 lr : 0.000014 wd: 0.000002, loss: 0.89 accuracy: 52.17\n",
      "count : 45 | epoch : 1 batch: 6000 lr : 0.000014 wd: 0.000002, loss: 0.91 accuracy: 52.24\n",
      "count : 45 | epoch : 1 batch: 8000 lr : 0.000014 wd: 0.000002, loss: 0.90 accuracy: 52.35\n",
      "count : 45 | epoch : 1 batch: 10000 lr : 0.000014 wd: 0.000002, loss: 0.89 accuracy: 52.22\n",
      "count : 45 | epoch : 1 batch: 12000 lr : 0.000014 wd: 0.000002, loss: 0.90 accuracy: 52.28\n",
      "count : 45 | epoch : 2 batch: 2000 lr : 0.000014 wd: 0.000002, loss: 0.89 accuracy: 52.14\n",
      "count : 45 | epoch : 2 batch: 4000 lr : 0.000014 wd: 0.000002, loss: 0.89 accuracy: 52.13\n",
      "count : 45 | epoch : 2 batch: 6000 lr : 0.000014 wd: 0.000002, loss: 0.90 accuracy: 52.19\n",
      "count : 45 | epoch : 2 batch: 8000 lr : 0.000014 wd: 0.000002, loss: 0.91 accuracy: 52.10\n",
      "count : 45 | epoch : 2 batch: 10000 lr : 0.000014 wd: 0.000002, loss: 0.89 accuracy: 52.22\n",
      "count : 45 | epoch : 2 batch: 12000 lr : 0.000014 wd: 0.000002, loss: 0.91 accuracy: 52.26\n",
      "count : 46 | epoch : 1 batch: 2000 lr : 0.000662 wd: 0.000005, loss: 0.95 accuracy: 51.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 46 | epoch : 1 batch: 4000 lr : 0.000662 wd: 0.000005, loss: 0.96 accuracy: 51.68\n",
      "count : 46 | epoch : 1 batch: 6000 lr : 0.000662 wd: 0.000005, loss: 0.95 accuracy: 52.31\n",
      "count : 46 | epoch : 1 batch: 8000 lr : 0.000662 wd: 0.000005, loss: 0.96 accuracy: 51.99\n",
      "count : 46 | epoch : 1 batch: 10000 lr : 0.000662 wd: 0.000005, loss: 0.97 accuracy: 51.65\n",
      "count : 46 | epoch : 1 batch: 12000 lr : 0.000662 wd: 0.000005, loss: 0.96 accuracy: 51.71\n",
      "count : 46 | epoch : 2 batch: 2000 lr : 0.000662 wd: 0.000005, loss: 0.94 accuracy: 51.80\n",
      "count : 46 | epoch : 2 batch: 4000 lr : 0.000662 wd: 0.000005, loss: 0.94 accuracy: 51.10\n",
      "count : 46 | epoch : 2 batch: 6000 lr : 0.000662 wd: 0.000005, loss: 0.96 accuracy: 51.59\n",
      "count : 46 | epoch : 2 batch: 8000 lr : 0.000662 wd: 0.000005, loss: 0.93 accuracy: 51.91\n",
      "count : 46 | epoch : 2 batch: 10000 lr : 0.000662 wd: 0.000005, loss: 0.97 accuracy: 51.53\n",
      "count : 46 | epoch : 2 batch: 12000 lr : 0.000662 wd: 0.000005, loss: 0.96 accuracy: 51.32\n",
      "count : 47 | epoch : 1 batch: 2000 lr : 0.000116 wd: 0.000029, loss: 0.90 accuracy: 51.96\n",
      "count : 47 | epoch : 1 batch: 4000 lr : 0.000116 wd: 0.000029, loss: 0.89 accuracy: 51.90\n",
      "count : 47 | epoch : 1 batch: 6000 lr : 0.000116 wd: 0.000029, loss: 0.88 accuracy: 51.96\n",
      "count : 47 | epoch : 1 batch: 8000 lr : 0.000116 wd: 0.000029, loss: 0.89 accuracy: 52.13\n",
      "count : 47 | epoch : 1 batch: 10000 lr : 0.000116 wd: 0.000029, loss: 0.90 accuracy: 51.95\n",
      "count : 47 | epoch : 1 batch: 12000 lr : 0.000116 wd: 0.000029, loss: 0.90 accuracy: 52.33\n",
      "count : 47 | epoch : 2 batch: 2000 lr : 0.000116 wd: 0.000029, loss: 0.88 accuracy: 52.26\n",
      "count : 47 | epoch : 2 batch: 4000 lr : 0.000116 wd: 0.000029, loss: 0.89 accuracy: 52.07\n",
      "count : 47 | epoch : 2 batch: 6000 lr : 0.000116 wd: 0.000029, loss: 0.88 accuracy: 52.08\n",
      "count : 47 | epoch : 2 batch: 8000 lr : 0.000116 wd: 0.000029, loss: 0.90 accuracy: 52.00\n",
      "count : 47 | epoch : 2 batch: 10000 lr : 0.000116 wd: 0.000029, loss: 0.89 accuracy: 52.04\n",
      "count : 47 | epoch : 2 batch: 12000 lr : 0.000116 wd: 0.000029, loss: 0.89 accuracy: 52.24\n",
      "count : 48 | epoch : 1 batch: 2000 lr : 0.000187 wd: 0.000526, loss: 0.87 accuracy: 51.99\n",
      "count : 48 | epoch : 1 batch: 4000 lr : 0.000187 wd: 0.000526, loss: 0.87 accuracy: 52.19\n",
      "count : 48 | epoch : 1 batch: 6000 lr : 0.000187 wd: 0.000526, loss: 0.89 accuracy: 52.18\n",
      "count : 48 | epoch : 1 batch: 8000 lr : 0.000187 wd: 0.000526, loss: 0.90 accuracy: 52.17\n",
      "count : 48 | epoch : 1 batch: 10000 lr : 0.000187 wd: 0.000526, loss: 0.91 accuracy: 51.98\n",
      "count : 48 | epoch : 1 batch: 12000 lr : 0.000187 wd: 0.000526, loss: 0.90 accuracy: 52.14\n",
      "count : 48 | epoch : 2 batch: 2000 lr : 0.000187 wd: 0.000526, loss: 0.88 accuracy: 51.65\n",
      "count : 48 | epoch : 2 batch: 4000 lr : 0.000187 wd: 0.000526, loss: 0.87 accuracy: 52.14\n",
      "count : 48 | epoch : 2 batch: 6000 lr : 0.000187 wd: 0.000526, loss: 0.89 accuracy: 52.11\n",
      "count : 48 | epoch : 2 batch: 8000 lr : 0.000187 wd: 0.000526, loss: 0.91 accuracy: 52.04\n",
      "count : 48 | epoch : 2 batch: 10000 lr : 0.000187 wd: 0.000526, loss: 0.89 accuracy: 52.16\n",
      "count : 48 | epoch : 2 batch: 12000 lr : 0.000187 wd: 0.000526, loss: 0.90 accuracy: 51.90\n",
      "count : 49 | epoch : 1 batch: 2000 lr : 0.000139 wd: 0.000267, loss: 0.87 accuracy: 52.27\n",
      "count : 49 | epoch : 1 batch: 4000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.17\n",
      "count : 49 | epoch : 1 batch: 6000 lr : 0.000139 wd: 0.000267, loss: 0.90 accuracy: 52.17\n",
      "count : 49 | epoch : 1 batch: 8000 lr : 0.000139 wd: 0.000267, loss: 0.89 accuracy: 52.27\n",
      "count : 49 | epoch : 1 batch: 10000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.28\n",
      "count : 49 | epoch : 1 batch: 12000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.22\n",
      "count : 49 | epoch : 2 batch: 2000 lr : 0.000139 wd: 0.000267, loss: 0.86 accuracy: 52.23\n",
      "count : 49 | epoch : 2 batch: 4000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 51.99\n",
      "count : 49 | epoch : 2 batch: 6000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.13\n",
      "count : 49 | epoch : 2 batch: 8000 lr : 0.000139 wd: 0.000267, loss: 0.89 accuracy: 52.03\n",
      "count : 49 | epoch : 2 batch: 10000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.19\n",
      "count : 49 | epoch : 2 batch: 12000 lr : 0.000139 wd: 0.000267, loss: 0.88 accuracy: 52.16\n",
      "count : 50 | epoch : 1 batch: 2000 lr : 0.000121 wd: 0.000007, loss: 0.87 accuracy: 51.94\n",
      "count : 50 | epoch : 1 batch: 4000 lr : 0.000121 wd: 0.000007, loss: 0.88 accuracy: 52.22\n",
      "count : 50 | epoch : 1 batch: 6000 lr : 0.000121 wd: 0.000007, loss: 0.87 accuracy: 51.89\n",
      "count : 50 | epoch : 1 batch: 8000 lr : 0.000121 wd: 0.000007, loss: 0.90 accuracy: 51.99\n",
      "count : 50 | epoch : 1 batch: 10000 lr : 0.000121 wd: 0.000007, loss: 0.88 accuracy: 52.11\n",
      "count : 50 | epoch : 1 batch: 12000 lr : 0.000121 wd: 0.000007, loss: 0.88 accuracy: 51.78\n",
      "count : 50 | epoch : 2 batch: 2000 lr : 0.000121 wd: 0.000007, loss: 0.86 accuracy: 51.87\n",
      "count : 50 | epoch : 2 batch: 4000 lr : 0.000121 wd: 0.000007, loss: 0.89 accuracy: 51.83\n",
      "count : 50 | epoch : 2 batch: 6000 lr : 0.000121 wd: 0.000007, loss: 0.86 accuracy: 51.81\n",
      "count : 50 | epoch : 2 batch: 8000 lr : 0.000121 wd: 0.000007, loss: 0.87 accuracy: 51.93\n",
      "count : 50 | epoch : 2 batch: 10000 lr : 0.000121 wd: 0.000007, loss: 0.88 accuracy: 52.19\n",
      "count : 50 | epoch : 2 batch: 12000 lr : 0.000121 wd: 0.000007, loss: 0.88 accuracy: 52.17\n",
      "count : 51 | epoch : 1 batch: 2000 lr : 0.000313 wd: 0.000002, loss: 0.87 accuracy: 51.74\n",
      "count : 51 | epoch : 1 batch: 4000 lr : 0.000313 wd: 0.000002, loss: 0.88 accuracy: 51.94\n",
      "count : 51 | epoch : 1 batch: 6000 lr : 0.000313 wd: 0.000002, loss: 0.89 accuracy: 51.65\n",
      "count : 51 | epoch : 1 batch: 8000 lr : 0.000313 wd: 0.000002, loss: 0.90 accuracy: 51.75\n",
      "count : 51 | epoch : 1 batch: 10000 lr : 0.000313 wd: 0.000002, loss: 0.90 accuracy: 51.86\n",
      "count : 51 | epoch : 1 batch: 12000 lr : 0.000313 wd: 0.000002, loss: 0.89 accuracy: 51.77\n",
      "count : 51 | epoch : 2 batch: 2000 lr : 0.000313 wd: 0.000002, loss: 0.87 accuracy: 51.95\n",
      "count : 51 | epoch : 2 batch: 4000 lr : 0.000313 wd: 0.000002, loss: 0.88 accuracy: 52.05\n",
      "count : 51 | epoch : 2 batch: 6000 lr : 0.000313 wd: 0.000002, loss: 0.89 accuracy: 51.73\n",
      "count : 51 | epoch : 2 batch: 8000 lr : 0.000313 wd: 0.000002, loss: 0.89 accuracy: 52.02\n",
      "count : 51 | epoch : 2 batch: 10000 lr : 0.000313 wd: 0.000002, loss: 0.90 accuracy: 51.94\n",
      "count : 51 | epoch : 2 batch: 12000 lr : 0.000313 wd: 0.000002, loss: 0.90 accuracy: 52.19\n",
      "count : 52 | epoch : 1 batch: 2000 lr : 0.000423 wd: 0.000058, loss: 0.88 accuracy: 51.81\n",
      "count : 52 | epoch : 1 batch: 4000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.78\n",
      "count : 52 | epoch : 1 batch: 6000 lr : 0.000423 wd: 0.000058, loss: 0.91 accuracy: 51.29\n",
      "count : 52 | epoch : 1 batch: 8000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.76\n",
      "count : 52 | epoch : 1 batch: 10000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.96\n",
      "count : 52 | epoch : 1 batch: 12000 lr : 0.000423 wd: 0.000058, loss: 0.91 accuracy: 51.45\n",
      "count : 52 | epoch : 2 batch: 2000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.40\n",
      "count : 52 | epoch : 2 batch: 4000 lr : 0.000423 wd: 0.000058, loss: 0.87 accuracy: 51.33\n",
      "count : 52 | epoch : 2 batch: 6000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 52.09\n",
      "count : 52 | epoch : 2 batch: 8000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 52.17\n",
      "count : 52 | epoch : 2 batch: 10000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.91\n",
      "count : 52 | epoch : 2 batch: 12000 lr : 0.000423 wd: 0.000058, loss: 0.89 accuracy: 51.30\n",
      "count : 53 | epoch : 1 batch: 2000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 51.60\n",
      "count : 53 | epoch : 1 batch: 4000 lr : 0.000150 wd: 0.000060, loss: 0.85 accuracy: 51.69\n",
      "count : 53 | epoch : 1 batch: 6000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 52.01\n",
      "count : 53 | epoch : 1 batch: 8000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 51.50\n",
      "count : 53 | epoch : 1 batch: 10000 lr : 0.000150 wd: 0.000060, loss: 0.87 accuracy: 51.61\n",
      "count : 53 | epoch : 1 batch: 12000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 51.82\n",
      "count : 53 | epoch : 2 batch: 2000 lr : 0.000150 wd: 0.000060, loss: 0.84 accuracy: 51.80\n",
      "count : 53 | epoch : 2 batch: 4000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 51.64\n",
      "count : 53 | epoch : 2 batch: 6000 lr : 0.000150 wd: 0.000060, loss: 0.87 accuracy: 51.99\n",
      "count : 53 | epoch : 2 batch: 8000 lr : 0.000150 wd: 0.000060, loss: 0.84 accuracy: 51.91\n",
      "count : 53 | epoch : 2 batch: 10000 lr : 0.000150 wd: 0.000060, loss: 0.87 accuracy: 51.81\n",
      "count : 53 | epoch : 2 batch: 12000 lr : 0.000150 wd: 0.000060, loss: 0.86 accuracy: 51.63\n",
      "count : 54 | epoch : 1 batch: 2000 lr : 0.000093 wd: 0.000048, loss: 0.83 accuracy: 51.71\n",
      "count : 54 | epoch : 1 batch: 4000 lr : 0.000093 wd: 0.000048, loss: 0.84 accuracy: 52.03\n",
      "count : 54 | epoch : 1 batch: 6000 lr : 0.000093 wd: 0.000048, loss: 0.86 accuracy: 51.88\n",
      "count : 54 | epoch : 1 batch: 8000 lr : 0.000093 wd: 0.000048, loss: 0.84 accuracy: 52.05\n",
      "count : 54 | epoch : 1 batch: 10000 lr : 0.000093 wd: 0.000048, loss: 0.84 accuracy: 51.99\n",
      "count : 54 | epoch : 1 batch: 12000 lr : 0.000093 wd: 0.000048, loss: 0.86 accuracy: 51.80\n",
      "count : 54 | epoch : 2 batch: 2000 lr : 0.000093 wd: 0.000048, loss: 0.83 accuracy: 52.12\n",
      "count : 54 | epoch : 2 batch: 4000 lr : 0.000093 wd: 0.000048, loss: 0.83 accuracy: 52.05\n",
      "count : 54 | epoch : 2 batch: 6000 lr : 0.000093 wd: 0.000048, loss: 0.83 accuracy: 52.04\n",
      "count : 54 | epoch : 2 batch: 8000 lr : 0.000093 wd: 0.000048, loss: 0.85 accuracy: 51.95\n",
      "count : 54 | epoch : 2 batch: 10000 lr : 0.000093 wd: 0.000048, loss: 0.85 accuracy: 51.97\n",
      "count : 54 | epoch : 2 batch: 12000 lr : 0.000093 wd: 0.000048, loss: 0.86 accuracy: 51.97\n",
      "count : 55 | epoch : 1 batch: 2000 lr : 0.000603 wd: 0.000034, loss: 0.87 accuracy: 51.06\n",
      "count : 55 | epoch : 1 batch: 4000 lr : 0.000603 wd: 0.000034, loss: 0.87 accuracy: 51.31\n",
      "count : 55 | epoch : 1 batch: 6000 lr : 0.000603 wd: 0.000034, loss: 0.90 accuracy: 51.19\n",
      "count : 55 | epoch : 1 batch: 8000 lr : 0.000603 wd: 0.000034, loss: 0.90 accuracy: 51.52\n",
      "count : 55 | epoch : 1 batch: 10000 lr : 0.000603 wd: 0.000034, loss: 0.91 accuracy: 50.97\n",
      "count : 55 | epoch : 1 batch: 12000 lr : 0.000603 wd: 0.000034, loss: 0.92 accuracy: 50.96\n",
      "count : 55 | epoch : 2 batch: 2000 lr : 0.000603 wd: 0.000034, loss: 0.88 accuracy: 51.40\n",
      "count : 55 | epoch : 2 batch: 4000 lr : 0.000603 wd: 0.000034, loss: 0.88 accuracy: 51.57\n",
      "count : 55 | epoch : 2 batch: 6000 lr : 0.000603 wd: 0.000034, loss: 0.89 accuracy: 51.13\n",
      "count : 55 | epoch : 2 batch: 8000 lr : 0.000603 wd: 0.000034, loss: 0.89 accuracy: 51.93\n",
      "count : 55 | epoch : 2 batch: 10000 lr : 0.000603 wd: 0.000034, loss: 0.88 accuracy: 51.23\n",
      "count : 55 | epoch : 2 batch: 12000 lr : 0.000603 wd: 0.000034, loss: 0.90 accuracy: 51.49\n",
      "count : 56 | epoch : 1 batch: 2000 lr : 0.000053 wd: 0.000002, loss: 0.84 accuracy: 51.47\n",
      "count : 56 | epoch : 1 batch: 4000 lr : 0.000053 wd: 0.000002, loss: 0.84 accuracy: 51.65\n",
      "count : 56 | epoch : 1 batch: 6000 lr : 0.000053 wd: 0.000002, loss: 0.82 accuracy: 51.69\n",
      "count : 56 | epoch : 1 batch: 8000 lr : 0.000053 wd: 0.000002, loss: 0.83 accuracy: 51.65\n",
      "count : 56 | epoch : 1 batch: 10000 lr : 0.000053 wd: 0.000002, loss: 0.84 accuracy: 51.87\n",
      "count : 56 | epoch : 1 batch: 12000 lr : 0.000053 wd: 0.000002, loss: 0.84 accuracy: 51.68\n",
      "count : 56 | epoch : 2 batch: 2000 lr : 0.000053 wd: 0.000002, loss: 0.82 accuracy: 51.80\n",
      "count : 56 | epoch : 2 batch: 4000 lr : 0.000053 wd: 0.000002, loss: 0.81 accuracy: 51.83\n",
      "count : 56 | epoch : 2 batch: 6000 lr : 0.000053 wd: 0.000002, loss: 0.83 accuracy: 51.82\n",
      "count : 56 | epoch : 2 batch: 8000 lr : 0.000053 wd: 0.000002, loss: 0.83 accuracy: 51.88\n",
      "count : 56 | epoch : 2 batch: 10000 lr : 0.000053 wd: 0.000002, loss: 0.82 accuracy: 51.77\n",
      "count : 56 | epoch : 2 batch: 12000 lr : 0.000053 wd: 0.000002, loss: 0.83 accuracy: 51.84\n",
      "count : 57 | epoch : 1 batch: 2000 lr : 0.000014 wd: 0.000042, loss: 0.83 accuracy: 51.89\n",
      "count : 57 | epoch : 1 batch: 4000 lr : 0.000014 wd: 0.000042, loss: 0.82 accuracy: 51.92\n",
      "count : 57 | epoch : 1 batch: 6000 lr : 0.000014 wd: 0.000042, loss: 0.82 accuracy: 51.94\n",
      "count : 57 | epoch : 1 batch: 8000 lr : 0.000014 wd: 0.000042, loss: 0.81 accuracy: 51.88\n",
      "count : 57 | epoch : 1 batch: 10000 lr : 0.000014 wd: 0.000042, loss: 0.80 accuracy: 52.02\n",
      "count : 57 | epoch : 1 batch: 12000 lr : 0.000014 wd: 0.000042, loss: 0.82 accuracy: 51.94\n",
      "count : 57 | epoch : 2 batch: 2000 lr : 0.000014 wd: 0.000042, loss: 0.83 accuracy: 51.84\n",
      "count : 57 | epoch : 2 batch: 4000 lr : 0.000014 wd: 0.000042, loss: 0.80 accuracy: 51.92\n",
      "count : 57 | epoch : 2 batch: 6000 lr : 0.000014 wd: 0.000042, loss: 0.81 accuracy: 51.92\n",
      "count : 57 | epoch : 2 batch: 8000 lr : 0.000014 wd: 0.000042, loss: 0.82 accuracy: 51.89\n",
      "count : 57 | epoch : 2 batch: 10000 lr : 0.000014 wd: 0.000042, loss: 0.81 accuracy: 51.88\n",
      "count : 57 | epoch : 2 batch: 12000 lr : 0.000014 wd: 0.000042, loss: 0.83 accuracy: 51.96\n",
      "count : 58 | epoch : 1 batch: 2000 lr : 0.000016 wd: 0.000004, loss: 0.80 accuracy: 51.91\n",
      "count : 58 | epoch : 1 batch: 4000 lr : 0.000016 wd: 0.000004, loss: 0.82 accuracy: 51.77\n",
      "count : 58 | epoch : 1 batch: 6000 lr : 0.000016 wd: 0.000004, loss: 0.83 accuracy: 51.85\n",
      "count : 58 | epoch : 1 batch: 8000 lr : 0.000016 wd: 0.000004, loss: 0.82 accuracy: 51.81\n",
      "count : 58 | epoch : 1 batch: 10000 lr : 0.000016 wd: 0.000004, loss: 0.83 accuracy: 51.95\n",
      "count : 58 | epoch : 1 batch: 12000 lr : 0.000016 wd: 0.000004, loss: 0.81 accuracy: 51.99\n",
      "count : 58 | epoch : 2 batch: 2000 lr : 0.000016 wd: 0.000004, loss: 0.79 accuracy: 51.93\n",
      "count : 58 | epoch : 2 batch: 4000 lr : 0.000016 wd: 0.000004, loss: 0.81 accuracy: 51.87\n",
      "count : 58 | epoch : 2 batch: 6000 lr : 0.000016 wd: 0.000004, loss: 0.82 accuracy: 51.92\n",
      "count : 58 | epoch : 2 batch: 8000 lr : 0.000016 wd: 0.000004, loss: 0.82 accuracy: 51.90\n",
      "count : 58 | epoch : 2 batch: 10000 lr : 0.000016 wd: 0.000004, loss: 0.83 accuracy: 51.95\n",
      "count : 58 | epoch : 2 batch: 12000 lr : 0.000016 wd: 0.000004, loss: 0.82 accuracy: 51.86\n",
      "count : 59 | epoch : 1 batch: 2000 lr : 0.000699 wd: 0.000008, loss: 0.84 accuracy: 50.85\n",
      "count : 59 | epoch : 1 batch: 4000 lr : 0.000699 wd: 0.000008, loss: 0.88 accuracy: 51.40\n",
      "count : 59 | epoch : 1 batch: 6000 lr : 0.000699 wd: 0.000008, loss: 0.90 accuracy: 50.71\n",
      "count : 59 | epoch : 1 batch: 8000 lr : 0.000699 wd: 0.000008, loss: 0.90 accuracy: 51.28\n",
      "count : 59 | epoch : 1 batch: 10000 lr : 0.000699 wd: 0.000008, loss: 0.92 accuracy: 50.51\n",
      "count : 59 | epoch : 1 batch: 12000 lr : 0.000699 wd: 0.000008, loss: 0.89 accuracy: 50.99\n",
      "count : 59 | epoch : 2 batch: 2000 lr : 0.000699 wd: 0.000008, loss: 0.87 accuracy: 50.17\n",
      "count : 59 | epoch : 2 batch: 4000 lr : 0.000699 wd: 0.000008, loss: 0.87 accuracy: 51.14\n",
      "count : 59 | epoch : 2 batch: 6000 lr : 0.000699 wd: 0.000008, loss: 0.89 accuracy: 50.48\n",
      "count : 59 | epoch : 2 batch: 8000 lr : 0.000699 wd: 0.000008, loss: 0.89 accuracy: 51.59\n",
      "count : 59 | epoch : 2 batch: 10000 lr : 0.000699 wd: 0.000008, loss: 0.89 accuracy: 51.31\n",
      "count : 59 | epoch : 2 batch: 12000 lr : 0.000699 wd: 0.000008, loss: 0.90 accuracy: 50.69\n",
      "count : 60 | epoch : 1 batch: 2000 lr : 0.000013 wd: 0.000968, loss: 0.83 accuracy: 51.28\n",
      "count : 60 | epoch : 1 batch: 4000 lr : 0.000013 wd: 0.000968, loss: 0.83 accuracy: 51.28\n",
      "count : 60 | epoch : 1 batch: 6000 lr : 0.000013 wd: 0.000968, loss: 0.82 accuracy: 51.43\n",
      "count : 60 | epoch : 1 batch: 8000 lr : 0.000013 wd: 0.000968, loss: 0.83 accuracy: 51.46\n",
      "count : 60 | epoch : 1 batch: 10000 lr : 0.000013 wd: 0.000968, loss: 0.82 accuracy: 51.68\n",
      "count : 60 | epoch : 1 batch: 12000 lr : 0.000013 wd: 0.000968, loss: 0.82 accuracy: 51.79\n",
      "count : 60 | epoch : 2 batch: 2000 lr : 0.000013 wd: 0.000968, loss: 0.81 accuracy: 51.83\n",
      "count : 60 | epoch : 2 batch: 4000 lr : 0.000013 wd: 0.000968, loss: 0.82 accuracy: 51.91\n",
      "count : 60 | epoch : 2 batch: 6000 lr : 0.000013 wd: 0.000968, loss: 0.81 accuracy: 51.90\n",
      "count : 60 | epoch : 2 batch: 8000 lr : 0.000013 wd: 0.000968, loss: 0.80 accuracy: 51.77\n",
      "count : 60 | epoch : 2 batch: 10000 lr : 0.000013 wd: 0.000968, loss: 0.82 accuracy: 51.78\n",
      "count : 60 | epoch : 2 batch: 12000 lr : 0.000013 wd: 0.000968, loss: 0.80 accuracy: 51.79\n",
      "count : 61 | epoch : 1 batch: 2000 lr : 0.000027 wd: 0.000601, loss: 0.81 accuracy: 51.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 61 | epoch : 1 batch: 4000 lr : 0.000027 wd: 0.000601, loss: 0.81 accuracy: 51.71\n",
      "count : 61 | epoch : 1 batch: 6000 lr : 0.000027 wd: 0.000601, loss: 0.81 accuracy: 51.81\n",
      "count : 61 | epoch : 1 batch: 8000 lr : 0.000027 wd: 0.000601, loss: 0.80 accuracy: 51.73\n",
      "count : 61 | epoch : 1 batch: 10000 lr : 0.000027 wd: 0.000601, loss: 0.79 accuracy: 51.79\n",
      "count : 61 | epoch : 1 batch: 12000 lr : 0.000027 wd: 0.000601, loss: 0.82 accuracy: 51.58\n",
      "count : 61 | epoch : 2 batch: 2000 lr : 0.000027 wd: 0.000601, loss: 0.82 accuracy: 51.70\n",
      "count : 61 | epoch : 2 batch: 4000 lr : 0.000027 wd: 0.000601, loss: 0.80 accuracy: 51.63\n",
      "count : 61 | epoch : 2 batch: 6000 lr : 0.000027 wd: 0.000601, loss: 0.81 accuracy: 51.81\n",
      "count : 61 | epoch : 2 batch: 8000 lr : 0.000027 wd: 0.000601, loss: 0.81 accuracy: 51.56\n",
      "count : 61 | epoch : 2 batch: 10000 lr : 0.000027 wd: 0.000601, loss: 0.79 accuracy: 51.70\n",
      "count : 61 | epoch : 2 batch: 12000 lr : 0.000027 wd: 0.000601, loss: 0.79 accuracy: 51.75\n",
      "count : 62 | epoch : 1 batch: 2000 lr : 0.000560 wd: 0.000011, loss: 0.84 accuracy: 51.56\n",
      "count : 62 | epoch : 1 batch: 4000 lr : 0.000560 wd: 0.000011, loss: 0.86 accuracy: 51.07\n",
      "count : 62 | epoch : 1 batch: 6000 lr : 0.000560 wd: 0.000011, loss: 0.86 accuracy: 51.53\n",
      "count : 62 | epoch : 1 batch: 8000 lr : 0.000560 wd: 0.000011, loss: 0.86 accuracy: 51.01\n",
      "count : 62 | epoch : 1 batch: 10000 lr : 0.000560 wd: 0.000011, loss: 0.87 accuracy: 51.34\n",
      "count : 62 | epoch : 1 batch: 12000 lr : 0.000560 wd: 0.000011, loss: 0.86 accuracy: 51.12\n",
      "count : 62 | epoch : 2 batch: 2000 lr : 0.000560 wd: 0.000011, loss: 0.84 accuracy: 51.40\n",
      "count : 62 | epoch : 2 batch: 4000 lr : 0.000560 wd: 0.000011, loss: 0.84 accuracy: 51.33\n",
      "count : 62 | epoch : 2 batch: 6000 lr : 0.000560 wd: 0.000011, loss: 0.86 accuracy: 51.29\n",
      "count : 62 | epoch : 2 batch: 8000 lr : 0.000560 wd: 0.000011, loss: 0.85 accuracy: 51.30\n",
      "count : 62 | epoch : 2 batch: 10000 lr : 0.000560 wd: 0.000011, loss: 0.85 accuracy: 50.62\n",
      "count : 62 | epoch : 2 batch: 12000 lr : 0.000560 wd: 0.000011, loss: 0.88 accuracy: 51.11\n",
      "count : 63 | epoch : 1 batch: 2000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.41\n",
      "count : 63 | epoch : 1 batch: 4000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.50\n",
      "count : 63 | epoch : 1 batch: 6000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.39\n",
      "count : 63 | epoch : 1 batch: 8000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.41\n",
      "count : 63 | epoch : 1 batch: 10000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.36\n",
      "count : 63 | epoch : 1 batch: 12000 lr : 0.000020 wd: 0.000061, loss: 0.79 accuracy: 51.51\n",
      "count : 63 | epoch : 2 batch: 2000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.46\n",
      "count : 63 | epoch : 2 batch: 4000 lr : 0.000020 wd: 0.000061, loss: 0.79 accuracy: 51.46\n",
      "count : 63 | epoch : 2 batch: 6000 lr : 0.000020 wd: 0.000061, loss: 0.80 accuracy: 51.48\n",
      "count : 63 | epoch : 2 batch: 8000 lr : 0.000020 wd: 0.000061, loss: 0.79 accuracy: 51.46\n",
      "count : 63 | epoch : 2 batch: 10000 lr : 0.000020 wd: 0.000061, loss: 0.79 accuracy: 51.66\n",
      "count : 63 | epoch : 2 batch: 12000 lr : 0.000020 wd: 0.000061, loss: 0.79 accuracy: 51.56\n",
      "count : 64 | epoch : 1 batch: 2000 lr : 0.000496 wd: 0.000002, loss: 0.80 accuracy: 50.94\n",
      "count : 64 | epoch : 1 batch: 4000 lr : 0.000496 wd: 0.000002, loss: 0.83 accuracy: 50.50\n",
      "count : 64 | epoch : 1 batch: 6000 lr : 0.000496 wd: 0.000002, loss: 0.85 accuracy: 51.34\n",
      "count : 64 | epoch : 1 batch: 8000 lr : 0.000496 wd: 0.000002, loss: 0.83 accuracy: 50.83\n",
      "count : 64 | epoch : 1 batch: 10000 lr : 0.000496 wd: 0.000002, loss: 0.86 accuracy: 51.16\n",
      "count : 64 | epoch : 1 batch: 12000 lr : 0.000496 wd: 0.000002, loss: 0.85 accuracy: 51.47\n",
      "count : 64 | epoch : 2 batch: 2000 lr : 0.000496 wd: 0.000002, loss: 0.82 accuracy: 51.14\n",
      "count : 64 | epoch : 2 batch: 4000 lr : 0.000496 wd: 0.000002, loss: 0.82 accuracy: 50.94\n",
      "count : 64 | epoch : 2 batch: 6000 lr : 0.000496 wd: 0.000002, loss: 0.82 accuracy: 51.48\n",
      "count : 64 | epoch : 2 batch: 8000 lr : 0.000496 wd: 0.000002, loss: 0.83 accuracy: 50.89\n",
      "count : 64 | epoch : 2 batch: 10000 lr : 0.000496 wd: 0.000002, loss: 0.84 accuracy: 50.74\n",
      "count : 64 | epoch : 2 batch: 12000 lr : 0.000496 wd: 0.000002, loss: 0.85 accuracy: 50.90\n",
      "count : 65 | epoch : 1 batch: 2000 lr : 0.000217 wd: 0.000016, loss: 0.79 accuracy: 51.24\n",
      "count : 65 | epoch : 1 batch: 4000 lr : 0.000217 wd: 0.000016, loss: 0.79 accuracy: 51.17\n",
      "count : 65 | epoch : 1 batch: 6000 lr : 0.000217 wd: 0.000016, loss: 0.81 accuracy: 51.17\n",
      "count : 65 | epoch : 1 batch: 8000 lr : 0.000217 wd: 0.000016, loss: 0.77 accuracy: 51.69\n",
      "count : 65 | epoch : 1 batch: 10000 lr : 0.000217 wd: 0.000016, loss: 0.81 accuracy: 51.35\n",
      "count : 65 | epoch : 1 batch: 12000 lr : 0.000217 wd: 0.000016, loss: 0.80 accuracy: 51.12\n",
      "count : 65 | epoch : 2 batch: 2000 lr : 0.000217 wd: 0.000016, loss: 0.78 accuracy: 51.29\n",
      "count : 65 | epoch : 2 batch: 4000 lr : 0.000217 wd: 0.000016, loss: 0.78 accuracy: 51.02\n",
      "count : 65 | epoch : 2 batch: 6000 lr : 0.000217 wd: 0.000016, loss: 0.80 accuracy: 51.59\n",
      "count : 65 | epoch : 2 batch: 8000 lr : 0.000217 wd: 0.000016, loss: 0.80 accuracy: 51.44\n",
      "count : 65 | epoch : 2 batch: 10000 lr : 0.000217 wd: 0.000016, loss: 0.80 accuracy: 51.64\n",
      "count : 65 | epoch : 2 batch: 12000 lr : 0.000217 wd: 0.000016, loss: 0.80 accuracy: 50.90\n",
      "count : 66 | epoch : 1 batch: 2000 lr : 0.000043 wd: 0.000012, loss: 0.77 accuracy: 51.41\n",
      "count : 66 | epoch : 1 batch: 4000 lr : 0.000043 wd: 0.000012, loss: 0.76 accuracy: 51.32\n",
      "count : 66 | epoch : 1 batch: 6000 lr : 0.000043 wd: 0.000012, loss: 0.76 accuracy: 51.47\n",
      "count : 66 | epoch : 1 batch: 8000 lr : 0.000043 wd: 0.000012, loss: 0.80 accuracy: 51.60\n",
      "count : 66 | epoch : 1 batch: 10000 lr : 0.000043 wd: 0.000012, loss: 0.77 accuracy: 51.53\n",
      "count : 66 | epoch : 1 batch: 12000 lr : 0.000043 wd: 0.000012, loss: 0.78 accuracy: 51.73\n",
      "count : 66 | epoch : 2 batch: 2000 lr : 0.000043 wd: 0.000012, loss: 0.76 accuracy: 51.51\n",
      "count : 66 | epoch : 2 batch: 4000 lr : 0.000043 wd: 0.000012, loss: 0.76 accuracy: 51.55\n",
      "count : 66 | epoch : 2 batch: 6000 lr : 0.000043 wd: 0.000012, loss: 0.76 accuracy: 51.63\n",
      "count : 66 | epoch : 2 batch: 8000 lr : 0.000043 wd: 0.000012, loss: 0.77 accuracy: 51.49\n",
      "count : 66 | epoch : 2 batch: 10000 lr : 0.000043 wd: 0.000012, loss: 0.78 accuracy: 51.58\n",
      "count : 66 | epoch : 2 batch: 12000 lr : 0.000043 wd: 0.000012, loss: 0.78 accuracy: 51.54\n",
      "count : 67 | epoch : 1 batch: 2000 lr : 0.000156 wd: 0.000005, loss: 0.76 accuracy: 51.70\n",
      "count : 67 | epoch : 1 batch: 4000 lr : 0.000156 wd: 0.000005, loss: 0.77 accuracy: 51.43\n",
      "count : 67 | epoch : 1 batch: 6000 lr : 0.000156 wd: 0.000005, loss: 0.77 accuracy: 51.32\n",
      "count : 67 | epoch : 1 batch: 8000 lr : 0.000156 wd: 0.000005, loss: 0.78 accuracy: 51.27\n",
      "count : 67 | epoch : 1 batch: 10000 lr : 0.000156 wd: 0.000005, loss: 0.80 accuracy: 51.32\n",
      "count : 67 | epoch : 1 batch: 12000 lr : 0.000156 wd: 0.000005, loss: 0.80 accuracy: 51.38\n",
      "count : 67 | epoch : 2 batch: 2000 lr : 0.000156 wd: 0.000005, loss: 0.76 accuracy: 51.08\n",
      "count : 67 | epoch : 2 batch: 4000 lr : 0.000156 wd: 0.000005, loss: 0.76 accuracy: 51.70\n",
      "count : 67 | epoch : 2 batch: 6000 lr : 0.000156 wd: 0.000005, loss: 0.78 accuracy: 51.06\n",
      "count : 67 | epoch : 2 batch: 8000 lr : 0.000156 wd: 0.000005, loss: 0.80 accuracy: 51.17\n",
      "count : 67 | epoch : 2 batch: 10000 lr : 0.000156 wd: 0.000005, loss: 0.78 accuracy: 51.18\n",
      "count : 67 | epoch : 2 batch: 12000 lr : 0.000156 wd: 0.000005, loss: 0.79 accuracy: 51.42\n",
      "count : 68 | epoch : 1 batch: 2000 lr : 0.000878 wd: 0.000198, loss: 0.83 accuracy: 50.68\n",
      "count : 68 | epoch : 1 batch: 4000 lr : 0.000878 wd: 0.000198, loss: 0.87 accuracy: 50.60\n",
      "count : 68 | epoch : 1 batch: 6000 lr : 0.000878 wd: 0.000198, loss: 0.86 accuracy: 50.29\n",
      "count : 68 | epoch : 1 batch: 8000 lr : 0.000878 wd: 0.000198, loss: 0.88 accuracy: 50.15\n",
      "count : 68 | epoch : 1 batch: 10000 lr : 0.000878 wd: 0.000198, loss: 0.86 accuracy: 50.04\n",
      "count : 68 | epoch : 1 batch: 12000 lr : 0.000878 wd: 0.000198, loss: 0.88 accuracy: 50.93\n",
      "count : 68 | epoch : 2 batch: 2000 lr : 0.000878 wd: 0.000198, loss: 0.85 accuracy: 51.19\n",
      "count : 68 | epoch : 2 batch: 4000 lr : 0.000878 wd: 0.000198, loss: 0.85 accuracy: 50.37\n",
      "count : 68 | epoch : 2 batch: 6000 lr : 0.000878 wd: 0.000198, loss: 0.87 accuracy: 50.88\n",
      "count : 68 | epoch : 2 batch: 8000 lr : 0.000878 wd: 0.000198, loss: 0.85 accuracy: 50.40\n",
      "count : 68 | epoch : 2 batch: 10000 lr : 0.000878 wd: 0.000198, loss: 0.87 accuracy: 49.61\n",
      "count : 68 | epoch : 2 batch: 12000 lr : 0.000878 wd: 0.000198, loss: 0.88 accuracy: 50.87\n",
      "count : 69 | epoch : 1 batch: 2000 lr : 0.000184 wd: 0.000002, loss: 0.78 accuracy: 51.52\n",
      "count : 69 | epoch : 1 batch: 4000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.31\n",
      "count : 69 | epoch : 1 batch: 6000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.40\n",
      "count : 69 | epoch : 1 batch: 8000 lr : 0.000184 wd: 0.000002, loss: 0.78 accuracy: 51.16\n",
      "count : 69 | epoch : 1 batch: 10000 lr : 0.000184 wd: 0.000002, loss: 0.79 accuracy: 51.04\n",
      "count : 69 | epoch : 1 batch: 12000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.32\n",
      "count : 69 | epoch : 2 batch: 2000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.32\n",
      "count : 69 | epoch : 2 batch: 4000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.47\n",
      "count : 69 | epoch : 2 batch: 6000 lr : 0.000184 wd: 0.000002, loss: 0.76 accuracy: 51.74\n",
      "count : 69 | epoch : 2 batch: 8000 lr : 0.000184 wd: 0.000002, loss: 0.78 accuracy: 51.65\n",
      "count : 69 | epoch : 2 batch: 10000 lr : 0.000184 wd: 0.000002, loss: 0.75 accuracy: 51.34\n",
      "count : 69 | epoch : 2 batch: 12000 lr : 0.000184 wd: 0.000002, loss: 0.77 accuracy: 51.30\n",
      "count : 70 | epoch : 1 batch: 2000 lr : 0.000057 wd: 0.000001, loss: 0.73 accuracy: 51.27\n",
      "count : 70 | epoch : 1 batch: 4000 lr : 0.000057 wd: 0.000001, loss: 0.74 accuracy: 51.37\n",
      "count : 70 | epoch : 1 batch: 6000 lr : 0.000057 wd: 0.000001, loss: 0.75 accuracy: 51.11\n",
      "count : 70 | epoch : 1 batch: 8000 lr : 0.000057 wd: 0.000001, loss: 0.76 accuracy: 51.28\n",
      "count : 70 | epoch : 1 batch: 10000 lr : 0.000057 wd: 0.000001, loss: 0.75 accuracy: 51.11\n",
      "count : 70 | epoch : 1 batch: 12000 lr : 0.000057 wd: 0.000001, loss: 0.74 accuracy: 51.34\n",
      "count : 70 | epoch : 2 batch: 2000 lr : 0.000057 wd: 0.000001, loss: 0.75 accuracy: 51.21\n",
      "count : 70 | epoch : 2 batch: 4000 lr : 0.000057 wd: 0.000001, loss: 0.74 accuracy: 51.26\n",
      "count : 70 | epoch : 2 batch: 6000 lr : 0.000057 wd: 0.000001, loss: 0.74 accuracy: 51.06\n",
      "count : 70 | epoch : 2 batch: 8000 lr : 0.000057 wd: 0.000001, loss: 0.76 accuracy: 51.13\n",
      "count : 70 | epoch : 2 batch: 10000 lr : 0.000057 wd: 0.000001, loss: 0.73 accuracy: 51.40\n",
      "count : 70 | epoch : 2 batch: 12000 lr : 0.000057 wd: 0.000001, loss: 0.74 accuracy: 51.42\n",
      "count : 71 | epoch : 1 batch: 2000 lr : 0.000024 wd: 0.000003, loss: 0.75 accuracy: 51.21\n",
      "count : 71 | epoch : 1 batch: 4000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.34\n",
      "count : 71 | epoch : 1 batch: 6000 lr : 0.000024 wd: 0.000003, loss: 0.73 accuracy: 51.27\n",
      "count : 71 | epoch : 1 batch: 8000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.33\n",
      "count : 71 | epoch : 1 batch: 10000 lr : 0.000024 wd: 0.000003, loss: 0.75 accuracy: 51.26\n",
      "count : 71 | epoch : 1 batch: 12000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.29\n",
      "count : 71 | epoch : 2 batch: 2000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.36\n",
      "count : 71 | epoch : 2 batch: 4000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.49\n",
      "count : 71 | epoch : 2 batch: 6000 lr : 0.000024 wd: 0.000003, loss: 0.75 accuracy: 51.43\n",
      "count : 71 | epoch : 2 batch: 8000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.23\n",
      "count : 71 | epoch : 2 batch: 10000 lr : 0.000024 wd: 0.000003, loss: 0.72 accuracy: 51.26\n",
      "count : 71 | epoch : 2 batch: 12000 lr : 0.000024 wd: 0.000003, loss: 0.74 accuracy: 51.48\n",
      "count : 72 | epoch : 1 batch: 2000 lr : 0.000016 wd: 0.000030, loss: 0.73 accuracy: 51.32\n",
      "count : 72 | epoch : 1 batch: 4000 lr : 0.000016 wd: 0.000030, loss: 0.74 accuracy: 51.31\n",
      "count : 72 | epoch : 1 batch: 6000 lr : 0.000016 wd: 0.000030, loss: 0.73 accuracy: 51.30\n",
      "count : 72 | epoch : 1 batch: 8000 lr : 0.000016 wd: 0.000030, loss: 0.74 accuracy: 51.38\n",
      "count : 72 | epoch : 1 batch: 10000 lr : 0.000016 wd: 0.000030, loss: 0.73 accuracy: 51.27\n",
      "count : 72 | epoch : 1 batch: 12000 lr : 0.000016 wd: 0.000030, loss: 0.75 accuracy: 51.37\n",
      "count : 72 | epoch : 2 batch: 2000 lr : 0.000016 wd: 0.000030, loss: 0.73 accuracy: 51.23\n",
      "count : 72 | epoch : 2 batch: 4000 lr : 0.000016 wd: 0.000030, loss: 0.75 accuracy: 51.29\n",
      "count : 72 | epoch : 2 batch: 6000 lr : 0.000016 wd: 0.000030, loss: 0.75 accuracy: 51.34\n",
      "count : 72 | epoch : 2 batch: 8000 lr : 0.000016 wd: 0.000030, loss: 0.72 accuracy: 51.23\n",
      "count : 72 | epoch : 2 batch: 10000 lr : 0.000016 wd: 0.000030, loss: 0.74 accuracy: 51.33\n",
      "count : 72 | epoch : 2 batch: 12000 lr : 0.000016 wd: 0.000030, loss: 0.73 accuracy: 51.24\n",
      "count : 73 | epoch : 1 batch: 2000 lr : 0.000029 wd: 0.000002, loss: 0.73 accuracy: 51.29\n",
      "count : 73 | epoch : 1 batch: 4000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.23\n",
      "count : 73 | epoch : 1 batch: 6000 lr : 0.000029 wd: 0.000002, loss: 0.76 accuracy: 51.25\n",
      "count : 73 | epoch : 1 batch: 8000 lr : 0.000029 wd: 0.000002, loss: 0.73 accuracy: 51.31\n",
      "count : 73 | epoch : 1 batch: 10000 lr : 0.000029 wd: 0.000002, loss: 0.73 accuracy: 51.37\n",
      "count : 73 | epoch : 1 batch: 12000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.26\n",
      "count : 73 | epoch : 2 batch: 2000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.29\n",
      "count : 73 | epoch : 2 batch: 4000 lr : 0.000029 wd: 0.000002, loss: 0.73 accuracy: 51.21\n",
      "count : 73 | epoch : 2 batch: 6000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.26\n",
      "count : 73 | epoch : 2 batch: 8000 lr : 0.000029 wd: 0.000002, loss: 0.73 accuracy: 51.24\n",
      "count : 73 | epoch : 2 batch: 10000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.35\n",
      "count : 73 | epoch : 2 batch: 12000 lr : 0.000029 wd: 0.000002, loss: 0.74 accuracy: 51.20\n",
      "count : 74 | epoch : 1 batch: 2000 lr : 0.000042 wd: 0.000500, loss: 0.74 accuracy: 51.37\n",
      "count : 74 | epoch : 1 batch: 4000 lr : 0.000042 wd: 0.000500, loss: 0.74 accuracy: 51.38\n",
      "count : 74 | epoch : 1 batch: 6000 lr : 0.000042 wd: 0.000500, loss: 0.76 accuracy: 51.40\n",
      "count : 74 | epoch : 1 batch: 8000 lr : 0.000042 wd: 0.000500, loss: 0.73 accuracy: 51.25\n",
      "count : 74 | epoch : 1 batch: 10000 lr : 0.000042 wd: 0.000500, loss: 0.73 accuracy: 51.25\n",
      "count : 74 | epoch : 1 batch: 12000 lr : 0.000042 wd: 0.000500, loss: 0.74 accuracy: 51.20\n",
      "count : 74 | epoch : 2 batch: 2000 lr : 0.000042 wd: 0.000500, loss: 0.74 accuracy: 51.32\n",
      "count : 74 | epoch : 2 batch: 4000 lr : 0.000042 wd: 0.000500, loss: 0.75 accuracy: 51.25\n",
      "count : 74 | epoch : 2 batch: 6000 lr : 0.000042 wd: 0.000500, loss: 0.73 accuracy: 51.36\n",
      "count : 74 | epoch : 2 batch: 8000 lr : 0.000042 wd: 0.000500, loss: 0.74 accuracy: 51.54\n",
      "count : 74 | epoch : 2 batch: 10000 lr : 0.000042 wd: 0.000500, loss: 0.73 accuracy: 51.31\n",
      "count : 74 | epoch : 2 batch: 12000 lr : 0.000042 wd: 0.000500, loss: 0.75 accuracy: 51.28\n",
      "count : 75 | epoch : 1 batch: 2000 lr : 0.000340 wd: 0.000091, loss: 0.75 accuracy: 50.93\n",
      "count : 75 | epoch : 1 batch: 4000 lr : 0.000340 wd: 0.000091, loss: 0.78 accuracy: 51.01\n",
      "count : 75 | epoch : 1 batch: 6000 lr : 0.000340 wd: 0.000091, loss: 0.78 accuracy: 51.49\n",
      "count : 75 | epoch : 1 batch: 8000 lr : 0.000340 wd: 0.000091, loss: 0.77 accuracy: 51.06\n",
      "count : 75 | epoch : 1 batch: 10000 lr : 0.000340 wd: 0.000091, loss: 0.77 accuracy: 51.21\n",
      "count : 75 | epoch : 1 batch: 12000 lr : 0.000340 wd: 0.000091, loss: 0.80 accuracy: 51.10\n",
      "count : 75 | epoch : 2 batch: 2000 lr : 0.000340 wd: 0.000091, loss: 0.75 accuracy: 51.33\n",
      "count : 75 | epoch : 2 batch: 4000 lr : 0.000340 wd: 0.000091, loss: 0.76 accuracy: 51.08\n",
      "count : 75 | epoch : 2 batch: 6000 lr : 0.000340 wd: 0.000091, loss: 0.76 accuracy: 51.01\n",
      "count : 75 | epoch : 2 batch: 8000 lr : 0.000340 wd: 0.000091, loss: 0.75 accuracy: 51.04\n",
      "count : 75 | epoch : 2 batch: 10000 lr : 0.000340 wd: 0.000091, loss: 0.80 accuracy: 51.18\n",
      "count : 75 | epoch : 2 batch: 12000 lr : 0.000340 wd: 0.000091, loss: 0.79 accuracy: 51.30\n",
      "count : 76 | epoch : 1 batch: 2000 lr : 0.000026 wd: 0.000202, loss: 0.73 accuracy: 51.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 76 | epoch : 1 batch: 4000 lr : 0.000026 wd: 0.000202, loss: 0.72 accuracy: 51.29\n",
      "count : 76 | epoch : 1 batch: 6000 lr : 0.000026 wd: 0.000202, loss: 0.74 accuracy: 51.41\n",
      "count : 76 | epoch : 1 batch: 8000 lr : 0.000026 wd: 0.000202, loss: 0.74 accuracy: 51.40\n",
      "count : 76 | epoch : 1 batch: 10000 lr : 0.000026 wd: 0.000202, loss: 0.74 accuracy: 51.49\n",
      "count : 76 | epoch : 1 batch: 12000 lr : 0.000026 wd: 0.000202, loss: 0.73 accuracy: 51.38\n",
      "count : 76 | epoch : 2 batch: 2000 lr : 0.000026 wd: 0.000202, loss: 0.74 accuracy: 51.29\n",
      "count : 76 | epoch : 2 batch: 4000 lr : 0.000026 wd: 0.000202, loss: 0.73 accuracy: 51.46\n",
      "count : 76 | epoch : 2 batch: 6000 lr : 0.000026 wd: 0.000202, loss: 0.72 accuracy: 51.50\n",
      "count : 76 | epoch : 2 batch: 8000 lr : 0.000026 wd: 0.000202, loss: 0.72 accuracy: 51.49\n",
      "count : 76 | epoch : 2 batch: 10000 lr : 0.000026 wd: 0.000202, loss: 0.75 accuracy: 51.39\n",
      "count : 76 | epoch : 2 batch: 12000 lr : 0.000026 wd: 0.000202, loss: 0.73 accuracy: 51.29\n",
      "count : 77 | epoch : 1 batch: 2000 lr : 0.000433 wd: 0.000006, loss: 0.76 accuracy: 51.14\n",
      "count : 77 | epoch : 1 batch: 4000 lr : 0.000433 wd: 0.000006, loss: 0.77 accuracy: 50.93\n",
      "count : 77 | epoch : 1 batch: 6000 lr : 0.000433 wd: 0.000006, loss: 0.78 accuracy: 50.80\n",
      "count : 77 | epoch : 1 batch: 8000 lr : 0.000433 wd: 0.000006, loss: 0.77 accuracy: 50.68\n",
      "count : 77 | epoch : 1 batch: 10000 lr : 0.000433 wd: 0.000006, loss: 0.79 accuracy: 50.93\n",
      "count : 77 | epoch : 1 batch: 12000 lr : 0.000433 wd: 0.000006, loss: 0.79 accuracy: 50.70\n",
      "count : 77 | epoch : 2 batch: 2000 lr : 0.000433 wd: 0.000006, loss: 0.76 accuracy: 50.89\n",
      "count : 77 | epoch : 2 batch: 4000 lr : 0.000433 wd: 0.000006, loss: 0.76 accuracy: 51.10\n",
      "count : 77 | epoch : 2 batch: 6000 lr : 0.000433 wd: 0.000006, loss: 0.77 accuracy: 51.08\n",
      "count : 77 | epoch : 2 batch: 8000 lr : 0.000433 wd: 0.000006, loss: 0.77 accuracy: 50.95\n",
      "count : 77 | epoch : 2 batch: 10000 lr : 0.000433 wd: 0.000006, loss: 0.78 accuracy: 50.89\n",
      "count : 77 | epoch : 2 batch: 12000 lr : 0.000433 wd: 0.000006, loss: 0.79 accuracy: 50.96\n",
      "count : 78 | epoch : 1 batch: 2000 lr : 0.000073 wd: 0.000138, loss: 0.73 accuracy: 51.18\n",
      "count : 78 | epoch : 1 batch: 4000 lr : 0.000073 wd: 0.000138, loss: 0.72 accuracy: 51.18\n",
      "count : 78 | epoch : 1 batch: 6000 lr : 0.000073 wd: 0.000138, loss: 0.74 accuracy: 51.27\n",
      "count : 78 | epoch : 1 batch: 8000 lr : 0.000073 wd: 0.000138, loss: 0.71 accuracy: 51.06\n",
      "count : 78 | epoch : 1 batch: 10000 lr : 0.000073 wd: 0.000138, loss: 0.74 accuracy: 51.14\n",
      "count : 78 | epoch : 1 batch: 12000 lr : 0.000073 wd: 0.000138, loss: 0.72 accuracy: 51.08\n",
      "count : 78 | epoch : 2 batch: 2000 lr : 0.000073 wd: 0.000138, loss: 0.74 accuracy: 51.44\n",
      "count : 78 | epoch : 2 batch: 4000 lr : 0.000073 wd: 0.000138, loss: 0.72 accuracy: 51.30\n",
      "count : 78 | epoch : 2 batch: 6000 lr : 0.000073 wd: 0.000138, loss: 0.71 accuracy: 51.43\n",
      "count : 78 | epoch : 2 batch: 8000 lr : 0.000073 wd: 0.000138, loss: 0.73 accuracy: 50.95\n",
      "count : 78 | epoch : 2 batch: 10000 lr : 0.000073 wd: 0.000138, loss: 0.72 accuracy: 51.19\n",
      "count : 78 | epoch : 2 batch: 12000 lr : 0.000073 wd: 0.000138, loss: 0.72 accuracy: 51.16\n",
      "count : 79 | epoch : 1 batch: 2000 lr : 0.000573 wd: 0.000022, loss: 0.75 accuracy: 50.47\n",
      "count : 79 | epoch : 1 batch: 4000 lr : 0.000573 wd: 0.000022, loss: 0.77 accuracy: 50.36\n",
      "count : 79 | epoch : 1 batch: 6000 lr : 0.000573 wd: 0.000022, loss: 0.79 accuracy: 51.00\n",
      "count : 79 | epoch : 1 batch: 8000 lr : 0.000573 wd: 0.000022, loss: 0.78 accuracy: 50.77\n",
      "count : 79 | epoch : 1 batch: 10000 lr : 0.000573 wd: 0.000022, loss: 0.79 accuracy: 51.28\n",
      "count : 79 | epoch : 1 batch: 12000 lr : 0.000573 wd: 0.000022, loss: 0.80 accuracy: 50.75\n",
      "count : 79 | epoch : 2 batch: 2000 lr : 0.000573 wd: 0.000022, loss: 0.75 accuracy: 50.87\n",
      "count : 79 | epoch : 2 batch: 4000 lr : 0.000573 wd: 0.000022, loss: 0.77 accuracy: 50.76\n",
      "count : 79 | epoch : 2 batch: 6000 lr : 0.000573 wd: 0.000022, loss: 0.78 accuracy: 50.36\n",
      "count : 79 | epoch : 2 batch: 8000 lr : 0.000573 wd: 0.000022, loss: 0.79 accuracy: 50.68\n",
      "count : 79 | epoch : 2 batch: 10000 lr : 0.000573 wd: 0.000022, loss: 0.78 accuracy: 50.58\n",
      "count : 79 | epoch : 2 batch: 12000 lr : 0.000573 wd: 0.000022, loss: 0.79 accuracy: 50.56\n",
      "count : 80 | epoch : 1 batch: 2000 lr : 0.000772 wd: 0.000684, loss: 0.75 accuracy: 50.57\n",
      "count : 80 | epoch : 1 batch: 4000 lr : 0.000772 wd: 0.000684, loss: 0.79 accuracy: 50.52\n",
      "count : 80 | epoch : 1 batch: 6000 lr : 0.000772 wd: 0.000684, loss: 0.81 accuracy: 50.31\n",
      "count : 80 | epoch : 1 batch: 8000 lr : 0.000772 wd: 0.000684, loss: 0.81 accuracy: 50.33\n",
      "count : 80 | epoch : 1 batch: 10000 lr : 0.000772 wd: 0.000684, loss: 0.81 accuracy: 50.60\n",
      "count : 80 | epoch : 1 batch: 12000 lr : 0.000772 wd: 0.000684, loss: 0.82 accuracy: 50.56\n",
      "count : 80 | epoch : 2 batch: 2000 lr : 0.000772 wd: 0.000684, loss: 0.77 accuracy: 50.66\n",
      "count : 80 | epoch : 2 batch: 4000 lr : 0.000772 wd: 0.000684, loss: 0.79 accuracy: 50.02\n",
      "count : 80 | epoch : 2 batch: 6000 lr : 0.000772 wd: 0.000684, loss: 0.79 accuracy: 50.68\n",
      "count : 80 | epoch : 2 batch: 8000 lr : 0.000772 wd: 0.000684, loss: 0.82 accuracy: 50.74\n",
      "count : 80 | epoch : 2 batch: 10000 lr : 0.000772 wd: 0.000684, loss: 0.80 accuracy: 50.32\n",
      "count : 80 | epoch : 2 batch: 12000 lr : 0.000772 wd: 0.000684, loss: 0.81 accuracy: 50.15\n",
      "count : 81 | epoch : 1 batch: 2000 lr : 0.000142 wd: 0.000007, loss: 0.72 accuracy: 51.28\n",
      "count : 81 | epoch : 1 batch: 4000 lr : 0.000142 wd: 0.000007, loss: 0.71 accuracy: 51.24\n",
      "count : 81 | epoch : 1 batch: 6000 lr : 0.000142 wd: 0.000007, loss: 0.72 accuracy: 51.15\n",
      "count : 81 | epoch : 1 batch: 8000 lr : 0.000142 wd: 0.000007, loss: 0.72 accuracy: 51.01\n",
      "count : 81 | epoch : 1 batch: 10000 lr : 0.000142 wd: 0.000007, loss: 0.71 accuracy: 50.99\n",
      "count : 81 | epoch : 1 batch: 12000 lr : 0.000142 wd: 0.000007, loss: 0.72 accuracy: 51.03\n",
      "count : 81 | epoch : 2 batch: 2000 lr : 0.000142 wd: 0.000007, loss: 0.69 accuracy: 51.24\n",
      "count : 81 | epoch : 2 batch: 4000 lr : 0.000142 wd: 0.000007, loss: 0.71 accuracy: 51.03\n",
      "count : 81 | epoch : 2 batch: 6000 lr : 0.000142 wd: 0.000007, loss: 0.71 accuracy: 51.03\n",
      "count : 81 | epoch : 2 batch: 8000 lr : 0.000142 wd: 0.000007, loss: 0.72 accuracy: 51.16\n",
      "count : 81 | epoch : 2 batch: 10000 lr : 0.000142 wd: 0.000007, loss: 0.71 accuracy: 51.10\n",
      "count : 81 | epoch : 2 batch: 12000 lr : 0.000142 wd: 0.000007, loss: 0.70 accuracy: 50.87\n",
      "count : 82 | epoch : 1 batch: 2000 lr : 0.000098 wd: 0.000297, loss: 0.69 accuracy: 51.02\n",
      "count : 82 | epoch : 1 batch: 4000 lr : 0.000098 wd: 0.000297, loss: 0.71 accuracy: 50.76\n",
      "count : 82 | epoch : 1 batch: 6000 lr : 0.000098 wd: 0.000297, loss: 0.69 accuracy: 50.82\n",
      "count : 82 | epoch : 1 batch: 8000 lr : 0.000098 wd: 0.000297, loss: 0.70 accuracy: 51.03\n",
      "count : 82 | epoch : 1 batch: 10000 lr : 0.000098 wd: 0.000297, loss: 0.70 accuracy: 50.95\n",
      "count : 82 | epoch : 1 batch: 12000 lr : 0.000098 wd: 0.000297, loss: 0.71 accuracy: 50.88\n",
      "count : 82 | epoch : 2 batch: 2000 lr : 0.000098 wd: 0.000297, loss: 0.69 accuracy: 51.09\n",
      "count : 82 | epoch : 2 batch: 4000 lr : 0.000098 wd: 0.000297, loss: 0.71 accuracy: 50.81\n",
      "count : 82 | epoch : 2 batch: 6000 lr : 0.000098 wd: 0.000297, loss: 0.70 accuracy: 50.87\n",
      "count : 82 | epoch : 2 batch: 8000 lr : 0.000098 wd: 0.000297, loss: 0.69 accuracy: 50.99\n",
      "count : 82 | epoch : 2 batch: 10000 lr : 0.000098 wd: 0.000297, loss: 0.70 accuracy: 50.93\n",
      "count : 82 | epoch : 2 batch: 12000 lr : 0.000098 wd: 0.000297, loss: 0.71 accuracy: 50.63\n",
      "count : 83 | epoch : 1 batch: 2000 lr : 0.000705 wd: 0.000023, loss: 0.75 accuracy: 50.50\n",
      "count : 83 | epoch : 1 batch: 4000 lr : 0.000705 wd: 0.000023, loss: 0.75 accuracy: 50.26\n",
      "count : 83 | epoch : 1 batch: 6000 lr : 0.000705 wd: 0.000023, loss: 0.78 accuracy: 50.11\n",
      "count : 83 | epoch : 1 batch: 8000 lr : 0.000705 wd: 0.000023, loss: 0.78 accuracy: 49.86\n",
      "count : 83 | epoch : 1 batch: 10000 lr : 0.000705 wd: 0.000023, loss: 0.79 accuracy: 50.52\n",
      "count : 83 | epoch : 1 batch: 12000 lr : 0.000705 wd: 0.000023, loss: 0.78 accuracy: 50.70\n",
      "count : 83 | epoch : 2 batch: 2000 lr : 0.000705 wd: 0.000023, loss: 0.76 accuracy: 50.41\n",
      "count : 83 | epoch : 2 batch: 4000 lr : 0.000705 wd: 0.000023, loss: 0.75 accuracy: 50.40\n",
      "count : 83 | epoch : 2 batch: 6000 lr : 0.000705 wd: 0.000023, loss: 0.76 accuracy: 50.47\n",
      "count : 83 | epoch : 2 batch: 8000 lr : 0.000705 wd: 0.000023, loss: 0.76 accuracy: 50.62\n",
      "count : 83 | epoch : 2 batch: 10000 lr : 0.000705 wd: 0.000023, loss: 0.79 accuracy: 49.94\n",
      "count : 83 | epoch : 2 batch: 12000 lr : 0.000705 wd: 0.000023, loss: 0.78 accuracy: 50.83\n",
      "count : 84 | epoch : 1 batch: 2000 lr : 0.000044 wd: 0.000453, loss: 0.72 accuracy: 50.76\n",
      "count : 84 | epoch : 1 batch: 4000 lr : 0.000044 wd: 0.000453, loss: 0.69 accuracy: 51.00\n",
      "count : 84 | epoch : 1 batch: 6000 lr : 0.000044 wd: 0.000453, loss: 0.70 accuracy: 50.94\n",
      "count : 84 | epoch : 1 batch: 8000 lr : 0.000044 wd: 0.000453, loss: 0.68 accuracy: 51.04\n",
      "count : 84 | epoch : 1 batch: 10000 lr : 0.000044 wd: 0.000453, loss: 0.68 accuracy: 50.98\n",
      "count : 84 | epoch : 1 batch: 12000 lr : 0.000044 wd: 0.000453, loss: 0.69 accuracy: 51.01\n",
      "count : 84 | epoch : 2 batch: 2000 lr : 0.000044 wd: 0.000453, loss: 0.69 accuracy: 50.97\n",
      "count : 84 | epoch : 2 batch: 4000 lr : 0.000044 wd: 0.000453, loss: 0.68 accuracy: 51.11\n",
      "count : 84 | epoch : 2 batch: 6000 lr : 0.000044 wd: 0.000453, loss: 0.67 accuracy: 51.06\n",
      "count : 84 | epoch : 2 batch: 8000 lr : 0.000044 wd: 0.000453, loss: 0.69 accuracy: 50.82\n",
      "count : 84 | epoch : 2 batch: 10000 lr : 0.000044 wd: 0.000453, loss: 0.67 accuracy: 50.86\n",
      "count : 84 | epoch : 2 batch: 12000 lr : 0.000044 wd: 0.000453, loss: 0.68 accuracy: 51.02\n",
      "count : 85 | epoch : 1 batch: 2000 lr : 0.000176 wd: 0.000261, loss: 0.68 accuracy: 50.68\n",
      "count : 85 | epoch : 1 batch: 4000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 50.78\n",
      "count : 85 | epoch : 1 batch: 6000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 50.79\n",
      "count : 85 | epoch : 1 batch: 8000 lr : 0.000176 wd: 0.000261, loss: 0.70 accuracy: 51.26\n",
      "count : 85 | epoch : 1 batch: 10000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 50.68\n",
      "count : 85 | epoch : 1 batch: 12000 lr : 0.000176 wd: 0.000261, loss: 0.71 accuracy: 50.98\n",
      "count : 85 | epoch : 2 batch: 2000 lr : 0.000176 wd: 0.000261, loss: 0.67 accuracy: 50.81\n",
      "count : 85 | epoch : 2 batch: 4000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 51.18\n",
      "count : 85 | epoch : 2 batch: 6000 lr : 0.000176 wd: 0.000261, loss: 0.70 accuracy: 51.14\n",
      "count : 85 | epoch : 2 batch: 8000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 51.05\n",
      "count : 85 | epoch : 2 batch: 10000 lr : 0.000176 wd: 0.000261, loss: 0.69 accuracy: 50.88\n",
      "count : 85 | epoch : 2 batch: 12000 lr : 0.000176 wd: 0.000261, loss: 0.70 accuracy: 50.64\n",
      "count : 86 | epoch : 1 batch: 2000 lr : 0.000064 wd: 0.000019, loss: 0.68 accuracy: 50.73\n",
      "count : 86 | epoch : 1 batch: 4000 lr : 0.000064 wd: 0.000019, loss: 0.68 accuracy: 50.95\n",
      "count : 86 | epoch : 1 batch: 6000 lr : 0.000064 wd: 0.000019, loss: 0.68 accuracy: 50.91\n",
      "count : 86 | epoch : 1 batch: 8000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.93\n",
      "count : 86 | epoch : 1 batch: 10000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.89\n",
      "count : 86 | epoch : 1 batch: 12000 lr : 0.000064 wd: 0.000019, loss: 0.68 accuracy: 50.99\n",
      "count : 86 | epoch : 2 batch: 2000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.86\n",
      "count : 86 | epoch : 2 batch: 4000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.81\n",
      "count : 86 | epoch : 2 batch: 6000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.85\n",
      "count : 86 | epoch : 2 batch: 8000 lr : 0.000064 wd: 0.000019, loss: 0.68 accuracy: 50.85\n",
      "count : 86 | epoch : 2 batch: 10000 lr : 0.000064 wd: 0.000019, loss: 0.67 accuracy: 50.95\n",
      "count : 86 | epoch : 2 batch: 12000 lr : 0.000064 wd: 0.000019, loss: 0.69 accuracy: 50.85\n",
      "count : 87 | epoch : 1 batch: 2000 lr : 0.000814 wd: 0.000001, loss: 0.74 accuracy: 49.78\n",
      "count : 87 | epoch : 1 batch: 4000 lr : 0.000814 wd: 0.000001, loss: 0.75 accuracy: 50.55\n",
      "count : 87 | epoch : 1 batch: 6000 lr : 0.000814 wd: 0.000001, loss: 0.77 accuracy: 50.23\n",
      "count : 87 | epoch : 1 batch: 8000 lr : 0.000814 wd: 0.000001, loss: 0.78 accuracy: 49.89\n",
      "count : 87 | epoch : 1 batch: 10000 lr : 0.000814 wd: 0.000001, loss: 0.78 accuracy: 50.34\n",
      "count : 87 | epoch : 1 batch: 12000 lr : 0.000814 wd: 0.000001, loss: 0.79 accuracy: 50.14\n",
      "count : 87 | epoch : 2 batch: 2000 lr : 0.000814 wd: 0.000001, loss: 0.75 accuracy: 50.54\n",
      "count : 87 | epoch : 2 batch: 4000 lr : 0.000814 wd: 0.000001, loss: 0.76 accuracy: 50.14\n",
      "count : 87 | epoch : 2 batch: 6000 lr : 0.000814 wd: 0.000001, loss: 0.76 accuracy: 49.63\n",
      "count : 87 | epoch : 2 batch: 8000 lr : 0.000814 wd: 0.000001, loss: 0.78 accuracy: 50.10\n",
      "count : 87 | epoch : 2 batch: 10000 lr : 0.000814 wd: 0.000001, loss: 0.78 accuracy: 50.18\n",
      "count : 87 | epoch : 2 batch: 12000 lr : 0.000814 wd: 0.000001, loss: 0.77 accuracy: 50.15\n",
      "count : 88 | epoch : 1 batch: 2000 lr : 0.000169 wd: 0.000001, loss: 0.68 accuracy: 50.93\n",
      "count : 88 | epoch : 1 batch: 4000 lr : 0.000169 wd: 0.000001, loss: 0.67 accuracy: 50.80\n",
      "count : 88 | epoch : 1 batch: 6000 lr : 0.000169 wd: 0.000001, loss: 0.68 accuracy: 50.43\n",
      "count : 88 | epoch : 1 batch: 8000 lr : 0.000169 wd: 0.000001, loss: 0.68 accuracy: 50.80\n",
      "count : 88 | epoch : 1 batch: 10000 lr : 0.000169 wd: 0.000001, loss: 0.68 accuracy: 50.64\n",
      "count : 88 | epoch : 1 batch: 12000 lr : 0.000169 wd: 0.000001, loss: 0.67 accuracy: 50.70\n",
      "count : 88 | epoch : 2 batch: 2000 lr : 0.000169 wd: 0.000001, loss: 0.66 accuracy: 50.79\n",
      "count : 88 | epoch : 2 batch: 4000 lr : 0.000169 wd: 0.000001, loss: 0.66 accuracy: 50.78\n",
      "count : 88 | epoch : 2 batch: 6000 lr : 0.000169 wd: 0.000001, loss: 0.68 accuracy: 50.77\n",
      "count : 88 | epoch : 2 batch: 8000 lr : 0.000169 wd: 0.000001, loss: 0.67 accuracy: 50.87\n",
      "count : 88 | epoch : 2 batch: 10000 lr : 0.000169 wd: 0.000001, loss: 0.67 accuracy: 50.70\n",
      "count : 88 | epoch : 2 batch: 12000 lr : 0.000169 wd: 0.000001, loss: 0.67 accuracy: 50.80\n",
      "count : 89 | epoch : 1 batch: 2000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.93\n",
      "count : 89 | epoch : 1 batch: 4000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.94\n",
      "count : 89 | epoch : 1 batch: 6000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.93\n",
      "count : 89 | epoch : 1 batch: 8000 lr : 0.000099 wd: 0.000008, loss: 0.65 accuracy: 50.80\n",
      "count : 89 | epoch : 1 batch: 10000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.73\n",
      "count : 89 | epoch : 1 batch: 12000 lr : 0.000099 wd: 0.000008, loss: 0.67 accuracy: 50.90\n",
      "count : 89 | epoch : 2 batch: 2000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.89\n",
      "count : 89 | epoch : 2 batch: 4000 lr : 0.000099 wd: 0.000008, loss: 0.65 accuracy: 50.90\n",
      "count : 89 | epoch : 2 batch: 6000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.97\n",
      "count : 89 | epoch : 2 batch: 8000 lr : 0.000099 wd: 0.000008, loss: 0.65 accuracy: 50.60\n",
      "count : 89 | epoch : 2 batch: 10000 lr : 0.000099 wd: 0.000008, loss: 0.67 accuracy: 50.74\n",
      "count : 89 | epoch : 2 batch: 12000 lr : 0.000099 wd: 0.000008, loss: 0.66 accuracy: 50.87\n",
      "count : 90 | epoch : 1 batch: 2000 lr : 0.000133 wd: 0.000002, loss: 0.66 accuracy: 50.85\n",
      "count : 90 | epoch : 1 batch: 4000 lr : 0.000133 wd: 0.000002, loss: 0.65 accuracy: 50.60\n",
      "count : 90 | epoch : 1 batch: 6000 lr : 0.000133 wd: 0.000002, loss: 0.65 accuracy: 50.89\n",
      "count : 90 | epoch : 1 batch: 8000 lr : 0.000133 wd: 0.000002, loss: 0.67 accuracy: 50.92\n",
      "count : 90 | epoch : 1 batch: 10000 lr : 0.000133 wd: 0.000002, loss: 0.66 accuracy: 50.80\n",
      "count : 90 | epoch : 1 batch: 12000 lr : 0.000133 wd: 0.000002, loss: 0.66 accuracy: 50.48\n",
      "count : 90 | epoch : 2 batch: 2000 lr : 0.000133 wd: 0.000002, loss: 0.65 accuracy: 50.69\n",
      "count : 90 | epoch : 2 batch: 4000 lr : 0.000133 wd: 0.000002, loss: 0.67 accuracy: 50.89\n",
      "count : 90 | epoch : 2 batch: 6000 lr : 0.000133 wd: 0.000002, loss: 0.64 accuracy: 50.44\n",
      "count : 90 | epoch : 2 batch: 8000 lr : 0.000133 wd: 0.000002, loss: 0.66 accuracy: 50.68\n",
      "count : 90 | epoch : 2 batch: 10000 lr : 0.000133 wd: 0.000002, loss: 0.67 accuracy: 50.87\n",
      "count : 90 | epoch : 2 batch: 12000 lr : 0.000133 wd: 0.000002, loss: 0.66 accuracy: 50.89\n",
      "count : 91 | epoch : 1 batch: 2000 lr : 0.000013 wd: 0.000013, loss: 0.65 accuracy: 50.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count : 91 | epoch : 1 batch: 4000 lr : 0.000013 wd: 0.000013, loss: 0.63 accuracy: 50.84\n",
      "count : 91 | epoch : 1 batch: 6000 lr : 0.000013 wd: 0.000013, loss: 0.66 accuracy: 50.84\n",
      "count : 91 | epoch : 1 batch: 8000 lr : 0.000013 wd: 0.000013, loss: 0.66 accuracy: 50.79\n",
      "count : 91 | epoch : 1 batch: 10000 lr : 0.000013 wd: 0.000013, loss: 0.64 accuracy: 50.93\n",
      "count : 91 | epoch : 1 batch: 12000 lr : 0.000013 wd: 0.000013, loss: 0.62 accuracy: 50.87\n",
      "count : 91 | epoch : 2 batch: 2000 lr : 0.000013 wd: 0.000013, loss: 0.63 accuracy: 50.86\n",
      "count : 91 | epoch : 2 batch: 4000 lr : 0.000013 wd: 0.000013, loss: 0.64 accuracy: 50.81\n",
      "count : 91 | epoch : 2 batch: 6000 lr : 0.000013 wd: 0.000013, loss: 0.64 accuracy: 50.88\n",
      "count : 91 | epoch : 2 batch: 8000 lr : 0.000013 wd: 0.000013, loss: 0.65 accuracy: 50.80\n",
      "count : 91 | epoch : 2 batch: 10000 lr : 0.000013 wd: 0.000013, loss: 0.64 accuracy: 50.96\n",
      "count : 91 | epoch : 2 batch: 12000 lr : 0.000013 wd: 0.000013, loss: 0.65 accuracy: 50.92\n",
      "count : 92 | epoch : 1 batch: 2000 lr : 0.000546 wd: 0.000049, loss: 0.67 accuracy: 50.29\n",
      "count : 92 | epoch : 1 batch: 4000 lr : 0.000546 wd: 0.000049, loss: 0.70 accuracy: 50.05\n",
      "count : 92 | epoch : 1 batch: 6000 lr : 0.000546 wd: 0.000049, loss: 0.71 accuracy: 50.07\n",
      "count : 92 | epoch : 1 batch: 8000 lr : 0.000546 wd: 0.000049, loss: 0.71 accuracy: 50.20\n",
      "count : 92 | epoch : 1 batch: 10000 lr : 0.000546 wd: 0.000049, loss: 0.72 accuracy: 50.60\n",
      "count : 92 | epoch : 1 batch: 12000 lr : 0.000546 wd: 0.000049, loss: 0.73 accuracy: 50.18\n",
      "count : 92 | epoch : 2 batch: 2000 lr : 0.000546 wd: 0.000049, loss: 0.66 accuracy: 50.52\n",
      "count : 92 | epoch : 2 batch: 4000 lr : 0.000546 wd: 0.000049, loss: 0.70 accuracy: 49.81\n",
      "count : 92 | epoch : 2 batch: 6000 lr : 0.000546 wd: 0.000049, loss: 0.69 accuracy: 50.89\n",
      "count : 92 | epoch : 2 batch: 8000 lr : 0.000546 wd: 0.000049, loss: 0.72 accuracy: 50.48\n",
      "count : 92 | epoch : 2 batch: 10000 lr : 0.000546 wd: 0.000049, loss: 0.72 accuracy: 50.06\n",
      "count : 92 | epoch : 2 batch: 12000 lr : 0.000546 wd: 0.000049, loss: 0.73 accuracy: 50.21\n",
      "count : 93 | epoch : 1 batch: 2000 lr : 0.000877 wd: 0.000010, loss: 0.71 accuracy: 49.78\n",
      "count : 93 | epoch : 1 batch: 4000 lr : 0.000877 wd: 0.000010, loss: 0.73 accuracy: 49.63\n",
      "count : 93 | epoch : 1 batch: 6000 lr : 0.000877 wd: 0.000010, loss: 0.75 accuracy: 50.43\n",
      "count : 93 | epoch : 1 batch: 8000 lr : 0.000877 wd: 0.000010, loss: 0.76 accuracy: 50.26\n",
      "count : 93 | epoch : 1 batch: 10000 lr : 0.000877 wd: 0.000010, loss: 0.77 accuracy: 50.56\n",
      "count : 93 | epoch : 1 batch: 12000 lr : 0.000877 wd: 0.000010, loss: 0.78 accuracy: 50.02\n",
      "count : 93 | epoch : 2 batch: 2000 lr : 0.000877 wd: 0.000010, loss: 0.72 accuracy: 49.13\n",
      "count : 93 | epoch : 2 batch: 4000 lr : 0.000877 wd: 0.000010, loss: 0.73 accuracy: 49.54\n",
      "count : 93 | epoch : 2 batch: 6000 lr : 0.000877 wd: 0.000010, loss: 0.75 accuracy: 49.90\n",
      "count : 93 | epoch : 2 batch: 8000 lr : 0.000877 wd: 0.000010, loss: 0.76 accuracy: 49.86\n",
      "count : 93 | epoch : 2 batch: 10000 lr : 0.000877 wd: 0.000010, loss: 0.75 accuracy: 50.30\n",
      "count : 93 | epoch : 2 batch: 12000 lr : 0.000877 wd: 0.000010, loss: 0.77 accuracy: 49.56\n",
      "count : 94 | epoch : 1 batch: 2000 lr : 0.000011 wd: 0.000010, loss: 0.68 accuracy: 50.01\n",
      "count : 94 | epoch : 1 batch: 4000 lr : 0.000011 wd: 0.000010, loss: 0.65 accuracy: 50.20\n",
      "count : 94 | epoch : 1 batch: 6000 lr : 0.000011 wd: 0.000010, loss: 0.66 accuracy: 50.22\n",
      "count : 94 | epoch : 1 batch: 8000 lr : 0.000011 wd: 0.000010, loss: 0.65 accuracy: 50.35\n",
      "count : 94 | epoch : 1 batch: 10000 lr : 0.000011 wd: 0.000010, loss: 0.67 accuracy: 50.49\n",
      "count : 94 | epoch : 1 batch: 12000 lr : 0.000011 wd: 0.000010, loss: 0.66 accuracy: 50.46\n",
      "count : 94 | epoch : 2 batch: 2000 lr : 0.000011 wd: 0.000010, loss: 0.64 accuracy: 50.45\n",
      "count : 94 | epoch : 2 batch: 4000 lr : 0.000011 wd: 0.000010, loss: 0.62 accuracy: 50.43\n",
      "count : 94 | epoch : 2 batch: 6000 lr : 0.000011 wd: 0.000010, loss: 0.68 accuracy: 50.42\n",
      "count : 94 | epoch : 2 batch: 8000 lr : 0.000011 wd: 0.000010, loss: 0.64 accuracy: 50.44\n",
      "count : 94 | epoch : 2 batch: 10000 lr : 0.000011 wd: 0.000010, loss: 0.64 accuracy: 50.36\n",
      "count : 94 | epoch : 2 batch: 12000 lr : 0.000011 wd: 0.000010, loss: 0.63 accuracy: 50.36\n",
      "count : 95 | epoch : 1 batch: 2000 lr : 0.000061 wd: 0.000595, loss: 0.63 accuracy: 50.59\n",
      "count : 95 | epoch : 1 batch: 4000 lr : 0.000061 wd: 0.000595, loss: 0.64 accuracy: 50.24\n",
      "count : 95 | epoch : 1 batch: 6000 lr : 0.000061 wd: 0.000595, loss: 0.61 accuracy: 50.45\n",
      "count : 95 | epoch : 1 batch: 8000 lr : 0.000061 wd: 0.000595, loss: 0.64 accuracy: 50.42\n",
      "count : 95 | epoch : 1 batch: 10000 lr : 0.000061 wd: 0.000595, loss: 0.64 accuracy: 50.52\n",
      "count : 95 | epoch : 1 batch: 12000 lr : 0.000061 wd: 0.000595, loss: 0.64 accuracy: 50.43\n",
      "count : 95 | epoch : 2 batch: 2000 lr : 0.000061 wd: 0.000595, loss: 0.62 accuracy: 50.47\n",
      "count : 95 | epoch : 2 batch: 4000 lr : 0.000061 wd: 0.000595, loss: 0.63 accuracy: 50.44\n",
      "count : 95 | epoch : 2 batch: 6000 lr : 0.000061 wd: 0.000595, loss: 0.63 accuracy: 50.52\n",
      "count : 95 | epoch : 2 batch: 8000 lr : 0.000061 wd: 0.000595, loss: 0.63 accuracy: 50.57\n",
      "count : 95 | epoch : 2 batch: 10000 lr : 0.000061 wd: 0.000595, loss: 0.62 accuracy: 50.55\n",
      "count : 95 | epoch : 2 batch: 12000 lr : 0.000061 wd: 0.000595, loss: 0.62 accuracy: 50.60\n",
      "count : 96 | epoch : 1 batch: 2000 lr : 0.000372 wd: 0.000103, loss: 0.64 accuracy: 50.59\n",
      "count : 96 | epoch : 1 batch: 4000 lr : 0.000372 wd: 0.000103, loss: 0.65 accuracy: 50.03\n",
      "count : 96 | epoch : 1 batch: 6000 lr : 0.000372 wd: 0.000103, loss: 0.67 accuracy: 50.66\n",
      "count : 96 | epoch : 1 batch: 8000 lr : 0.000372 wd: 0.000103, loss: 0.65 accuracy: 50.15\n",
      "count : 96 | epoch : 1 batch: 10000 lr : 0.000372 wd: 0.000103, loss: 0.67 accuracy: 50.37\n",
      "count : 96 | epoch : 1 batch: 12000 lr : 0.000372 wd: 0.000103, loss: 0.68 accuracy: 50.12\n",
      "count : 96 | epoch : 2 batch: 2000 lr : 0.000372 wd: 0.000103, loss: 0.65 accuracy: 50.34\n",
      "count : 96 | epoch : 2 batch: 4000 lr : 0.000372 wd: 0.000103, loss: 0.66 accuracy: 50.68\n",
      "count : 96 | epoch : 2 batch: 6000 lr : 0.000372 wd: 0.000103, loss: 0.66 accuracy: 50.32\n",
      "count : 96 | epoch : 2 batch: 8000 lr : 0.000372 wd: 0.000103, loss: 0.67 accuracy: 50.56\n",
      "count : 96 | epoch : 2 batch: 10000 lr : 0.000372 wd: 0.000103, loss: 0.64 accuracy: 50.63\n",
      "count : 96 | epoch : 2 batch: 12000 lr : 0.000372 wd: 0.000103, loss: 0.66 accuracy: 50.51\n",
      "count : 97 | epoch : 1 batch: 2000 lr : 0.000028 wd: 0.000024, loss: 0.62 accuracy: 50.42\n",
      "count : 97 | epoch : 1 batch: 4000 lr : 0.000028 wd: 0.000024, loss: 0.63 accuracy: 50.55\n",
      "count : 97 | epoch : 1 batch: 6000 lr : 0.000028 wd: 0.000024, loss: 0.60 accuracy: 50.53\n",
      "count : 97 | epoch : 1 batch: 8000 lr : 0.000028 wd: 0.000024, loss: 0.60 accuracy: 50.51\n",
      "count : 97 | epoch : 1 batch: 10000 lr : 0.000028 wd: 0.000024, loss: 0.63 accuracy: 50.56\n",
      "count : 97 | epoch : 1 batch: 12000 lr : 0.000028 wd: 0.000024, loss: 0.61 accuracy: 50.76\n",
      "count : 97 | epoch : 2 batch: 2000 lr : 0.000028 wd: 0.000024, loss: 0.60 accuracy: 50.55\n",
      "count : 97 | epoch : 2 batch: 4000 lr : 0.000028 wd: 0.000024, loss: 0.61 accuracy: 50.61\n",
      "count : 97 | epoch : 2 batch: 6000 lr : 0.000028 wd: 0.000024, loss: 0.61 accuracy: 50.70\n",
      "count : 97 | epoch : 2 batch: 8000 lr : 0.000028 wd: 0.000024, loss: 0.61 accuracy: 50.62\n",
      "count : 97 | epoch : 2 batch: 10000 lr : 0.000028 wd: 0.000024, loss: 0.61 accuracy: 50.75\n",
      "count : 97 | epoch : 2 batch: 12000 lr : 0.000028 wd: 0.000024, loss: 0.62 accuracy: 50.71\n",
      "count : 98 | epoch : 1 batch: 2000 lr : 0.000019 wd: 0.000005, loss: 0.63 accuracy: 50.63\n",
      "count : 98 | epoch : 1 batch: 4000 lr : 0.000019 wd: 0.000005, loss: 0.61 accuracy: 50.70\n",
      "count : 98 | epoch : 1 batch: 6000 lr : 0.000019 wd: 0.000005, loss: 0.60 accuracy: 50.70\n",
      "count : 98 | epoch : 1 batch: 8000 lr : 0.000019 wd: 0.000005, loss: 0.61 accuracy: 50.65\n",
      "count : 98 | epoch : 1 batch: 10000 lr : 0.000019 wd: 0.000005, loss: 0.60 accuracy: 50.59\n",
      "count : 98 | epoch : 1 batch: 12000 lr : 0.000019 wd: 0.000005, loss: 0.59 accuracy: 50.56\n",
      "count : 98 | epoch : 2 batch: 2000 lr : 0.000019 wd: 0.000005, loss: 0.61 accuracy: 50.81\n",
      "count : 98 | epoch : 2 batch: 4000 lr : 0.000019 wd: 0.000005, loss: 0.60 accuracy: 50.69\n",
      "count : 98 | epoch : 2 batch: 6000 lr : 0.000019 wd: 0.000005, loss: 0.61 accuracy: 50.59\n",
      "count : 98 | epoch : 2 batch: 8000 lr : 0.000019 wd: 0.000005, loss: 0.61 accuracy: 50.67\n",
      "count : 98 | epoch : 2 batch: 10000 lr : 0.000019 wd: 0.000005, loss: 0.62 accuracy: 50.69\n",
      "count : 98 | epoch : 2 batch: 12000 lr : 0.000019 wd: 0.000005, loss: 0.59 accuracy: 50.76\n",
      "count : 99 | epoch : 1 batch: 2000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.62\n",
      "count : 99 | epoch : 1 batch: 4000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.69\n",
      "count : 99 | epoch : 1 batch: 6000 lr : 0.000012 wd: 0.000001, loss: 0.61 accuracy: 50.68\n",
      "count : 99 | epoch : 1 batch: 8000 lr : 0.000012 wd: 0.000001, loss: 0.62 accuracy: 50.70\n",
      "count : 99 | epoch : 1 batch: 10000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.61\n",
      "count : 99 | epoch : 1 batch: 12000 lr : 0.000012 wd: 0.000001, loss: 0.61 accuracy: 50.55\n",
      "count : 99 | epoch : 2 batch: 2000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.69\n",
      "count : 99 | epoch : 2 batch: 4000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.81\n",
      "count : 99 | epoch : 2 batch: 6000 lr : 0.000012 wd: 0.000001, loss: 0.60 accuracy: 50.78\n",
      "count : 99 | epoch : 2 batch: 8000 lr : 0.000012 wd: 0.000001, loss: 0.61 accuracy: 50.68\n",
      "count : 99 | epoch : 2 batch: 10000 lr : 0.000012 wd: 0.000001, loss: 0.61 accuracy: 50.73\n",
      "count : 99 | epoch : 2 batch: 12000 lr : 0.000012 wd: 0.000001, loss: 0.62 accuracy: 50.66\n",
      "count : 100 | epoch : 1 batch: 2000 lr : 0.000042 wd: 0.000008, loss: 0.60 accuracy: 50.64\n",
      "count : 100 | epoch : 1 batch: 4000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.75\n",
      "count : 100 | epoch : 1 batch: 6000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.66\n",
      "count : 100 | epoch : 1 batch: 8000 lr : 0.000042 wd: 0.000008, loss: 0.62 accuracy: 50.73\n",
      "count : 100 | epoch : 1 batch: 10000 lr : 0.000042 wd: 0.000008, loss: 0.62 accuracy: 50.61\n",
      "count : 100 | epoch : 1 batch: 12000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.59\n",
      "count : 100 | epoch : 2 batch: 2000 lr : 0.000042 wd: 0.000008, loss: 0.60 accuracy: 50.67\n",
      "count : 100 | epoch : 2 batch: 4000 lr : 0.000042 wd: 0.000008, loss: 0.60 accuracy: 50.75\n",
      "count : 100 | epoch : 2 batch: 6000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.60\n",
      "count : 100 | epoch : 2 batch: 8000 lr : 0.000042 wd: 0.000008, loss: 0.62 accuracy: 50.84\n",
      "count : 100 | epoch : 2 batch: 10000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.74\n",
      "count : 100 | epoch : 2 batch: 12000 lr : 0.000042 wd: 0.000008, loss: 0.61 accuracy: 50.69\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "max_count = 100 \n",
    "for count in range(max_count):\n",
    "    weight_decay = 10**np.random.uniform(-6,-3)\n",
    "    learning_rate = 10**np.random.uniform(-5,-3)\n",
    "    \n",
    "    for epoch in range(2): \n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=weight_decay)\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            X = inputs.reshape(-1,32*32*3)\n",
    "            x = torch.tensor(X)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred,labels)\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for data in testloader:\n",
    "                        images, labels = data\n",
    "                        X = images.reshape(-1,32*32*3)\n",
    "                        outputs = model(X)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                print(f'count : {count+1} | epoch : {epoch+1} batch: {i+1} lr : {learning_rate:.6f} wd: {weight_decay:.6f}, loss: {running_loss/2000:.2f} accuracy: {100 * (correct / total):.2f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- count : 17 | epoch : 1 batch: 4000 lr : 0.000008 wd: 0.000640, loss: 1.07 accuracy: 54.21\n",
    "- count : 37 | epoch : 2 batch: 4000 lr : 0.000007 wd: 0.000441, loss: 1.06 accuracy: 54.21\n",
    "- count : 44 | epoch : 2 batch: 4000 lr : 0.000006 wd: 0.003821, loss: 1.08 accuracy: 54.22 \n",
    "- count : 47 | epoch : 2 batch: 4000 lr : 0.000007 wd: 0.000411, loss: 1.08 accuracy: 54.21\n",
    "- count : 63 | epoch : 1 batch: 10000 lr : 0.000003 wd: 0.000003, loss: 1.08 accuracy: 54.24\n",
    "- count : 64 | epoch : 1 batch: 2000 lr : 0.000003 wd: 0.000014, loss: 1.06 accuracy: 54.20\n",
    "- count : 67 | epoch : 1 batch: 10000 lr : 0.000009 wd: 0.000362, loss: 1.07 accuracy: 54.21\n",
    "- count : 68 | epoch : 2 batch: 8000 lr : 0.000004 wd: 0.000131, loss: 1.08 accuracy: 54.20\n",
    "- count : 76 | epoch : 1 batch: 4000 lr : 0.000004 wd: 0.000390, loss: 1.05 accuracy: 54.22\n",
    "- count : 80 | epoch : 2 batch: 12000 lr : 0.000004 wd: 0.000084, loss: 1.07 accuracy: 54.22\n",
    "- count : 82 | epoch : 1 batch: 4000 lr : 0.000006 wd: 0.000178, loss: 1.05 accuracy: 54.24\n",
    "- count : 82 | epoch : 2 batch: 8000 lr : 0.000006 wd: 0.000178, loss: 1.06 accuracy: 54.21\n",
    "- count : 87 | epoch : 2 batch: 10000 lr : 0.000003 wd: 0.000281, loss: 1.05 accuracy: 54.20\n",
    "- count : 88 | epoch : 2 batch: 2000 lr : 0.000006 wd: 0.000006, loss: 1.06 accuracy: 54.27\n",
    "- count : 89 | epoch : 1 batch: 8000 lr : 0.000004 wd: 0.000928, loss: 1.05 accuracy: 54.26\n",
    "- count : 90 | epoch : 1 batch: 6000 lr : 0.000002 wd: 0.001040, loss: 1.07 accuracy: 54.22\n",
    "- count : 91 | epoch : 1 batch: 4000 lr : 0.000001 wd: 0.000007, loss: 1.06 accuracy: 54.20\n",
    "- count : 92 | epoch : 2 batch: 6000 lr : 0.000010 wd: 0.000060, loss: 1.07 accuracy: 54.25\n",
    "- count : 93 | epoch : 1 batch: 10000 lr : 0.000002 wd: 0.000021, loss: 1.06 accuracy: 54.25\n",
    "- count : 94 | epoch : 1 batch: 8000 lr : 0.000006 wd: 0.004167, loss: 1.07 accuracy: 54.25\n",
    "- count : 95 | epoch : 1 batch: 8000 lr : 0.000001 wd: 0.000357, loss: 1.08 accuracy: 54.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "within the range of previous coarse range of learning rate and weight decay, the result of hyperparameter optimization is pertaining low value in loss and promising accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.608\n",
      "[1,  4000] loss: 0.597\n",
      "[1,  6000] loss: 0.612\n",
      "[1,  8000] loss: 0.604\n",
      "[1, 10000] loss: 0.594\n",
      "[1, 12000] loss: 0.607\n",
      "[2,  2000] loss: 0.611\n",
      "[2,  4000] loss: 0.598\n",
      "[2,  6000] loss: 0.609\n",
      "[2,  8000] loss: 0.598\n",
      "[2, 10000] loss: 0.608\n",
      "[2, 12000] loss: 0.603\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =6e-6\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=0.004167)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 50 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 57 %\n",
      "Accuracy of  bird : 40 %\n",
      "Accuracy of   cat : 35 %\n",
      "Accuracy of  deer : 44 %\n",
      "Accuracy of   dog : 39 %\n",
      "Accuracy of  frog : 56 %\n",
      "Accuracy of horse : 55 %\n",
      "Accuracy of  ship : 66 %\n",
      "Accuracy of truck : 54 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate =1e-3 weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.709\n",
      "[1,  4000] loss: 0.730\n",
      "[1,  6000] loss: 0.751\n",
      "[1,  8000] loss: 0.751\n",
      "[1, 10000] loss: 0.775\n",
      "[1, 12000] loss: 0.760\n",
      "[2,  2000] loss: 0.698\n",
      "[2,  4000] loss: 0.743\n",
      "[2,  6000] loss: 0.741\n",
      "[2,  8000] loss: 0.756\n",
      "[2, 10000] loss: 0.760\n",
      "[2, 12000] loss: 0.756\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate =1e-3\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,weight_decay=1e-6)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,32*32*3)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 49 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 52 %\n",
      "Accuracy of   car : 60 %\n",
      "Accuracy of  bird : 39 %\n",
      "Accuracy of   cat : 34 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 33 %\n",
      "Accuracy of  frog : 52 %\n",
      "Accuracy of horse : 54 %\n",
      "Accuracy of  ship : 64 %\n",
      "Accuracy of truck : 49 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,32*32*3)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir='./main_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose([Resize((32,32)),\n",
    "                                 ToTensor(),\n",
    "                                 Normalize([0.485,0.456,0.406],[0.229,0.2245,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'train_dir'),\n",
    "                                            transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'test_dir'), \n",
    "                                           transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('face','nonface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 2000\n",
       "    Root location: ./main_dir\\train_dir\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(32, 32), interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.2245, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "outputSize = 2\n",
    "hiddenSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (3): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize)) \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(inputSize, hiddenSize, requires_grad=True)\n",
    "#W1.requires_grad_()\n",
    "W2 = torch.randn(hiddenSize,outputSize, requires_grad=True)\n",
    "#W2.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2da4we13nf/2fvS2rJ5UqieBVJyZQlSpYvERzFdtNAThHZMaJ+SAq7QSqgAvihCeIUAWq5/iAT6IcECZK2QOpCiF0rhWHFddxYMJzYiipZcVErom+y7qJEUaTJ1Yri7nK5u9zr6Ydz/nP+M3Pe3XeXy12O/fyAxTt7Zt6ZM++cmXlu53mc9x6GYRhG8+jY6A4YhmEYq8Me4IZhGA3FHuCGYRgNxR7ghmEYDcUe4IZhGA3FHuCGYRgN5ZIe4M65u51zLznnjjnn7l+rThmGYRjL41YbB+6c6wTwMoB/AeAUgKcBfMJ7//zadc8wDMNoRdclfPf9AI55718DAOfcwwDuAdDyAb5p0yY/ODh4CYc0DMP4+ePMmTNnvffXVtsv5QG+G8BJ+f8UgF9c6guDg4M4fPjwJRzSMAzj548jR46cyLVfig3cZdpq9hjn3GHn3FHn3NGpqalLOJxhGIahXMoD/BSAvfL/HgCnqxt57x/03t/hvb9j06ZNl3A4wzAMQ7mUB/jTAA465w4453oAfBzAI2vTLcMwDGM5Vm0D997PO+d+D8C3AHQC+IL3/rmV7uelN7sBADt27izabjp4EwDgnbfcXLRdv+8aAMD2beH/ftkHT2Je2ibj5/hEahsbD5+j584BAEZGRop1rx47BgB45sc/Ltq+88QTAIAzLz4tex5f4mx2AQBu/aUPFS0f/FBYvvMDHyjaDt16CABw4EA4iwG5Clyckb1eXAyf09Op7fN/8tnSkY8cObJEv1rRAwDYtOP20O/b3lWsOXDDAQDA3r1JydqxI1yjPXv3FG3XXBOuy+bNVwEABrZsLtZ1xZMZH5eORzo6kuxw6mRwpYzFC9TRmda98Fzwib/04otF2/DwGQDAyZPJBfNTLk8cjy0Xa8cE+mQ5/PYPPPD7ta1W91saDzzwQOn/I3/6cPpnIQ7i+bnU1tsLAOjuS3fz5qvC+OntCev6+9O6rYNbAQA33viOou32d4ex+75fuKNo4/jcfFUnAGBxIR1yMXajYxnRNXYNm+Nw3ib3KJ8z52SIvfJyeKb843eeLNr+4dFHAQDj42MAgOEzw8W6N4+/Fnc2K0cNv80DD/y7pTsnXIoTE977bwL45qXswzAMw1gdl/QAXwv4htU3bV9c7unpKdoolMUXaElC5fKitM3G1+SiNlaYnUl7GY/S39tnz0rbWOZoS9ARfs6e3tRvngslC22jhKrCwPpOjR0AkH777u40HLq7gmakkrJKxmQh/sAzs+E36ptLUm5XV5CA+uTaLi4EcWhRLkxHRRzS60I2b06/39atIRT1XNSkAMB1hGP5JX9BHQxzLbcy1pdOGVcci7zeet23DQ0BAAa2DBRtPVFUXhQxe3Y2SLUd02Ff83PpWs/Pq55eRsfh9HS4F2ZmwrhakOjnONQLjR7QZ0Vi+3XbAaT7amYmSdscu3MTYiKYXfndb1PpDcMwGoo9wA3DMBrKhptQcqpS4cigJwHJ3EAleEo0oTmaS8RZQW0lZ0Kh+j4jqvrIyJsAgJMnTxVtU8N0OixlQlEPZDA7qDmI6t7WrVuLNq7mN/Ui8I3aucQRL43UD2wODsiBgS2xXxkzllwDNWmRqkpK9VX3J7vF4kI4s5nZdIY8Bk00M5Pp9+6K6qeqzdzurJi7uuIAmQP7q45TTk/QwdBalTYuA7wRMzdkV7xvgPQc2LYtmEuGotkESA5zfgJpjKlJbnq67DTX/3nPL2b6oSaUzrjMsTk5mZ5Ps/Hhcn7ifNF27txoOBcxQ+7bt690TgtyzIn43bfFfHTxvJhT2sQkcMMwjIay4RL4wJYg/Q0MJAmLbyyV/qKPqpCsL8pLli9YfakyaolOMyBJi3wL65uZ0hxD1AJ8I6o8LGJ+6G1ajM5L1SYGo8NNc8DI6ho8BXWx8Zync5FxbROl544kgfdVtB9K4kCSeMvXJYQKqmZUdTqplE7hvEOuy2IRTZbOkL9Rjono5JkQ6YTL6nTdEvv79ng8v3mVsBhUqteueh2NNUcl4eLmrN+kKrVyHNEBuHvX7mLdtbFNJXAu67OCIYibN4exWXWSh+4sLYFX1+ecn3of8H5RRz+1B95Duk+O4VlxbKqTs11MAjcMw2go9gA3DMNoKBtuQsk5MamW99Z9ZkUM5nTJhBLU8Zyas7iQ1JaF6OW8GL98UWwSOVU9oR2h2kQTQPLQbVrCFEF1DgCoMbK32mv29qI0TkYLwOSFS1H7GXSe3tl0HjFuXePXqYb2lsxYHXEXuo+w361b6UzKHDn5qApH88KiOq6643ZhX5M8YaRxoeYSxpwrVKFdNPP4cbU3cXtzXK4rizmTQLqOLl4zNdMx1pumk/1xRjAAbN8eTChbxRw5GIMDSs72OI45TNV0weU5MeF1ZkwsXJ+bt8Axz0/th55L0Z94L82Ig58m21GZy6DzGtrFJHDDMIyGsuESeG4mZn/MjSAv1QK+COdEmKLkrW9VvjFVKud6SniTkxeKdbnZfyUHJelgPGOUEjuS1JrygaS3MMMH5WVdOFgX+EIWAZ/nJ0IoJs6X+7064sHm0z5mKuecm3Wpkgcdj3Pym/I7VKAWMw5Lddry3NUJTaGF0v7Zs+kLbNO+sd/V/oftw495sUN/VJNTNgbVGKPG1ZNuauY2UackJe/r94cQvAMHkgTOfEkq5fb2inpXgZq53jcT50P4Xm4mcEdHClaYny/P1FUJn1qhPrM4TsvO1PBJCV+fN8NnQrDEKcnnk3O2LoeNbMMwjIZiD3DDMIyGsuEmlHahdsFP8WlhPtonyslogo6uajYdlSnmO6V3nIs2GTV/0J2p6panajUZTRIZlXCbzB5jnLtS0c6gOaJoGio7acM/l2ZCodkjnUtnxUyiTt3RJRwqqjrSITwyQlNYUmmp6eZScWrqH57z2FhQuTWhGJ3Keg2oruoMPjqrizGgntPZJTKaGZcRuQabw2AYFHMJ08Le+I4bi7aDNx0EkEwnu3anOPChoeC8zFkaZmZaz/dQ0yrRsZNzzldNKLqumC06pGaV8JkLvJifvw5Aev4AwFsxlfWrx15N+7hqiQkiLTAJ3DAMo6EsK4E7574A4GMARrz3t8W2IQB/DWA/gNcB/Cvv/ehqOqBhfkvRWRGsRPDFYgxJ011Rai2njA1yHws5jLyZCjrwjavhjAyl0xmbXJ6L++0TiZ1hTuqUocNF/CO1pPLqkGWEnEoUzC+Sd7SulCR59PSUvcQanpcLaeqNsyx5nuE7oW/UZoa2Je2jv78uUVCuUWWCDk1eFz12Na8FkMK3ejOhYwMIGo/OaluYbYyi+bNFT9LUroqzbVkUBEi5Qm58RyrQcP2+/QCAq69hnh7JgZO5X6gB0jkJJE2VY0cDGZiPpFdmDHd0dsb9J3mWml/uuVBI4Kg7LHXEc2+8Ja6V+4aaRe5ZsRLakcC/CODuStv9AB7z3h8E8Fj83zAMw1hHlhVNvPdPOuf2V5rvAfArcfkhAE8A+NRqOjA3Xw9NKzonvevpKrepHYzSec5ErMHzRdGGt4KN9fTpnxbr+JbWN+38XL1Ps1FKnY8hg2rvpnShb9ViIko9aWFByZ4fRdTS5IPMZIKVE+zzbmvqG232tAeqNsRzz2lIOoGB6+lXUC1hbj4c6/xEmnhBSektKWdXtfFrfggm6l/InLteqwMHbgjfjddHJyWdZNa4+RTGZVx++gZT3p1tQ6EW4u7du4q2XXG5dL9EOzDHuvpDiNqSqa2NnksGAOYzYgkzzbVC/43et5S8dexyPOeeC9dHzYEaBJA0hn37RMPYzv2HT/WH7Yrhksz5ApR/h3ZZrQ38Ou/9GQCIn9uX2d4wDMNYYy67E9M5d9g5d9Q5d3RqaupyH84wDOPnhtV6d950zu303p9xzu0EMNJqQ+/9gwAeBIBdu3b56nqqLaqqM6xHZ2JSgSm2knAdmh3UrEIVTJ1gnAnFROy5sDx1jLEu5JyEFLHQAfOd7NmTqrZz9pg6+Qa2hH3obMSuJX51mlfKsyLXorzD5nhsMX/E34hmCk2FSVW2NKs05qDQMMJqnUz9venY1FApqsQsoAGkGXD9/aGeZkm97ayHYdLB1JtJITodPaLqoOUxp4Zfr+3LuHzs2ZvuDd4T6sjjzGW992ne5KfeezRnqMOShRRGR5PjuwgTjrMdNXdKkX62pz7NW58HHLuTF0Jbr5jk2F81sdI8qw7T+flw/mn2cbo3ejKpp/l7rITVSuCPALg3Lt8L4Our3I9hGIaxStoJI/wygsPyGufcKQAPAPgjAF9xzt0H4A0Av7XaDtB5qVWlKSX2Se+qGQ80zH46I6Ayb4c6JmaKcLzwOSdvUL5hNcCfIUTd0kbpk2/yffuTI4NOjatLTky0PJdcbsH5uF13dzqplKthpe9beaPHHC7qCKXUQG1C98+SVhr2RSmqJ5OkhhK7Fmpg2Obzzz9ftDH3g4Zw8rv8/VRyo3SuhSKm44QjlYootee0qldfPQYAmBrW4W6ZCS83B2+6qVhmeOm14rTj9ZuQ0mSUnicyWjIlXtXyxsfDGDuvBT+ik5PrNMcJ79vezIwbPRYlb+5DnwsDA6GP6ihnCK5qDBz//ZnyhLzXdL+5Pi1HO1Eon2ix6sMrPpphGIaxZthMTMMwjIay4VPUcrHWXd1Brchkky1QqwmtL7ormkvK8dQxX0Z0vNFpBuTTltKs05MparBjxw4AZXWfbaV0l1ErksLsxVuznp2knvNF+6SqYHvo9M+gVi6MJjXxwmg48luxkxrXSlVzx84dRRudQXrN+BttzhT6ZL+7xXHK/BRUTXU5t4/BGEus8bKsNTiTiRdP6W3TvtI1tTqY68mhQ4eK5b5M2mia28bGx4s2Oh7peF4u/w/NoBclPzHNpvzM5TFRxybR8URzBp8fszJLOaWjrvdN2944cQJAMqkOiXOeaabVHJSb67AcJoEbhmE0lA2XwGn81zcRw4QmkULIqtJ4rmq7hhdxeWwsSXo8BiXxUi6NGFakYXHF9ot1yY0SBUspAcmRNrAlSb59zOFS20N6e+beu7mCFbl+5InOyx6Z2TXLMKvWEk2pqEal2jyQpIZSqFSUoig9dHcnp0wuj0lnETKYjkWpnOGBx48fL9ZR61AJnE7XxcV0bcfGLsS2SlZC6HXWUaQl14zLgYYMpgyS6U5gjh+dha3jAqiGAbceu6WSZ3HmJe/Ha66tV7GntqzomGGYKx3m6milxqgZC1lOMVe+TTVbktM2u5eKL26BSeCGYRgNxR7ghmEYDWXDTShTMd5Sk9a8HlXo/v7kBJneGVTzrdHvOCkFr6lZ6T44k0qLNlANYqymzsbKxWAWDgxxbtDkQzNCl5gMtkTVXrUjKoRLuSfUMMJDleLXWQNyNlflO7Bpxx3FMmd09YmT9uSzz3Jv8q3QX8Z6X51JpqNq5eBg2F6zXlLDPXUyqJxMvAVIBXBRkTmzU/tG1Xgqfj7+2GPFOsbSHjp0a9FG81X5egfnF1VTdbQmdVXVVjOhXG46xelO04maSAajI3GbpCCmiaNqSgFSfPeExHxzjOl44j4YYLBXAg2YxlXNGpzprMmmLlbMf3RIAsDpn56O/UlmFZpQ9Jyrsy3VbMPACC3isJ4zMQ3DMIwNZsMlcCbxX8gY/3Wm5PBwcIgwRE8lVIYhvSWz+yi55Yog0KGieT66qzleAQwM1KU0hhpxZpmGDFIK0PSwOcmbbXSBaCAl/SLlUL2Ys2ShtROTifABYCim7tScIpRexk7Il6J0nUK8khRDTaNUdi5K0kOZVJxcp5ILy7KVJKboQM5JG9R0JibSdWSa0DEJOxzqrMsdnNFGp5duP1Kkrh2vfs24jCws1sucqTZLB7UGDmyNhR+YHlglcWqImk6W94mmjC1mSUcpW2cTUyq/fv91so9633nvUEsYl1BHPgN0Jib7PThYD2pgwYodO1M/WFBC88Ckgiqb6h1qgUnghmEYDcUe4IZhGA1lw00oVHXL6lbQacqpSYOTiiqVxltOF3XxJmpt5dl6rIdXj0ll/LJWsKbzIZdEiuqczujq7a3PlMyZUKgoXYxWknItz7iNzPyabcOJqeYPOmo0mRATV70kpiJWM+FvqjM9i1lyEkefKuakvjEmm+rkjKyr1hXU7Wjm0b5Tze4YTr83Hc5qmsnNtuT4oaqrqnoaF5bAaj3Re5TjQttoOukTMwnNmnTu6UxgVsIpJZ2Ky7pfjguaS7TSDR2J269O/ZyOQ2V6Opk/+J3RGMs+l3GK6/OJZkV1VFbrXqq5lcEPem+k/ZkJxTAM42eeDZfAczOS+FZluA6QnGmUvnI5TjSV41L1IymBM+wPSNKAvmkpxakjhRIkZwbqTMyMH7RwVKpsTsk7CsXQCZYTE+VZiQAwFjfU/CFVtGgCHUC333570UaniUo0P/rhDwGoBFz//TQsqqjGPVQP+0p1BZPkS6cuHTxAkrBuvDFVImehDTo29dwp4W+SccLj5/JqcMxouloe88JpDRVtrc0Ya0Muz5Hel0wRrJIpl7dUNDsgjS11UNNRrlJ5cvqz8EJ9XOvTgYcYGko3MKVnaun8H0jjU60GvA9U2uc4zT2zKG3r84YpbAFRD5bBJHDDMIyGsuESOEN8VPrjm1vtwGyjlJ2TwBWGFWl4YJHVL2N7Y54R3Rff/jkplHlBylnvEPuY+tER3+76puT6VIE+raOtkFIpkCYMjI+1lsDPn/p/xfKJE8H2rRLqre96VzynNHmJ0gvtcSrF5Cb3UHpXaYSnz2RwGs7F303DNSmhaG6T6ekYGhpt/NvEPl7NCqfL6sPguQ7EEDM9ZrpGJoGvJ/OZ+DwNGcxpyZ3xJuK919+f7l+OU30uTMbxrPboquSvviPeQyMjKYyQt/fkhXqYLrVCDXuduSYcX3OX8D7RyUCU7KmUTl1I99fEfBinmuVQl9tlWQncObfXOfe4c+4F59xzzrlPxvYh59yjzrlX4ue25fZlGIZhrB3tmFDmAfyh9/4WAHcC+F3n3CEA9wN4zHt/EMBj8X/DMAxjnWinpNoZAGfi8oRz7gUAuwHcg1ArEwAeAvAEgE+ttAO7d+8CUEknG9XghbGk0nA9w8l05mZntmZkV62N6j1V725R9xcWw3aaKpWhhaqqF2FOUaXK1YdUzZEao3aNvo9ciUuqlar2FbMoZTbYVrTmheefA5AqdgPAwZsOAiirfS+9+GLcrj5jsuqsBYAb3xFMJ5oLheS0P6rLamaik6pc9CIcazyapQYlNDM5R0Vtjqpof18yEVWvVa/kuUmmpIyX2bhsaA6cwpGXMXeqKWWuMmNT1+VqYvJ5UKqdOV+enTkppoulQnJ1vynkODpaxTQy0BHGrpoot29nKG7aHy05NKHMZUIG9Zi59MvLsSInpnNuP4D3AngKwHXx4c6H/PYW3znsnDvqnDs6NTW14g4ahmEYedp2YjrnrgLwNwD+wHt/3jnX1ve89w8CeBAAdu3a5avrN2Umy/At3C9SVzVRvzoWOyqOD0ATyCepq+og0WMuVPavy+oI5f4oXZada+XPsF9+L7VRIOVuVWKfng4re6UKO6WWUl6XJYTJqeFnAAB//3fflL79Wjx2kobpqKTjVLUP/r6lEnNRcxg+U89xkQuVYrZHPWZuchSzwRU5akQ651hQiYlZCLXAxcBFFnkIx9eJTSmMUUNWR2FcXkpFNeJY0HuU63XyF68tHewqxRf3gah7lFrVcck2lmdT6ZzrdNIax5GOf45B3iPX70/ZC7fEdYuiKU5O1rMnTk8zICEcXzVcOlM5wa663C5tSeDOuW6Eh/eXvPdfi81vOud2xvU7AYy0+r5hGIax9rQTheIAfB7AC977P5NVjwC4Ny7fC+Dra989wzAMoxXtmFA+COB3APzEOfej2PYfAfwRgK845+4D8AaA31pNB6g2q+pN50AuFWxh1uhWs0ZXaV/alqvk3pFJR1rdvy7ntufsLp3lRVNId+ZX1SburStqk7OyUgtEFPvN5IZZ2h8XzA3f/ta3ihaqgoduTUUyinwPUV09Lwnq6XApFZZg7VFN5xnVzp5Mekw6idWE0ptx+hJeM92ex9JzP7sQ1Gy9LtxvkShf4na3MsWnel/TKRiXCXUk03SSu/56bZnLhm25Z4CaRbP7jbs7G80xKZ1wMmMsNVMbALbHHCgcT9dkip0sV0U+zemoV7EvilNkam2uhHaiUL4LoJXB+8MrPqJhGIaxJmz4TMyc9My3bnmWY9mhqNIX96HSKx2WC5kZm8VnRz0UEbKPXJGH+UIyDeKoOtdmZoIzpL8/Sf2UxlXuqFajnxcBn6dVzuQWjlGqyp2imloyduL/Fsv/9NTNAMpZAJmt7epYtVt/q4tFYYTkWJk4f77Wt+r2udl3Gm7F6zhfck6F343OTJ0hm3MAXewMx9Lx0bWrLL1vHaxnltsiOVnOmwR+2ckFFehY4H2o4/rcaNAGqRWqdE7JW8fw9v4wo1Id39VSiCrFc3yqFM/Zvvr84Pihw1LPhWNdZ1ayv2UNPoxnOl1LmkZ0Yp7Xca33d5tYLhTDMIyGYg9wwzCMhrLhJpRcvDEdB6UY0CUcBlRV1IFG52JuJhfNL2qG0RmKxX4Z6y37pRpEhx/NCgBwMdbJnLuqniJX986zomInp4m5uWBO0HOfyahg5cRMy/PU954CUE7tevCm4OShQ0VjaZdy0Gg6Waqnp06eBJBmdQJJNVZTVIrnr8fhVmfbAik2lqp1+G5H7VxokuH1UEcrzS+rSRZkrJ7lHIVkqaACJc24lmr33XXzKRNLvf/OXwRQjq/mvaSmHDpby7U5gwmFMzB11u/IyJsAgLNjZ4s2jlk1/+kxQr/T/rlfnem8e98+rBSTwA3DMBrKhkvgOZLDMnVvPkpxlAzzORUWZJnJ3JNUydC4jsXwBu/pkX10lY+tyzOlULqwzHAnlfSmL3JWWF0CzzG7yH6lNkqSGp5IKVeLJaxUAvfjzwIAvp0iC3H8+GsAUtEELfbQmbkG1JbKgkVZW8qFSuXCydTZuVBcq7nSvoD0m+p+6bTWtKJMjM9rpZoApfeLq8g1YayeXArgHHrPcbxxFm8uvXNXJk5Xt2M5tqGoEZfTUocxprlNOJ46M1aA3Axjjid1xE9PX6xtx/uFhU00UIPSuRY2yYVMLodJ4IZhGA3FHuCGYRgNZcNNKNkKO4uscalOzHq1jCq5WZeqblWdJarG9xYJrtS5FlX7+XqinJyzjGkrZ2ZSnOrcfHSwisVjrlgXj5M5tZKjJpqPcqrjSqEpBQBefprLewAAv3BXmpfFJGMaa81rNXpO0m5G1ZXbqZpIs4fG0KY47eSArJJLfqUOXKqfS9VTLVUuv5CLr93wof8zj5oB56KZYm5O77n6rMxNlWs6o3MIOjOm1XgT6SxGVrPqzVTr4T1dMslFB6iaUDi2aErR5HI8fjklcv1cUjrlMCtYZ3PSeanBAly/8PaP0C4mgRuGYTSUDRdDqhWktS27PWdRZsTWnBSv++Xbjm9aLdRAiVeldIYElfoWl+m00OrnaZahVsEOoUHz2zWULnxSeGfaSSDlbVCJgueae8uvDcOxPykkktXdVWrg71EunIHYt57SNkBe2qbzSKXnaiJ7DTvkdlq9m6liVWJi37kvpiUFgFdeebnWN/TfXjsHY205K9eA113TQFdTEQNJauY61cKpSU0spnHKY6iWTLpyocGZOq28r1TDLXLr9NRzrVDqz43TXHgsj6XPrBMnTgAAXnn55aKNy7fsrHW7JSaBG4ZhNJQNl8CXIitRs3p8zmY+V7eZ5yby0Ca7SSbc5Oxr3dHGpW1FmaZoQxsePlOso9ScK5M0Obk3HStKHCkjWbKjj7wZJgloBjWGD5Zt4Mv7BNqnHgL46qvHAACDklOEkrRKIylRf+tcF4Nb0z5oN+wRmyKPqzZTQql5MNOmUOKmlqWa0diJUDru6gMpE+Ott72rtg9jbRkeHi6WOYaXK/JQLfihY2I0hu+pT4N+GZ2swwlb9B31yv77Mv4TjlnVcHmvsR86UYjhiaqdUsMoFWKJY5HH1Hv6B0e/DwD4xye/U7Q9+5Pgk7rl9+5Bu5gEbhiG0VDsAW4YhtFQljWhOOf6ADyJMOWuC8BXvfcPOOcOAHgYwBCAHwD4He99vdTzMnDmXMkkkpllWSW3fW4mpm5X5ECJjobOXPGGTDrIru5Mde1FOjOTuYSmAO0/VbuTMVcIkFQ27ktNF6OxkjzzLWibOhmxM4UqrhX6W81WktEDKQWmmpQKlbezntOGqmuPmFxyM9uYTpZtJWcSZ+RlTGalYhNRRacZq5Qcv6McElbdn3F5UCcmUfPXfH/d8dhdKWiiJjnmONm2bQhV9HoX+XPibNwZmcHM8TwqM3WXMrX0FgVCksmlCILorptWcymwx2J/Xo8znwHgmWd+HD5//EzRtjD6k7i0tiaUGQB3ee/fDeA9AO52zt0J4I8B/Ln3/iBChdj72j6qYRiGccm0U5HHA7gQ/+2Ofx7AXQD+dWx/CMBnAXxupR2gcyMnPbfLQkbazu0jVbTPFHvIbM+3aq/MwlmMQfkMW1Jpm2/3sdKkgtCm0gjf0pQuOPEASA5NzeXBtnIuj7WXwBVKLVpIISdRMcyL56JaDR0/ubDD+VK2RY6Bxdr2vAbd82mo5oo80EFEp/LwmeRA644S25BIblq13rg8aCgntTbNIEmWykaohRfoDFdNihLyuXMpLHApDZfLmt+IwQ/6DOAxioIzpXw+vfGcUt9yY5xaaa4kYj7vycrDhNutSt8Z62GOAHgUwKsAxrz3vAtPAdjd4ruHnXNHnXNHp6amVtxBwzAMI09bD3Dv/YL3/j0Ic67fD+CW3GYtvvug9/4O7/0dmzZtWn1PDcMwjBIrigP33o85554AcCeAQedcV5TC9wA4vZoOMF1ojqWcmf36F8AAAAggSURBVKXiDbl8KnG9qmdVNUdNErn0qdxeK5wXqlV3Oe2ltql6luLANc1qcEZS1cvFjU/J9uynxrmvLfWa1Yyl1Ur1b2dMKIWzOMaIl+N8g+lJzSpFulwxoVCd5PmV04sGNXW2Qx2WYfmMxOC/9GKI9T7+2vFSvwBgb6z9qelyry5ieOux58baMDaWTImM/9eiGt10AiYLYnHf8l5SJybTxGoOkty8An6H5prRTGrhiUxR1JzDlPU3tYjJYNyvziMpcgFlngd00l8tceMHDtwAoHxPnz6dxme7LCuBO+eudc4NxuV+AL8K4AUAjwP4zbjZvQC+vuKjG4ZhGKumHQl8J4CHnHOdCA/8r3jvv+Gcex7Aw865/wTghwA+v5oOUPrKhe8pKcyvvi6f94SVzuv7pfNyTnKWFJXtxTFRDSUC6g7IkjQQcx7o253SthZjYN84M3S+NIM040zt6q61rS0xXFK0j4VMxXCGZ+mstM7K9chlaCuVZ4sz67SNWgels1xeC4V5aHT2HZfn3g5aQt/2VKrqn/3zXwYAHDx4U9HGbHBnnv/2kscy1gbee6qxppDSFMBAhz7HmN4P+Yx/9ecBKbTk3rp0rs+KXAggZ1luixL4loFUAKIv47DnjFGdOVq9l3fvTm7C7duvAwB89GO/Lv0I5/z8dx9ueU5V2olCeQbAezPtryHYww3DMIwNwGZiGoZhNJQNT2ZFh5Sq5fRt5MwlOagOLbRR9EFRVT051+pOLTUtUH3iZ7koRFDxOjMxoZMdyRRBU8FcJnlTjiKhzmUzpTA+vl7MYjYzi02dN9N9wfxBNbU0Ey0T37uQ2S9jzvl7LDcPgL9fzvkLBPNVT09KHnb77e8GALzz5puLNjOhXH50PBV1brvrQQJ6vTkWujNmtLmB1vfLUjO5y8VR6mYV3rcDYiahOZSmEx3zufubzw8NYOAY577Uibl3bzCnHNyV9kED0We/Wz+/VpgEbhiG0VBcmGi5PuzatcsfPnx43Y5nGIbxs8CRI0e+772/o9puErhhGEZDsQe4YRhGQ7EHuGEYRkOxB7hhGEZDWVcnpnPuLQCTAOpJNZrFNWj2OTS9/0Dzz6Hp/Qeafw5N6v8+7/211cZ1fYADgHPuaM6b2iSafg5N7z/Q/HNoev+B5p9D0/sPmAnFMAyjsdgD3DAMo6FsxAP8wQ045lrT9HNoev+B5p9D0/sPNP8cmt7/9beBG4ZhGGuDmVAMwzAayro+wJ1zdzvnXnLOHXPO3b+ex14Nzrm9zrnHnXMvOOeec859MrYPOecedc69Ej8vb4n4SyQWpf6hc+4b8f8DzrmnYv//2jnXs9w+NhLn3KBz7qvOuRfjtfilBl6Dfx/H0LPOuS875/qu5OvgnPuCc27EOfestGV/cxf4r/G+fsY5976N63mixTn8SRxHzzjn/jerjcV1n47n8JJz7tc2ptcrY90e4LGiz18A+AiAQwA+4Zw7tF7HXyXzAP7Qe38LQh3Q3419vh/AY977gwAei/9fyXwSoQwe+WMAfx77Pwrgvg3pVfv8FwB/772/GcC7Ec6lMdfAObcbwO8DuMN7fxtCCaSP48q+Dl8EcHelrdVv/hEAB+PfYQCfW6c+LscXUT+HRwHc5r2/HcDLAD4NAPG+/jiAW+N3/lt8Zl3RrKcE/n4Ax7z3r3nvZwE8DOCedTz+ivHen/He/yAuTyA8OHYj9PuhuNlDAP7lxvRweZxzewD8OoC/jP87AHcB+Grc5Erv/xYAv4xYss97P+u9H0ODrkGkC0C/c64LwCYAZ3AFXwfv/ZMAzlWaW/3m9wD4Kx/4HkLB853r09PW5M7Be//tWIgdAL6HUJAdCOfwsPd+xnt/HMAxNKDi2Ho+wHcDOCn/n4ptjcA5tx+htNxTAK7z3p8BwkMewPbW39xw/jOA/wCAWe6vBjAmg/hKvw43AHgLwP+IZqC/dM5tRoOugff+pwD+FMAbCA/ucQDfR7OuA9D6N2/qvf1vAfxdXG7kOaznA9xl2hoRAuOcuwrA3wD4A+/9+Y3uT7s45z4GYMR7/31tzmx6JV+HLgDvA/A57/17EVIxXLHmkhzRVnwPgAMAdgHYjGB2qHIlX4elaNqYgnPuMwgm0i+xKbPZFX0OwPo+wE8B2Cv/7wFweh2Pvyqcc90ID+8vee+/FpvfpIoYP0c2qn/L8EEAv+Gcex3BZHUXgkQ+GFV54Mq/DqcAnPLePxX//yrCA70p1wAAfhXAce/9W977OQBfA/ABNOs6AK1/80bd2865ewF8DMBv+xRH3ahzIOv5AH8awMHoee9BcBg8so7HXzHRXvx5AC947/9MVj0C4N64fC+Ar69339rBe/9p7/0e7/1+hN/7/3jvfxvA4wB+M252xfYfALz3wwBOOufeGZs+DOB5NOQaRN4AcKdzblMcUzyHxlyHSKvf/BEA/yZGo9wJYJymlisN59zdAD4F4De891Oy6hEAH3fO9TrnDiA4ZP9pI/q4Irz36/YH4KMInt9XAXxmPY+9yv5+CEGNegbAj+LfRxHsyI8BeCV+Dm10X9s4l18B8I24fAPC4DwG4H8B6N3o/i3T9/cAOBqvw98C2Na0awDgCIAXATwL4H8i1LC9Yq8DgC8j2OvnEKTT+1r95gjmh7+I9/VPEKJtrtRzOIZg6+b9/N9l+8/Ec3gJwEc2uv/t/NlMTMMwjIZiMzENwzAaij3ADcMwGoo9wA3DMBqKPcANwzAaij3ADcMwGoo9wA3DMBqKPcANwzAaij3ADcMwGsr/B3E/zdmKaHM3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonface  face nonface  face\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.063\n",
      "[1,   400] loss: 0.065\n",
      "[2,   200] loss: 0.061\n",
      "[2,   400] loss: 0.063\n",
      "[3,   200] loss: 0.056\n",
      "[3,   400] loss: 0.064\n",
      "[4,   200] loss: 0.057\n",
      "[4,   400] loss: 0.062\n",
      "[5,   200] loss: 0.057\n",
      "[5,   400] loss: 0.062\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    learning_rate = 6e-6\n",
    "    weight_decay =0.004167\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay = weight_decay)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  face : 96 %\n",
      "Accuracy of nonface : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with regularization weight_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation \n",
    "\n",
    "- Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data.\n",
    "- Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomCrop\n",
    "transforms = transforms.Compose([RandomCrop(20,20),\n",
    "                                ToTensor(),\n",
    "                                Normalize([0.485,0.456,0.406],[0.229,0.2245,0.225])\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'train_dir'),\n",
    "                                            transform=transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 2000\n",
       "    Root location: ./main_dir\\train_dir\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               RandomCrop(size=(20, 20), padding=20)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.2245, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose([Resize((20,20)),\n",
    "                                 ToTensor(),\n",
    "                                 Normalize([0.485,0.456,0.406],[0.229,0.2245,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'test_dir'), \n",
    "                                           transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('face','nonface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " face nonface  face nonface\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " face  face  face  face\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 20*20*3\n",
    "outputSize = 2\n",
    "hiddenSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1200, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (3): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, 0.74)\n",
      "(epoch: 1, 0.70)\n",
      "(epoch: 2, 0.71)\n",
      "(epoch: 2, 0.71)\n",
      "(epoch: 3, 0.69)\n",
      "(epoch: 3, 0.69)\n",
      "(epoch: 4, 0.69)\n",
      "(epoch: 4, 0.69)\n",
      "(epoch: 5, 0.69)\n",
      "(epoch: 5, 0.69)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    learning_rate = 1e-2\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_accuracy = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #running_accuracy +=acc.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'(epoch: {epoch + 1}, {running_loss / 200:.2f})')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 57 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # we dont use back propagation during interference\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  face : 86 %\n",
      "Accuracy of nonface : 28 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose([Resize((32,32)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 ToTensor(),\n",
    "                                 Normalize([0.485,0.456,0.406],[0.229,0.2245,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'train_dir'),\n",
    "                                            transform=transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transforms = transforms.Compose([Resize((32,32)),\n",
    "                                 ToTensor(),\n",
    "                                 Normalize([0.485,0.456,0.406],[0.229,0.2245,0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.ImageFolder(root=os.path.join(root_dir,'test_dir'), \n",
    "                                           transform=transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('face','nonface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "outputSize = 2\n",
    "hiddenSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=10, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
      "  (3): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonface nonface nonface nonface\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, 0.08)\n",
      "(epoch: 1, 0.07)\n",
      "(epoch: 2, 0.09)\n",
      "(epoch: 2, 0.07)\n",
      "(epoch: 3, 0.09)\n",
      "(epoch: 3, 0.07)\n",
      "(epoch: 4, 0.08)\n",
      "(epoch: 4, 0.08)\n",
      "(epoch: 5, 0.07)\n",
      "(epoch: 5, 0.07)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    learning_rate = 6e-6\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.004167)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_accuracy = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #running_accuracy +=acc.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'(epoch: {epoch + 1}, {running_loss / 200:.2f})')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # we dont use back propagation during interference\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  face : 96 %\n",
      "Accuracy of nonface : 99 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "hiddenSize_1 = 100\n",
    "hiddenSize_2 = 50 \n",
    "outputSize = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize_1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize_1,hiddenSize_2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize_2,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, 0.09)\n",
      "(epoch: 1, 0.09)\n",
      "(epoch: 2, 0.09)\n",
      "(epoch: 2, 0.09)\n",
      "(epoch: 3, 0.09)\n",
      "(epoch: 3, 0.09)\n",
      "(epoch: 4, 0.09)\n",
      "(epoch: 4, 0.09)\n",
      "(epoch: 5, 0.08)\n",
      "(epoch: 5, 0.10)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    learning_rate = 6e-6\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.004167)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_accuracy = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #running_accuracy +=acc.item()\n",
    "        if i % 200 == 199:    # print every 2000 mini-batches\n",
    "            print(f'(epoch: {epoch + 1}, {running_loss / 200:.2f})')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # we dont use back propagation during interference\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  face : 97 %\n",
      "Accuracy of nonface : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(2))\n",
    "class_total = list(0. for i in range(2))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputSize = 32*32*3\n",
    "hiddenSize_1 = 100\n",
    "hiddenSize_2 = 10 \n",
    "outputSize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(inputSize,hiddenSize_1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize_1,hiddenSize_2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hiddenSize_2,outputSize),\n",
    "    torch.nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, 1.73)\n",
      "(epoch: 1, 1.71)\n",
      "(epoch: 1, 1.71)\n",
      "(epoch: 1, 1.68)\n",
      "(epoch: 1, 1.65)\n",
      "(epoch: 1, 1.65)\n",
      "(epoch: 2, 1.65)\n",
      "(epoch: 2, 1.60)\n",
      "(epoch: 2, 1.59)\n",
      "(epoch: 2, 1.61)\n",
      "(epoch: 2, 1.57)\n",
      "(epoch: 2, 1.56)\n",
      "(epoch: 3, 1.55)\n",
      "(epoch: 3, 1.54)\n",
      "(epoch: 3, 1.54)\n",
      "(epoch: 3, 1.52)\n",
      "(epoch: 3, 1.53)\n",
      "(epoch: 3, 1.51)\n",
      "(epoch: 4, 1.49)\n",
      "(epoch: 4, 1.48)\n",
      "(epoch: 4, 1.48)\n",
      "(epoch: 4, 1.48)\n",
      "(epoch: 4, 1.48)\n",
      "(epoch: 4, 1.46)\n",
      "(epoch: 5, 1.44)\n",
      "(epoch: 5, 1.44)\n",
      "(epoch: 5, 1.46)\n",
      "(epoch: 5, 1.43)\n",
      "(epoch: 5, 1.43)\n",
      "(epoch: 5, 1.42)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    learning_rate = 6e-6\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=0.004167)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_accuracy = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #running_accuracy +=acc.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'(epoch: {epoch + 1}, {running_loss / 2000:.2f})')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 48 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # we dont use back propagation during interference\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 62 %\n",
      "Accuracy of  bird : 31 %\n",
      "Accuracy of   cat : 29 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 38 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 64 %\n",
      "Accuracy of truck : 52 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Model requires different learning rate and weight_decay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rache\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch: 1, 1.62)\n",
      "(epoch: 1, 1.59)\n",
      "(epoch: 1, 1.55)\n",
      "(epoch: 1, 1.54)\n",
      "(epoch: 1, 1.54)\n",
      "(epoch: 1, 1.52)\n",
      "(epoch: 2, 1.45)\n",
      "(epoch: 2, 1.47)\n",
      "(epoch: 2, 1.44)\n",
      "(epoch: 2, 1.48)\n",
      "(epoch: 2, 1.44)\n",
      "(epoch: 2, 1.45)\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): \n",
    "    learning_rate = 1e-2\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, weight_decay=1e-6)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #running_accuracy = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        X = inputs.reshape(-1,inputSize)\n",
    "        x = torch.tensor(X)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred,labels)\n",
    "    \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        #running_accuracy +=acc.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'(epoch: {epoch + 1}, {running_loss / 2000:.2f})')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad(): # we dont use back propagation during interference\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy : %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 47 %\n",
      "Accuracy of   car : 39 %\n",
      "Accuracy of  bird : 27 %\n",
      "Accuracy of   cat : 43 %\n",
      "Accuracy of  deer : 48 %\n",
      "Accuracy of   dog : 27 %\n",
      "Accuracy of  frog : 53 %\n",
      "Accuracy of horse : 51 %\n",
      "Accuracy of  ship : 67 %\n",
      "Accuracy of truck : 68 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        X = images.reshape(-1,inputSize)\n",
    "        outputs = model(X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
